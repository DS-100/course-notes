{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Pandas III\n",
    "execute:\n",
    "  echo: true\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-tools: true\n",
    "    toc: true\n",
    "    toc-title: Pandas III\n",
    "    page-layout: full\n",
    "    theme:\n",
    "      - cosmo\n",
    "      - cerulean\n",
    "    callout-icon: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"false\"}\n",
    "## Learning Outcomes\n",
    "* Perform advanced aggregation using `.groupby()`\n",
    "* Use the `pd.pivot_table` method to construct a pivot table\n",
    "* Perform simple merges between DataFrames using `pd.merge()`\n",
    ":::\n",
    "\n",
    "Last time, we introduced the concept of aggregating data – we familiarized ourselves with `GroupBy` objects and used them as tools to consolidate and summarize a DataFrame. In this lecture, we will explore working with the different aggregation functions and dive into some advanced `.groupby` methods to show just how powerful of a resource they can be for understanding our data. We will also introduce other techniques for data aggregation to provide flexibility in how we manipulate our tables. \n",
    "\n",
    "## Revisiting the `.agg()` Function\n",
    "\n",
    "We'll start by loading the `babynames` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mary</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Helen</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Frances</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Sex  Year      Name  Count\n",
       "0    CA   F  1910      Mary    295\n",
       "1    CA   F  1910     Helen    239\n",
       "2    CA   F  1910   Dorothy    220\n",
       "3    CA   F  1910  Margaret    163\n",
       "4    CA   F  1910   Frances    134"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "# This code pulls census data and loads it into a DataFrame\n",
    "# We won't cover it explicitly in this class, but you are welcome to explore it on your own\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os.path\n",
    "import zipfile\n",
    "\n",
    "data_url = \"https://www.ssa.gov/oact/babynames/state/namesbystate.zip\"\n",
    "local_filename = \"data/babynamesbystate.zip\"\n",
    "if not os.path.exists(local_filename): # If the data exists don't download again\n",
    "    with urllib.request.urlopen(data_url) as resp, open(local_filename, 'wb') as f:\n",
    "        f.write(resp.read())\n",
    "\n",
    "zf = zipfile.ZipFile(local_filename, 'r')\n",
    "\n",
    "ca_name = 'STATE.CA.TXT'\n",
    "field_names = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "with zf.open(ca_name) as fh:\n",
    "    babynames = pd.read_csv(fh, header=None, names=field_names)\n",
    "\n",
    "babynames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using `.agg` to find the total number of babies born in each year. Recall that using `.agg` with `.groupby()` follows the format: `df.groupby(column_name).agg(aggregation_function)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>9163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>9983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>17946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>22094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>26926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "Year       \n",
       "1910   9163\n",
       "1911   9983\n",
       "1912  17946\n",
       "1913  22094\n",
       "1914  26926"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "babynames.groupby(\"Year\")[[\"Count\"]].agg(sum).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/aggregation.png\" alt='aggregation' width='600'>\n",
    "\n",
    "There are many different aggregations that can be applied to the grouped data. `.agg()` can take in any function that aggregates several values into one summary value.\n",
    "\n",
    "Because of this fairly broad requirement, `pandas` offers many ways of computing an aggregation.\n",
    "\n",
    "**In-built** Python operations – such as `sum`, `max`, and `min` – are automatically recognized by `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`NumPy`** functions, such as `np.mean`, `np.max`, `np.min`, and `np.sum`, are also fair game in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` also offers a number of in-built functions, including:\n",
    "\n",
    "* `.agg(\"sum\")`\n",
    "* `.agg(\"max\")`\n",
    "* `.agg(\"min\")`\n",
    "* `.agg(\"mean\")`\n",
    "* `.agg(\"first\")`\n",
    "* `.agg(\"last\")`\n",
    "\n",
    "Some commonly-used aggregation functions can even be called directly, without explicit use of `.agg()`. For example, we can call `.mean()` on `.groupby()`: `babynames.groupby(\"Year\").mean()`. \n",
    "\n",
    "We can now put this all into practice. Say we want to find the baby name with sex \"F\" that has fallen in popularity the most in California. To calculate this, we can first create a metric: \"Ratio to Peak\" (RTP). The RTP is the ratio of babies born with a given name in 2022 to the *maximum* number of babies born with the name in *any* year. \n",
    "\n",
    "Let's start with calculating this for one baby, \"Jennifer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018796372629843364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "# We filter by babies with sex \"F\" and sort by \"Year\"\n",
    "f_babynames = babynames[babynames[\"Sex\"] == \"F\"]\n",
    "f_babynames = f_babynames.sort_values([\"Year\"])\n",
    "\n",
    "#Determine how many Jennifers were born in CA per year\n",
    "jenn_counts_series = f_babynames[f_babynames[\"Name\"] == \"Jennifer\"][\"Count\"]\n",
    "\n",
    "#Determine the max number of Jennifers born in a year and the number born in 2022 to calculate RTP\n",
    "max_jenn = max(f_babynames[f_babynames[\"Name\"] == \"Jennifer\"][\"Count\"])\n",
    "curr_jenn = f_babynames[f_babynames[\"Name\"] == \"Jennifer\"][\"Count\"].iloc[-1]\n",
    "rtp = curr_jenn / max_jenn\n",
    "rtp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating a function to calculate RTP and applying it to our `DataFrame` by using `.groupby()`, we can easily compute the RTP for all names at once! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aadhini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aadhira</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aadhya</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aadya</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aahana</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year     Count\n",
       "Name                   \n",
       "Aadhini   1.0  1.000000\n",
       "Aadhira   1.0  0.500000\n",
       "Aadhya    1.0  0.660000\n",
       "Aadya     1.0  0.586207\n",
       "Aahana    1.0  0.269231"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ratio_to_peak(series):\n",
    "    return series.iloc[-1] / max(series)\n",
    "\n",
    "#Using .groupby() to apply the function\n",
    "rtp_table = f_babynames.groupby(\"Name\")[[\"Year\", \"Count\"]].agg(ratio_to_peak)\n",
    "rtp_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"**`pandas`**-ification\" of logic you saw in Data 8. Much of the logic you've learned in Data 8 will serve you well in Data 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuisance Columns\n",
    "\n",
    "Note that you must be careful with which columns you apply the `.agg()` function to. If we were to apply our function to the table as a whole by doing `f_babynames.groupby(\"Name\").agg(ratio_to_peak)`, executing our `.agg()` call would result in a `TypeError`.\n",
    "\n",
    "<img src=\"images/error.png\" alt='error' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By explicitly selecting column(s) we want to apply our aggregation function to **BEFORE** calling `.agg()`, we can avoid this issue and prevent unintentional loss of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GroupBy()`, Continued\n",
    "\n",
    "Let's now dive deeper into `groupby`. As we learned last lecture, a `groupby` operation involves some combination of **splitting a DataFrame into grouped subframes**, **applying a function**, and **combining the results**. \n",
    "\n",
    "For some arbitrary DataFrame `df` below, the code `df.groupby(\"year\").agg(sum)` does the following:\n",
    "\n",
    "- **Splits** the `DataFrame` into sub-`DataFrame`s with rows belonging to the same year.\n",
    "- **Applies** the `sum` function to each column of each sub-`DataFrame`.\n",
    "- **Combines** the results of `sum` into a single `DataFrame`, indexed by `year`.\n",
    "\n",
    "<img src=\"images/groupby_demo.png\" alt='groupby_demo' width='600'>\n",
    "\n",
    "Note that the result of `groupby` applied to a `DataFrame` is a `DataFrameGroupBy` object, **not** a `DataFrame`.\n",
    "\n",
    "### Aggregation with `lambda` Functions\n",
    "\n",
    "What if we wish to aggregate our DataFrame using a non-standard function – for example, a function of our own design? We can do so by combining `.agg` with `lambda` expressions.\n",
    "\n",
    "We'll work with the `elections` DataFrame again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Party</th>\n",
       "      <th>Popular vote</th>\n",
       "      <th>Result</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>151271</td>\n",
       "      <td>loss</td>\n",
       "      <td>57.210122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1824</td>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>113142</td>\n",
       "      <td>win</td>\n",
       "      <td>42.789878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1828</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>642806</td>\n",
       "      <td>win</td>\n",
       "      <td>56.203927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1828</td>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>National Republican</td>\n",
       "      <td>500897</td>\n",
       "      <td>loss</td>\n",
       "      <td>43.796073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1832</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>702735</td>\n",
       "      <td>win</td>\n",
       "      <td>54.574789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year          Candidate                  Party  Popular vote Result  \\\n",
       "0  1824     Andrew Jackson  Democratic-Republican        151271   loss   \n",
       "1  1824  John Quincy Adams  Democratic-Republican        113142    win   \n",
       "2  1828     Andrew Jackson             Democratic        642806    win   \n",
       "3  1828  John Quincy Adams    National Republican        500897   loss   \n",
       "4  1832     Andrew Jackson             Democratic        702735    win   \n",
       "\n",
       "           %  \n",
       "0  57.210122  \n",
       "1  42.789878  \n",
       "2  56.203927  \n",
       "3  43.796073  \n",
       "4  54.574789  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first consider a puzzle to jog our memory. We will attempt to find the `Candidate` from each `Party` with the highest `%` of votes. \n",
    "\n",
    "A naive approach may be to group by the `Party` column and aggregate by the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.groupby(\"Party\").agg(max).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is clearly wrong – the DataFrame claims that Woodrow Wilson won the presidency in 2020.\n",
    "\n",
    "Why is this happening? Here, the `max` aggregation function is taken over every column *independently*. Among Democrats, `max` is computing:\n",
    "\n",
    "- The most recent `Year` a Democratic candidate ran for president (2020)\n",
    "- The `Candidate` with the alphabetically \"largest\" name (\"Woodrow Wilson\")\n",
    "- The `Result` with the alphabetically \"largest\" outcome (\"win\")\n",
    "\n",
    "Instead, let's try a different approach. We will:\n",
    "\n",
    "1. Sort the DataFrame so that rows are in descending order of `%`\n",
    "2. Group by `Party` and select the first row of each sub-DataFrame\n",
    "\n",
    "While it may seem unintuitive, sorting `elections` by descending order of `%` is extremely helpful. If we then group by `Party`, the first row of each groupby object will contain information about the `Candidate` with the highest voter `%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_sorted_by_percent = elections.sort_values(\"%\", ascending=False)\n",
    "elections_sorted_by_percent.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_sorted_by_percent.groupby(\"Party\").agg(lambda x : x.iloc[0]).head(10)\n",
    "\n",
    "# Equivalent to the below code\n",
    "# elections_sorted_by_percent.groupby(\"Party\").agg('first').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an illustration of the process:\n",
    "\n",
    "<img src=\"images/puzzle_demo.png\" alt='groupby_demo' width='600'>\n",
    "\n",
    "Notice how our code correctly determines that Lyndon Johnson from the Democratic Party has the highest voter `%`.\n",
    "\n",
    "More generally, `lambda` functions are used to design custom aggregation functions that aren't pre-defined by Python. The input parameter `x` to the `lambda` function is a `GroupBy` object. Therefore, it should make sense why `lambda x : x.iloc[0]` selects the first row in each groupby object.\n",
    "\n",
    "\n",
    "In fact, there's a few different ways to approach this problem. Each approach has different tradeoffs in terms of readability, performance, memory consumption, complexity, etc. We've given a few examples below. \n",
    "\n",
    "**Note**: Understanding these alternative solutions is not required. They are given to demonstrate the vast number of problem-solving approaches in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the idxmax function\n",
    "best_per_party = elections.loc[elections.groupby('Party')['%'].idxmax()]\n",
    "best_per_party.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the .drop_duplicates function\n",
    "best_per_party2 = elections.sort_values('%').drop_duplicates(['Party'], keep='last')\n",
    "best_per_party2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other `GroupBy` Features\n",
    "\n",
    "There are many aggregation methods we can use with `.agg`. Some useful options are:\n",
    "\n",
    "* [`.mean`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.mean.html#pandas.core.groupby.DataFrameGroupBy.mean): creates a new DataFrame with the mean value of each group\n",
    "* [`.sum`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.sum.html#pandas.core.groupby.DataFrameGroupBy.sum): creates a new DataFrame with the sum of each group\n",
    "* [`.max`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.max.html#pandas.core.groupby.DataFrameGroupBy.max) and [`.min`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.min.html#pandas.core.groupby.DataFrameGroupBy.min): creates a new DataFrame with the maximum/minimum value of each group\n",
    "* [`.first`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.first.html#pandas.core.groupby.DataFrameGroupBy.first) and [`.last`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.last.html#pandas.core.groupby.DataFrameGroupBy.last): creates a new DataFrame with the first/last row in each group\n",
    "* [`.size`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.size.html#pandas.core.groupby.DataFrameGroupBy.size): creates a new **Series** with the number of entries in each group\n",
    "* [`.count`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.count.html#pandas.core.groupby.DataFrameGroupBy.count): creates a new **DataFrame** with the number of entries, excluding missing values. \n",
    "\n",
    "Note the slight difference between `.size()` and `.count()`: while `.size()` returns a Series and counts the number of entries including the missing values, `.count()` returns a DataFrame and counts the number of entries in each column excluding missing values. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'letter':['A','A','B','C','C','C'], \n",
    "                   'num':[1,2,3,4,np.NaN,4], \n",
    "                   'state':[np.NaN, 'tx', 'fl', 'hi', np.NaN, 'ak']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"letter\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"letter\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recall that the `value_counts()` function in the previous note does something similar. It turns out `value_counts()` and `groupby.size()` are the same, except `value_counts()` sorts the resulting Series in descending order automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These (and other) aggregation functions are so common that `pandas` allows for writing shorthand. Instead of explicitly stating the use of `.agg`, we can call the function directly on the `GroupBy` object.\n",
    "\n",
    "For example, the following are equivalent:\n",
    "\n",
    "- `elections.groupby(\"Candidate\").agg(mean)` \n",
    "- `elections.groupby(\"Candidate\").mean()`\n",
    "\n",
    "There are many other methods that `pandas` supports. You can check them out on the [`pandas` documentation](https://pandas.pydata.org/docs/reference/groupby.html).\n",
    "\n",
    "\n",
    "\n",
    "### Filtering by Group\n",
    "\n",
    "Another common use for `GroupBy` objects is to filter data by group. \n",
    "\n",
    "`groupby.filter` takes an argument $\\text{f}$, where $\\text{f}$ is a function that:\n",
    "\n",
    "- Takes a DataFrame object as input\n",
    "- Returns a single `True` or `False` for the each sub-DataFrame\n",
    "\n",
    "Sub-DataFrames that correspond to `True` are returned in the final result, whereas those with a `False` value are not. Importantly, `groupby.filter` is different from `groupby.agg` in that an *entire* sub-DataFrame is returned in the final DataFrame, not just a single row. As a result, `groupby.filter` preserves the original indices.\n",
    "\n",
    "To illustrate how this happens, consider the following `.filter` function applied on some arbitrary data. Say we want to identify \"tight\" election years – that is, we want to find all rows that correspond to elections years where all candidates in that year won a similar portion of the total vote. Specifically, let's find all rows corresponding to a year where no candidate won more than 45% of the total vote. \n",
    "\n",
    "In other words, we want to: \n",
    "\n",
    "- Find the years where the maximum `%` in that year is less than 45%\n",
    "- Return all DataFrame rows that correspond to these years\n",
    "\n",
    "For each year, we need to find the maximum `%` among *all* rows for that year. If this maximum `%` is lower than 45%, we will tell `pandas` to keep all rows corresponding to that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.groupby(\"Year\").filter(lambda sf: sf[\"%\"].max() < 45).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? In this example, we've defined our filtering function, $\\text{f}$, to be `lambda sf: sf[\"%\"].max() < 45`. This filtering function will find the maximum `\"%\"` value among all entries in the grouped sub-DataFrame, which we call `sf`. If the maximum value is less than 45, then the filter function will return `True` and all rows in that grouped sub-DataFrame will appear in the final output DataFrame. \n",
    "\n",
    "Examine the DataFrame above. Notice how, in this preview of the first 9 rows, all entries from the years 1860 and 1912 appear. This means that in 1860 and 1912, no candidate in that year won more than 45% of the total vote. \n",
    "\n",
    "You may ask: how is the `groupby.filter` procedure different to the boolean filtering we've seen previously? Boolean filtering considers *individual* rows when applying a boolean condition. For example, the code `elections[elections[\"%\"] < 45]` will check the `\"%\"` value of every single row in `elections`; if it is less than 45, then that row will be kept in the output. `groupby.filter`, in contrast, applies a boolean condition *across* all rows in a group. If not all rows in that group satisfy the condition specified by the filter, the entire group will be discarded in the output. \n",
    "\n",
    "\n",
    "## Aggregating Data with Pivot Tables\n",
    "\n",
    "We know now that `.groupby` gives us the ability to group and aggregate data across our DataFrame. The examples above formed groups using just one column in the DataFrame. It's possible to group by multiple columns at once by passing in a list of column names to `.groupby`. \n",
    "\n",
    "Let's consider the `babynames` dataset. In this problem, we will find the total number of baby names associated with each sex for each year. To do this, we'll group by *both* the `\"Year\"` and `\"Sex\"` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "import urllib.request\n",
    "import os.path\n",
    "\n",
    "# Download data from the web directly\n",
    "data_url = \"https://www.ssa.gov/oact/babynames/names.zip\"\n",
    "local_filename = \"data/babynames.zip\"\n",
    "if not os.path.exists(local_filename): # if the data exists don't download again\n",
    "    with urllib.request.urlopen(data_url) as resp, open(local_filename, 'wb') as f:\n",
    "        f.write(resp.read())\n",
    "\n",
    "        \n",
    "# Load data without unzipping the file\n",
    "import zipfile\n",
    "babynames = [] \n",
    "with zipfile.ZipFile(local_filename, \"r\") as zf:\n",
    "    data_files = [f for f in zf.filelist if f.filename[-3:] == \"txt\"]\n",
    "    def extract_year_from_filename(fn):\n",
    "        return int(fn[3:7])\n",
    "    for f in data_files:\n",
    "        year = extract_year_from_filename(f.filename)\n",
    "        with zf.open(f) as fp:\n",
    "            df = pd.read_csv(fp, names=[\"Name\", \"Sex\", \"Count\"])\n",
    "            df[\"Year\"] = year\n",
    "            babynames.append(df)\n",
    "babynames = pd.concat(babynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Find the total number of baby names associated with each sex for each year in the data\n",
    "babynames.groupby([\"Year\", \"Sex\"])[[\"Count\"]].agg(sum).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both `\"Year\"` and `\"Sex\"` serve as the index of the DataFrame (they are both rendered in bold). We've created a *multi-index* DataFrame where two different index values, the year and sex, are used to uniquely identify each row. \n",
    "\n",
    "This isn't the most intuitive way of representing this data – and, because multi-indexed DataFrames have multiple dimensions in their index, they can often be difficult to use. \n",
    "\n",
    "Another strategy to aggregate across two columns is to create a pivot table. You saw these back in [Data 8](https://inferentialthinking.com/chapters/08/3/Cross-Classifying_by_More_than_One_Variable.html#pivot-tables-rearranging-the-output-of-group). One set of values is used to create the index of the pivot table; another set is used to define the column names. The values contained in each cell of the table correspond to the aggregated data for each index-column pair.\n",
    "\n",
    "The best way to understand pivot tables is to see one in action. Let's return to our original goal of summing the total number of names associated with each combination of year and sex. We'll call the `pandas` [`.pivot_table`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html) method to create a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# The `pivot_table` method is used to generate a Pandas pivot table\n",
    "import numpy as np\n",
    "babynames.pivot_table(\n",
    "    index = \"Year\", \n",
    "    columns = \"Sex\", \n",
    "    values = \"Count\", \n",
    "    aggfunc = np.sum).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks a lot better! Now, our DataFrame is structured with clear index-column combinations. Each entry in the pivot table represents the summed count of names for a given combination of `\"Year\"` and `\"Sex\"`.\n",
    "\n",
    "Let's take a closer look at the code implemented above. \n",
    "\n",
    "* `index = \"Year\"` specifies the column name in the original DataFrame that should be used as the index of the pivot table\n",
    "* `columns = \"Sex\"` specifies the column name in the original DataFrame that should be used to generate the columns of the pivot table\n",
    "* `values = \"Count\"` indicates what values from the original DataFrame should be used to populate the entry for each index-column combination\n",
    "* `aggfunc = np.sum` tells `pandas` what function to use when aggregating the data specified by `values`. Here, we are summing the name counts for each pair of `\"Year\"` and `\"Sex\"`\n",
    "\n",
    "We can even include multiple values in the index or columns of our pivot tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babynames_pivot = babynames.pivot_table(\n",
    "    index=\"Year\",     # the rows (turned into index)\n",
    "    columns=\"Sex\",    # the column values\n",
    "    values=[\"Count\", \"Name\"], \n",
    "    aggfunc=max,   # group operation\n",
    ")\n",
    "babynames_pivot.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Tables \n",
    "\n",
    "When working on data science projects, we're unlikely to have absolutely all the data we want contained in a single DataFrame – a real-world data scientist needs to grapple with data coming from multiple sources. If we have access to multiple datasets with related information, we can join two or more tables into a single DataFrame. \n",
    "\n",
    "To put this into practice, we'll revisit the `elections` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to understand the popularity of the names of each presidential candidate in 2020. To do this, we'll need the combined data of `babynames` *and* `elections`. \n",
    "\n",
    "We'll start by creating a new column containing the first name of each presidential candidate. This will help us join each name in `elections` to the corresponding name data in `babynames`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# This `str` operation splits each candidate's full name at each \n",
    "# blank space, then takes just the candidiate's first name\n",
    "elections[\"First Name\"] = elections[\"Candidate\"].str.split().str[0]\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we'll only consider `babynames` data from 2020\n",
    "babynames_2020 = babynames[babynames[\"Year\"]==2020]\n",
    "babynames_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to join the two tables. [`pd.merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) is the `pandas` method used to join DataFrames together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(left = elections, right = babynames_2020, \\\n",
    "                  left_on = \"First Name\", right_on = \"Name\")\n",
    "merged.head()\n",
    "# Notice that pandas automatically specifies `Year_x` and `Year_y` \n",
    "# when both merged DataFrames have the same column name to avoid confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the parameters:\n",
    "\n",
    "* `left` and `right` parameters are used to specify the DataFrames to be joined.\n",
    "* `left_on` and `right_on` parameters are assigned to the string names of the columns to be used when performing the join. These two `on` parameters tell `pandas` what values should act as pairing keys to determine which rows to merge across the DataFrames. We'll talk more about this idea of a pairing key next lecture.\n",
    "\n",
    "\n",
    "## Parting Note\n",
    "\n",
    "Congratulations! We finally tackled `pandas`. Don't worry if you are still not feeling very comfortable with it—you will have plenty of chance to practice over the next few weeks.\n",
    "\n",
    "Next, we will get our hands dirty with some real-world datasets and use our `pandas` knowledge to conduct some exploratory data analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
