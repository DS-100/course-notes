[
  {
    "objectID": "visualization_1.html",
    "href": "visualization_1.html",
    "title": "Visualization I",
    "section": "",
    "text": "In our journey of the data science lifecycle, we have begun to explore the vast world of exploratory data analysis. More recently, we learned how to pre-process data using feature engineering and data manipulation techniques. As we work towards designing complex models, there is one key component missing in our arsenal - the ability to visualize and discern relationships in existing data.\nThese next two lectures will introduce you to various examples of data visualizations and their underlying theory. In doing so, we’ll motivate their usefulness in real-world examples with helpful plotting libraries."
  },
  {
    "objectID": "visualization_1.html#visualizations-in-data-8-and-data-100-so-far",
    "href": "visualization_1.html#visualizations-in-data-8-and-data-100-so-far",
    "title": "Visualization I",
    "section": "Visualizations in Data 8 and Data 100 (so far)",
    "text": "Visualizations in Data 8 and Data 100 (so far)\nYou’ve likely encountered several forms of data visualizations in your studies. You may remember two such examples from Data 8: line charts and histograms. Each of these served a unique purpose. For example, line charts displayed how numerical quantities changed over time, while histograms were useful in understanding a variable’s distribution.\n\n\nLine Chart\n\n\n\n\nHistogram"
  },
  {
    "objectID": "visualization_1.html#goals-of-visualization",
    "href": "visualization_1.html#goals-of-visualization",
    "title": "Visualization I",
    "section": "Goals of Visualization",
    "text": "Goals of Visualization\nVisualizations are useful for a number of reasons. In Data 100, we consider two areas in particular:\n\nTo broaden your understanding of the data\n\nKey part in exploratory data analysis\nUseful in investigating relationships between variables\n\nTo communicate your results to others\n\nVisualization theory is especially important here\n\n\nOne of the most common applications of visualizations - and the one that will be covered today - is in understanding a distribution of data."
  },
  {
    "objectID": "visualization_1.html#an-overview-of-distributions",
    "href": "visualization_1.html#an-overview-of-distributions",
    "title": "Visualization I",
    "section": "An Overview of Distributions",
    "text": "An Overview of Distributions\nA distribution describes the frequency of unique values in a variable. Distributions must satisfy two properties:\n\nEach data point must belong to only one category.\nThe total frequency of all categories must sum to 100%. In other words, their total count should equal the number of values in consideration.\n\nLet’s look at a couple of examples.\n\n\nNot a Valid Distribution\n\n\n\n\nValid Distribution\n\n\n\nLeft Diagram: This is not a valid distribution. Individuals can belong to more than one category and the total frequency of all categories does not sum up to 100%.\nRight Diagram: This example satisfies the two properties of distributions, so it is a valid distribution."
  },
  {
    "objectID": "visualization_1.html#bar-plots",
    "href": "visualization_1.html#bar-plots",
    "title": "Visualization I",
    "section": "Bar Plots",
    "text": "Bar Plots\nAs we saw above, bar plots are one of the most common ways of displaying the distribution of a qualitative (categorical) variable. The length of a bar plot encodes the frequency of a category; the width encodes no useful information.\nLet’s contextualize this in an example. We will use the familiar births dataset from Data 8 in our analysis.\n\n\nCode\nimport pandas as pd\n\nbirths = pd.read_csv(\"baby.csv\")\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nWe can visualize the distribution of the Maternal Smoker column using a bar plot. There are a few ways to do this.\n\nPlotting in Pandas\n\n# births['Maternal Smoker'].value_counts().plot(kind = 'bar');\n\nRecall that .value_counts() returns a Series with the total count of each unique value. We call .plot(kind = 'bar') on this result to visualize these counts as a bar plot.\nPlotting methods in pandas are the least preferred and not supported in Data 100, as their functionality is limited. Instead, future examples will focus on other libaries built specifically for visualizing data. The most well-known library here is matplotlib.\n\n\nPlotting in Matplotlib\n\nimport matplotlib.pyplot as plt\n\nms = births['Maternal Smoker'].value_counts()\nplt.bar(ms.index, ms)\nplt.xlabel(\"Maternal Smoker\")\nplt.ylabel(\"Count\");\n\n\n\n\nWhile more code is required to achieve the same result, matplotlib is often used over pandas for its ability to plot more complex visualizations, some of which are discussed shortly.\nHowever, notice how the x-axis is a range of integers rather than the two categories, True and False. This is because matplotlib coerces True to a value of 1 and False to 0. Also, note how we needed to label the axes with plt.xlabel and plt.ylabel - matplotlib does not support automatic axis labeling. To get around these inconveniences, we can use a more effecient plotting library, seaborn.\n\n\nPlotting in Seaborn\n\nimport seaborn as sns\nsns.countplot(data = births, x = \"Maternal Smoker\");\n\n\n\n\nseaborn.countplot both counts and visualizes the number of unique values in a given column. This column is specified by the x argument to sns.countplot, while the DataFrame is specified by the data argument.\nFor the vast majority of visualizations, seaborn is far more concise and aesthetically pleasing than matplotlib. However, the color scheme of this particular bar plot is abritrary - it encodes no additional information about the categories themselves. This is not always true; color may signify meaningful detail in other visualizations. We’ll explore this more in-depth during the next lecture.\n\n\nPlotting in Plotly\n\nplotly is one of the most versatile plottling libraries and widely used in industry. However, plotly has various dependencies that make it difficult to support in Data 100. Therfore, we have intentionally excluded the code to generate the plot above.\nBy now, you’ll have noticed that each of these plotting libraries have a very different syntax. As with pandas, we’ll teach you the important methods in matplotlib and seaborn, but you’ll learn more through documentation.\n\nMatplotlib Documentation\nSeaborn Documentation"
  },
  {
    "objectID": "visualization_1.html#histograms",
    "href": "visualization_1.html#histograms",
    "title": "Visualization I",
    "section": "Histograms",
    "text": "Histograms\nHistograms are a natural extension to bar plots; they visualize the distribution of quantitative (numerical) data.\nRevisiting our example with the births DataFrame, let’s plot the distribution of the Maternal Pregnancy Weight column.\n\n\nCode\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nHow should we define our categories for this variable? In the previous example, these were the unique values of the Maternal Smoker column: True and False. If we use similar logic here, our categories are the different numerical weights contained in the Maternal Pregnancy Weight column.\nUnder this assumption, let’s plot this distribution using the seaborn.countplot function.\n\nsns.countplot(data = births, x = 'Maternal Pregnancy Weight');\n\n\n\n\nThis histogram clearly suffers from overplotting. This is somewhat expected for Maternal Pregnancy Weight - it is a quantitative variable that takes on a wide range of values.\nTo combat this problem, statisticians use bins to categorize numerical data. Luckily, seaborn provides a helpful plotting function that automatically bins our data.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\n\n\n\n\nThis diagram is known as a histogram. While it looks more reasonable, notice how we lose fine-grain information on the distribution of data contained within each bin. We can introduce rug plots to minimize this information loss. An overlaid “rug plot” displays the within-bin distribution of our data, as denoted by the thickness of the colored line on the x-axis.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');\n\n\n\n\nYou may have seen histograms drawn differently - perhaps with an overlaid density curve and normalized y-axis. We can display both with a few tweaks to our code.\nTo visualize a density curve, we can set the the kde = True argument of the sns.histplot. Setting the argument stat = \"density\" normalizes our histogram and displays densities, instead of counts, on the y-axis. You’ll notice that the area under the density curve is 1.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\", kde = True, \n             stat = \"density\")\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');"
  },
  {
    "objectID": "visualization_1.html#evaluating-histograms",
    "href": "visualization_1.html#evaluating-histograms",
    "title": "Visualization I",
    "section": "Evaluating Histograms",
    "text": "Evaluating Histograms\nHistograms allow us to assess a distribution by their shape. There are a few properties of histograms we can analyze:\n\nSkewness and Tails\n\nSkewed left vs skewed right\nLeft tail vs right tail\n\nOutliers\n\nDefined arbitrarily for now\n\nModes\n\nMost commonly occuring data\n\n\n\nSkewness and Tails\nIf a distribution has a long right tail (such as Maternal Pregancy Weight), it is skewed right. In a right-skewed distribution, the few large outliers “pull” the mean to the right of the median.\nIf a distribution has a long left tail, it is skewed left. In a left-skewed distribution, the few small outliers “pull” the mean to the left of the median.\nIn the case where a distribution has equal-sized right and left tails, it is symmetric. The mean is approximately equal to the median.\n\n\nOutliers\nLoosely speaking, an outlier is defined as a data point that lies an abnormally large distance away from other values. We’ll define the statistical measure for this shortly.\nOutliers disproportionately influce the mean because their magnitude is directly involved in computing the average. However, the median is largely unaffected - the magnitude of an outlier is irrelevant; we only care that it is some non-zero distance away from the midpoint of the data.\n\n\nModes\nA mode of a distribution is a local or global maximum. A distribution with a single clear maximum is unimodal, distributions with two modes are bimodal, and those with 3 or more are multimodal.\nFor example, the distribution of birth weights for maternal smokers is (weakly) multimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == True]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');\n\n\n\n\nOn the other hand, the distribution of birth weights for maternal non-smokers is unimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');"
  },
  {
    "objectID": "visualization_1.html#box-plots-and-violin-plots",
    "href": "visualization_1.html#box-plots-and-violin-plots",
    "title": "Visualization I",
    "section": "Box Plots and Violin Plots",
    "text": "Box Plots and Violin Plots\n\nBoxplots\nBoxplots are an alternative to histograms that visualize numerical distributions. They are especially useful in graphicaly summarizing several characteristics of a distribution. These include:\n\nLower Quartile (\\(1\\)st Quartile)\nMedian (\\(2\\)nd Quartile)\nUpper Quartile (\\(3\\)rd Quartile)\nInterquartile Range (IQR)\nWhiskers\nOutliers\n\nThe lower quartile, median, and uper quartile are the \\(25\\)th, \\(50\\)th, and \\(75\\)th percentiles of data, respectively. The interquartile range measures the spread of the middle \\(50\\)% of the distribution, calculated as the (\\(3\\)rd Quartile \\(-\\) \\(1\\)st Quartile).\nThe whiskers of a box-plot are the two points that lie at the \\(1\\)st Quartile \\(-\\) (\\(1.5\\) * IQR), and the \\(3\\)rd Quartile \\(+\\) (\\(1.5\\) * IQR). They are the lower and upper ranges of “normal” data (the points excluding outliers). Subsequently, the outliers are the data points that fall beyond the whiskers, or further than (\\(1.5\\) \\(*\\) IQR) from the extreme quartiles.\nLet’s visualize a box-plot of the Birth Weight column.\n\n\nCode\nimport numpy as np\n\nsns.boxplot(data = births, y = \"Birth Weight\");\n\nbweights = births['Birth Weight']\nq1 = np.percentile(bweights, 25)\nq2 = np.percentile(bweights, 50)\nq3 = np.percentile(bweights, 75)\niqr = q3 - q1\nwhisk1 = q1 - (1.5 * iqr)\nwhisk2 = q3 + (1.5 * iqr)\n\nprint(\"The first quartile is {}\".format(q1))\nprint(\"The second quartile is {}\".format(q2))\nprint(\"The third quartile is {}\".format(q3))\nprint(\"The interquartile range is {}\".format(iqr))\nprint(\"The whiskers are {} and {}\".format(whisk1, whisk2))\n\n\nThe first quartile is 108.0\nThe second quartile is 120.0\nThe third quartile is 131.0\nThe interquartile range is 23.0\nThe whiskers are 73.5 and 165.5\n\n\n\n\n\nHere is a helpful visual that summarizes our discussion above.\n\n\n\nViolin Plots\nAnother diagram that is useful in visualizing a variable’s distribution is the violin plot. A violin plot supplements a box-plot with a smoothed density curve on either side of the plot. These density curves highlight the relative frequency of variable’s possible values. If you look closely, you’ll be able to discern the quartiles, whiskers, and other hallmark features of the box-plot.\n\nsns.violinplot(data = births, y = 'Birth Weight');"
  },
  {
    "objectID": "visualization_1.html#comparing-quantitative-distributions",
    "href": "visualization_1.html#comparing-quantitative-distributions",
    "title": "Visualization I",
    "section": "Comparing Quantitative Distributions",
    "text": "Comparing Quantitative Distributions\nEarlier in our discussion of the mode, we visualized two histograms that described the distribution of birth weights for maternal smokers and non-smokers. However, comparing these histograms was difficult because they were displayed on seperate plots. Can we overlay the two to tell a more compelling story?\nIn seaborn, multiple calls to a plotting library in the same code cell will overlay the plots. For example:\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nbirths_non_maternal_smoker = births[births['Maternal Smoker'] == True]\n\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight',\n             color = 'orange', label = 'smoker')\nsns.histplot(data = births_non_maternal_smoker, x= 'Birth Weight',\n             color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nHowever, notice how this diagram suffers from overplotting. We can fix this with a call to sns.kdeplot. This will remove the bins and overlay the histogram with a density curve that better summarizes the distribution.\n\nsns.kdeplot(data = births_maternal_smoker, x= 'Birth Weight', color = 'orange', label = 'smoker')\nsns.kdeplot(data = births_non_maternal_smoker, x= 'Birth Weight', color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nUnfortunately, we lose critical information in our distribution by removing small details. Therefore, we typically prefer to use box-plots and violin plots when comparing distributions. These are more concise and allow us to compare summary statistics across many distributions.\n\nsns.violinplot(data=births, x='Maternal Smoker', y='Birth Weight');\n# The following line of code plots a box-plot\n#sns.boxplot(data=births, x='Maternal Smoker', y='Birth Weight');"
  },
  {
    "objectID": "visualization_1.html#relationships-between-quantitative-variables",
    "href": "visualization_1.html#relationships-between-quantitative-variables",
    "title": "Visualization I",
    "section": "Relationships Between Quantitative Variables",
    "text": "Relationships Between Quantitative Variables\nUp until now, we’ve discussed how to visualize single-variable distributions. Going beyond this, we want to understand the relationship between pairs of numerical variables.\n\nScatter Plots\nScatter plots are one of the most useful tools in representing the relationship between two quantitative variables. They are particularly important in gauging the strength, or correlation between variables. Knowledge of these relationships can then motivate decisions in our modeling process.\nFor example, let’s plot a scatter plot comparing the Maternal Pregnancy Weight and Birth Weight colums, using both matplotlib and seaborn.\n\n# Matplotlib Example\nplt.scatter(births['Maternal Pregnancy Weight'], births['Birth Weight'])\n# For brevity, we have excluded code to label the axes\n\n<matplotlib.collections.PathCollection at 0x7f9c70521730>\n\n\n\n\n\n\n# Seaborn Example\nsns.scatterplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\",\n                hue = \"Maternal Smoker\")\n\n<AxesSubplot: xlabel='Maternal Pregnancy Weight', ylabel='Birth Weight'>\n\n\n\n\n\nThis is an example where color is used to add a third dimension to our plot. This is possible with the hue paramater in seaborn, which adds a categorical column encoding to an existing visualization. This way, we can look for relationships in Maternal Pregnancy Weight and Birth Weight in both maternal smokers and non-smokers. If we wish to see the relationship’s strength more clearly, we can use sns.lmplot.\n\nsns.lmplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\", \n           hue=\"Maternal Smoker\", ci=False);\n\n\n\n\nWe can make out a weak, positive relationship in pregnancy weight and birth weight for both maternal smokers and non-smokers (slightly more positive in maternal smokers).\n\n\nHex Plots and Contour Plots\nUnfortunately, our scatter plots above suffered from overplotting, which made them hard to interpret. And with a large number of points, jittering is unlikely to resolve the issue. Instead, we can look to hex plots and contour plots.\nHex Plots can be thought of as a two dimensional histogram that shows the joint distribution between two variables. This is particularly useful working with very dense data.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'hex')\n\n<seaborn.axisgrid.JointGrid at 0x7f9c85264970>\n\n\n\n\n\nThe axes are evidently binned into hexagons, which makes the linear relationship easier to decipher. Darker regions generally indicate a higher density of points.\nOn the other hand, contour plots are two dimensional versions of density curves with marginal distributions of each variable on the axes. We’ve used very similar code here to generate our contour plots, with the addition of the kind = 'kde' and fill = True arguments.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'kde', fill = True)\n\n<seaborn.axisgrid.JointGrid at 0x7f9c601cd460>"
  },
  {
    "objectID": "visualization_2.html",
    "href": "visualization_2.html",
    "title": "Visualization II",
    "section": "",
    "text": "In the last lecture, we learned that density curves are smooth, continuous functions that represent a distribution of values. In this section, we’ll learn how to construct density curves using Kernel Density Estimation.\n\n\nKernel Density Estimation involves a technique called smoothing - a process applied to a distribution of values that allows us to analyze the more general structure of the dataset.\nMany of the visualizations we learned during the last lecture are examples of this. Histograms are smoothed versions of one-dimensional rug plots, and hex plots are smoother alternatives to two-dimensional scatter plots. They remove the detail from individual observations so we can visualize the patterns in our distribution.\n\n\n\nKernel Density Estimation is a smoothing technique that allows us to estimate a density curve (also known as a probability density function) from a set of observations. There are a few steps in this process:\n\nPlace a kernel at each data point\nNormalize kernels to have total area of 1\nSum kernels together\n\nSuppose we have 5 data points: \\([2.2, 2.8, 3.7, 5.3, 5.7]\\). We wish to recreate the following Kernel Density Estimate:\n\n\nCode\nimport seaborn as sns\n\ndata = [2.2, 2.8, 3.7, 5.3, 5.7]\nsns.kdeplot(data);\n\n\n\n\n\nLet’s walk through each step to construct this density curve.\n\n\nTo begin generating a density curve, we need to choose a kernel and bandwidth value. What are these exactly? A kernel is a density curve itself, and the bandwidth is a measure of the kernel’s width. Recall that a valid density has an area of 1.\nAt each of our 5 points (depicted in the rug plot on the left), we’ve placed a Gaussian kernel with a bandwidth parameter of alpha = 1. We’ll explore what these are in the next section.\n\n\nRugplot of Data\n\n\n\n\nKernelized Data\n\n\n\n\n\n\nNotice how these 5 kernels are density curves - meaning they each have an area of 1. In Step 3, we will be summing each these kernels, and we want the result to be a valid density that has an area of 1. Therefore, it makes sense to normalize our current set of kernels by multiplying each by \\(\\frac{1}{5}\\).\n\n\nKernelized Data\n\n\n\n\nNormalized Kernels\n\n\n\n\n\n\nOur kernel density estimate (KDE) is the vertical sum of the normalized kernels along the x-axis. It is depicted below on the right.\n\n\nNormalized Kernels\n\n\n\n\nKernel Density Estimate\n\n\n\n\n\n\n\n\n\n\nA kernel (for our purposes) is a valid density function. This means it:\n\nMust be non-negative for all inputs.\nMust integrate to 1.\n\n\n\nThe most common kernel is the Gaussian kernel. The Gaussian kernel is equivalent to the Gaussian probability density function (the Normal distribution), centered at the observed value \\(x_i\\) with a standard deviation of \\(\\alpha\\) (this is known as the bandwidth parameter).\n\\(K_a(x, x_i) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}}}e^{-\\frac{(x-x_i)^{2}}{2a^{2}}}\\)$\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt \n\ndef gaussian_kernel(alpha, x, z):\n    return 1.0/np.sqrt(2. * np.pi * alpha**2) * np.exp(-(x - z) ** 2 / (2.0 * alpha**2))\n\nxs = np.linspace(-5, 5, 200)\nalpha = 1\nkde_curve = [gaussian_kernel(alpha, x, 0) for x in xs]\nplt.plot(xs, kde_curve);\n\n\n\n\n\nThe Gaussian kernel centered at 0 with bandwidth \\(\\alpha\\) = 1.\n\n\n\n\nIf you’ve taken a probability class, you’ll recognize that the mean of this Gaussian kernel is \\(x_i\\) and the standard deviation is \\(\\alpha\\). Increasing \\(\\alpha\\) - equivalently, the bandwidth - smoothens the density curve. Larger values of \\(\\alpha\\) are typically easier to understand; however, we begin to lose important distributional information as \\(\\alpha\\) increases.\nHere is how adjusting \\(\\alpha\\) affects a distribution in some variable from an arbitrary dataset.\n\n\nGaussian Kernel, Alpha = 0.1\n\n\n\n\nGaussian Kernel, Alpha = 1\n\n\n\n\n\nGaussian Kernel, Alpha = 2\n\n\n\n\nGaussian Kernel, Alpha = 10\n\n\n\n\n\n\nAnother example of a kernel is the Boxcar kernel. The boxcar kernel assigns a uniform density to points within a “window” of the observation, and a density of 0 elsewhere.\n\\(K_a(x, x_i) = \\begin{cases}  \\frac{1}{\\alpha}, & |x - x_i| \\le \\frac{\\alpha}{2}\\\\  0, & \\text{else }  \\end{cases}\\)\n\n\nCode\ndef boxcar_kernel(alpha, x, z):\n    return (((x-z)>=-alpha/2)&((x-z)<=alpha/2))/alpha\n\nxs = np.linspace(-5, 5, 200)\nalpha=1\nkde_curve = [boxcar_kernel(alpha, x, 0) for x in xs]\nplt.plot(xs, kde_curve);\n\n\n\n\n\nThe Boxcar kernel centered at 0 with bandwidth \\(\\alpha\\) = 1.\n\n\n\n\nThe diagram on the right is how the density curve for our 5 point dataset would have looked had we used the Boxcar kernel with bandwidth \\(\\alpha\\) = 1."
  },
  {
    "objectID": "visualization_2.html#visualization-theory",
    "href": "visualization_2.html#visualization-theory",
    "title": "Visualization II",
    "section": "Visualization Theory",
    "text": "Visualization Theory\nThis section marks a pivot to the second major topic of this lecture - visualization theory. We’ll discuss the abstract nature of visualizations, which will help us make informed decisions to construct them.\nRemember, we had two goals for visualizing data. This section is particularly important in motivating\n\nHelp our understanding of the data and results\nCommunicating our results and conclusions with others\n\n\nInformation Channels\nThere are various channels of information in visualizations - these include encodings, color, and scale, to name a few. In constructing good visuals, we should utilize these channels to convey information that answers our questions.\nFor example, we learned a few ways to picture a distribution: rugplots, KDEs, and histograms. Neither is strictle better than any other; they all convey varying levels of detail, and some may be more advantageous depending on the application.\n\nEncodings in Rugplots\nOne detail that we may have overlooked in our earlier discussion of rugplots is the importance of encodings. Rugplots are effective visuals because they utilize encodings in line thickness to convey frequency. Consider the following diagram:\n\n\n\nMulti-Dimensional Data\nEncodings are useful in representing complex"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "data100-course-notes",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "pandas_1.html#dataframes",
    "href": "pandas_1.html#dataframes",
    "title": "Pandas I",
    "section": "DataFrames",
    "text": "DataFrames\nTabular data is one of the most common data formats used in data science. We’ll primarily be looking at tabular data in Data 100.\nIn Data 8, you encountered the Table class of the datascience library. In Data 100, we’ll be using the DataFrame class of the pandas library to represent tabular data.\nHere is an example of a DataFrame containing election data.\n\nimport pandas as pd\n\nelections = pd.read_csv(\"elections.csv\")\nelections\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n      loss\n      1.073699\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n      win\n      51.311515\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n182 rows × 6 columns\n\n\n\nLet’s dissect the code above.\n\nWe first import the pandas library into our Python environment, using the alias pd.   import pandas as pd\nThere are a number of ways to read data into a DataFrame. In Data 100, our data are typically stored in a CSV (comma-seperated values) file format. We can import a CSV file into a DataFrame by passing the data path as an argument to the following pandas function.   pd.read_csv(\"elections.csv\")\n\nThis code stores our DataFrame object into the elections variable. Upon inspection, our elections DataFrame has 182 rows and 6 columns. Each row represents a single record - in our example, a presedential candidate in some particular year. Each column represents a single attribute, or feature of the record.\nThe API (application programming interface) for the DataFrame class is enormous. In the next section, we’ll discuss several methods of the DataFrame API that allow us to extract subsets of data."
  },
  {
    "objectID": "pandas_1.html#slicing-in-dataframes",
    "href": "pandas_1.html#slicing-in-dataframes",
    "title": "Pandas I",
    "section": "Slicing in DataFrames",
    "text": "Slicing in DataFrames\nOne of the most important tasks in manipulating a DataFrame is extracting a subset of rows and columns. This is called slicing. We can do so using three primary methods of the DataFrame class:\n\n.loc\n.iloc\n[]\n\n\nIndexing with .loc\nThe .loc operator selects rows and columns in a DataFrame by their row and column labels, respectively. The row label (commonly referred to as the index) is the bold text on the far left of a DataFrame, while the column label is the text found at the top of a DataFrame. By default, pandas assigns row labels as sequential integers beginning from 0. The column labels in our elections DataFrame are the columns Year, Candidate, Party, Popular Vote, Result, %.\n.loc lets us specify the row and column labels to select from our DataFrame as the first and second arguments to the function. For example, to select the the row labeled 0 and the column labeled Candidate from our elections DataFrame:\n\nelections.loc[0, 'Candidate']\n\n'Andrew Jackson'\n\n\nTo select multiple rows and columns, we can use Python slice notation. We can select the first four rows and first four columns.\n\nelections.loc[0:3, 'Year':'Popular vote']\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSuppose that instead, we wanted every column value for the first four rows in the elections DataFrame. The shorthand : comes in great use.\n\nelections.loc[0:3, :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\nA couple of things we should note. Unlike conventional Python, Pandas allows us to slice string values (in our example, the column labels). Secondly, slicing in Pandas is inclusive. Notice how our resulting DataFrame includes every row and column between and including the slice labels we specified.\nEquivalently, we can use a list to obtain multiple rows and columns in our elections DataFrame.\n\nelections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nLastly, we can interchange list and slicing notation.\n\nelections.loc[[0, 1, 2, 3], :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nIndexing with .iloc\nSlicing with .iloc works similarily to .loc, although .iloc uses the integer positions of rows and columns rather the labels. The arguments for the .iloc function also behave similarly - single values, lists, indices, and any combination of these are permitted.\nWe can begin reproducing our results from above. Let’s begin by selecting for the first presedential candidate in our elections DataFrame:\n\n# elections.loc[0, \"Candidate\"] - Previous approach\nelections.iloc[0, 1]\n\n'Andrew Jackson'\n\n\nNotice how the first argument to both .loc and .iloc are the same. This is because the row with a label of 0 is conveniently in the 0th (or first) position of the elections DataFrame. Generally, this is true of any DataFrame where the row labels are incremented in ascending order from 0.\nHowever, when we select for the first four rows and columns using .iloc, we notice something.\n\n# elections.loc[0:3, 'Year':'Popular vote'] - Previous approach\nelections.iloc[0:4, 0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSlicing is no longer inclusive in .iloc - it’s exclusive! Sad to say, this is one of Pandas syntatical subtleties. Don’t worry, you’ll get used to with practice.\nList behavior works just as expected.\n\n#elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']] - Previous Approach\nelections.iloc[[0, 1, 2, 3], [0, 1, 2, 3]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nThis discussion begs the question: when should we use .loc vs .iloc? In most cases, .loc is generally safer to use. You can imagine .iloc may return incorrect values when applied to a dataset where the ordering of data can change.\n\n\nIndexing with []\nThe [] selection operator is the most baffling of all, yet the most commonly used. It only takes a single argument, which may be one of the following:\n\nA slice of row numbers\nA list of column labels\nA single column label\n\nThat is, [] is context dependent. Let’s see some examples.\n\nA slice of row numbers\nSay we wanted the first four rows of our elections DataFrame.\n\nelections[0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nA list of column labels\nSuppose we now want the first four columns.\n\nelections[[\"Year\", \"Candidate\", \"Party\", \"Popular vote\"]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n    \n  \n\n182 rows × 4 columns\n\n\n\n\n\nA single column label\nLastly, if we only want the Candidate column.\n\nelections[\"Candidate\"]\n\n0         Andrew Jackson\n1      John Quincy Adams\n2         Andrew Jackson\n3      John Quincy Adams\n4         Andrew Jackson\n             ...        \n177           Jill Stein\n178         Joseph Biden\n179         Donald Trump\n180         Jo Jorgensen\n181       Howard Hawkins\nName: Candidate, Length: 182, dtype: object\n\n\nThe output looks quite different - it’s no longer a DataFrame! This is a Series. We’ll talk about what a Series is in the next section."
  },
  {
    "objectID": "pandas_1.html#dataframes-series-and-indices",
    "href": "pandas_1.html#dataframes-series-and-indices",
    "title": "Pandas I",
    "section": "DataFrames, Series, and Indices",
    "text": "DataFrames, Series, and Indices\nWe saw that selecting a single column from a DataFrame using the [] operator outputted a new data format, called a Series. Let’s verify this claim.\n\ntype(elections)\n\npandas.core.frame.DataFrame\n\n\n\ntype(elections['Candidate'])\n\npandas.core.series.Series\n\n\nA Series is a one dimensional object that represents a single column of data. It has two components - an index and a column of data. A DataFrame is equivalent to a collection of Series, which all share the same index. Notice how the index is equivalent to the DataFrame index (or row labels) we discussed above.\n\nHowever, a DataFrame index doesn’t have to be an integer, nor does it have to be unique. For example, we can set our index to be the name of presedential candidates. Selecting a new Series from this modified DataFrame yields the following:\n\nTo retrieve the indices of a DataFrame, simple use the .index attribute of the DataFrame class.\n\nelections.set_index(\"Candidate\", inplace=True)\nelections.index\n\nIndex(['Andrew Jackson', 'John Quincy Adams', 'Andrew Jackson',\n       'John Quincy Adams', 'Andrew Jackson', 'Henry Clay', 'William Wirt',\n       'Hugh Lawson White', 'Martin Van Buren', 'William Henry Harrison',\n       ...\n       'Darrell Castle', 'Donald Trump', 'Evan McMullin', 'Gary Johnson',\n       'Hillary Clinton', 'Jill Stein', 'Joseph Biden', 'Donald Trump',\n       'Jo Jorgensen', 'Howard Hawkins'],\n      dtype='object', name='Candidate', length=182)\n\n\n\nelections.reset_index(inplace=True)\n\nEarlier, we mentioned that a Series was just a column of data. What if we wanted a single column as a DataFrame? To do so, we can pass in a list containing a single column to the [] selection operator.\n\nelections[[\"Party\"]] # [\"Party\"] is the argument - a list with a single element\n\n\n\n\n\n  \n    \n      \n      Party\n    \n  \n  \n    \n      0\n      Democratic-Republican\n    \n    \n      1\n      Democratic-Republican\n    \n    \n      2\n      Democratic\n    \n    \n      3\n      National Republican\n    \n    \n      4\n      Democratic\n    \n    \n      ...\n      ...\n    \n    \n      177\n      Green\n    \n    \n      178\n      Democratic\n    \n    \n      179\n      Republican\n    \n    \n      180\n      Libertarian\n    \n    \n      181\n      Green\n    \n  \n\n182 rows × 1 columns"
  },
  {
    "objectID": "pandas_1.html#conditional-selection",
    "href": "pandas_1.html#conditional-selection",
    "title": "Pandas I",
    "section": "Conditional Selection",
    "text": "Conditional Selection\nConditional selection allows us to select a subset of rows in a DataFrame if they follow some specified condition.\nTo understand how to use conditional selection, we must look at another input to the .loc and [] operators - a boolean array. This boolean array must have a length equal to the number of rows in the DataFrame. It will then return all rows with a corresponding True value in the array.\nHere, we will select all even-indexed rows in the first 10 rows of our DataFrame.\n\n# Why is :9 is the correct slice to select the first 10 rows?\nelections_first_10_rows = elections.loc[:9, :]\n\n# Notice how we have exactly 10 elements in our boolean array argument\nelections_first_10_rows[[True, False, True, False, True, \\\n                         False, True, False, True, False]]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      4\n      Andrew Jackson\n      1832\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      6\n      William Wirt\n      1832\n      Anti-Masonic\n      100715\n      loss\n      7.821583\n    \n    \n      8\n      Martin Van Buren\n      1836\n      Democratic\n      763291\n      win\n      52.272472\n    \n  \n\n\n\n\n\nSingle Boolean Selection\nUnfortunately, using this method to select multiple rows in a large DataFrame is infeasible. Instead, we can provide a logical condition as an input to .loc or [] that returns a boolean array with said length.\nFor example, to return all candidates affilliated with the Independent party:\n\nlogical_operator = elections['Party'] == \"Independent\"\nelections[logical_operator]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\nHere, logical_operator evaluates to a Series of boolean values with length 182.\n\nlogical_operator\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n177    False\n178    False\n179    False\n180    False\n181    False\nName: Party, Length: 182, dtype: bool\n\n\nRows 121, 130, 143, 161, 167, and 174 evaluate to True and are thus returned in the DataFrame.\n\n\nCode\nprint(logical_operator.loc[[121, 130, 143, 161, 167, 174]])\n\n\n121    True\n130    True\n143    True\n161    True\n167    True\n174    True\nName: Party, dtype: bool\n\n\nPassing a Series as an argument to elections[] has the same affect as using in a boolean array. In fact, the [] selection operator can take a boolean Series, array, and list as arguments. These three are used interchangeably thoughout the course.\nSimilarly, we can use .loc to achieve similar results.\n\nelections.loc[elections['Party'] == \"Independent\"]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\n\n\nMultiple Boolean Selection\nBoolean conditions can be combined using various operators that allow us to filter results by multiple conditions. Some examples include the & (and) operator and | (or) operator.\nNote When using logical operators, pay careful attention to surround each condition with a set of paranthesis (). Doing so will ensure your code doesn’t throw an error.\nFor example, if we want to return data on all presidential candidates affiliated with the Independent Party before the 21st century, we can do so:\n\nelections[(elections['Party'] == \"Independent\") \\\n          & (elections['Year'] < 2000)]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298"
  },
  {
    "objectID": "pandas_1.html#handy-utility-functions",
    "href": "pandas_1.html#handy-utility-functions",
    "title": "Pandas I",
    "section": "Handy Utility Functions",
    "text": "Handy Utility Functions\nThere are a large number of operations supported by pandas Series and DataFrames that allow us to efficiently manipulate data . In this section, we’ll cover a few.\n\n.head and .tail\n.shape and .size\n.describe\n.sample\n.value_counts\n.unique\n.sort_values\n\n\n.head / .tail\n.head(n) and .tail(n) display the first n and last n rows in a DataFrame, respectively.\n\nelections.head(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      John Quincy Adams\n      1824\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n  \n\n\n\n\n\nelections.tail(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      179\n      Donald Trump\n      2020\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      Jo Jorgensen\n      2020\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      Howard Hawkins\n      2020\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n\n\n\n\n\n.shape / .size\n.shape returns a tuple with the number of rows and columns.  .size returns the total number of data cells. This is the product of the number of rows and columns.\n\nelections.shape\n\n(182, 6)\n\n\n\nnum_rows, num_cols = elections.shape\nassert(elections.size == num_rows * num_cols)\nelections.size\n\n1092\n\n\n\n\n.describe\n.describe() returns a DataFrame of useful summary statistics for each numerical column.\n\nelections.describe()\n\n\n\n\n\n  \n    \n      \n      Year\n      Popular vote\n      %\n    \n  \n  \n    \n      count\n      182.000000\n      1.820000e+02\n      182.000000\n    \n    \n      mean\n      1934.087912\n      1.235364e+07\n      27.470350\n    \n    \n      std\n      57.048908\n      1.907715e+07\n      22.968034\n    \n    \n      min\n      1824.000000\n      1.007150e+05\n      0.098088\n    \n    \n      25%\n      1889.000000\n      3.876395e+05\n      1.219996\n    \n    \n      50%\n      1936.000000\n      1.709375e+06\n      37.677893\n    \n    \n      75%\n      1988.000000\n      1.897775e+07\n      48.354977\n    \n    \n      max\n      2020.000000\n      8.126892e+07\n      61.344703\n    \n  \n\n\n\n\n\n\n.sample\n.sample(n) returns a random sample of n items from the given DataFrame.\n\nelections.sample(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      168\n      Barack Obama\n      2012\n      Democratic\n      65915795\n      win\n      51.258484\n    \n    \n      3\n      John Quincy Adams\n      1828\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      15\n      Martin Van Buren\n      1848\n      Free Soil\n      291501\n      loss\n      10.138474\n    \n  \n\n\n\n\n\n\n.value_counts\n.value_counts() is called on a Series and returns a Series containing the count of unique values.\n\nelections['Candidate'].value_counts()\n\nNorman Thomas         5\nRalph Nader           4\nFranklin Roosevelt    4\nEugene V. Debs        4\nGrover Cleveland      3\n                     ..\nMitt Romney           1\nJohn M. Palmer        1\nJohn Kennedy          1\nJo Jorgensen          1\nMillard Fillmore      1\nName: Candidate, Length: 132, dtype: int64\nThis code tells us how many times each candidate ran for president of the United States.\n\n\n\n\n.unique\n.unique() is called on a Series and returns an array with the unique values contained in that Series.\n\n# For brevity, we have limited the results to 5 candidates \nelections['Candidate'].unique()[:5]\n\narray(['Andrew Jackson', 'John Quincy Adams', 'Henry Clay',\n       'William Wirt', 'Hugh Lawson White'], dtype=object)\n\n\n\n\n.sort_values\n.sort_values() returns a sorted Series of values from the Series it was called on. Numerical values are in sorted magnitude, while text is sorted in alphabetical order. You may specify optional arguments to sort in ascending or descending order.\n\nelections['Candidate'].sort_values()\n\n75           Aaron S. Watkins\n27            Abraham Lincoln\n23            Abraham Lincoln\n108           Adlai Stevenson\n105           Adlai Stevenson\n                ...          \n19             Winfield Scott\n37     Winfield Scott Hancock\n74             Woodrow Wilson\n70             Woodrow Wilson\n16             Zachary Taylor\nName: Candidate, Length: 182, dtype: object"
  },
  {
    "objectID": "pandas_1.html#parting-note",
    "href": "pandas_1.html#parting-note",
    "title": "Pandas I",
    "section": "Parting Note",
    "text": "Parting Note\nThe pandas library is enormous and contains many useful functions. Here is a link to documentation.\nThis lecture and the next will cover important methods you should be fluent in. However, we want you to get familiar with the real world programming practice of …Googling! Answers to your questions can be found in documentation, Stack Overflow, etc.\nWith that, let’s move on to Pandas II."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "pandas_1/pandas_1.html#dataframes",
    "href": "pandas_1/pandas_1.html#dataframes",
    "title": "Pandas I",
    "section": "DataFrames",
    "text": "DataFrames\nTabular data is one of the most common data formats used in data science. We’ll primarily be looking at tabular data in Data 100.\nIn Data 8, you encountered the Table class of the datascience library. In Data 100, we’ll be using the DataFrame class of the pandas library to represent tabular data.\nHere is an example of a DataFrame containing election data.\n\nimport pandas as pd\n\nelections = pd.read_csv(\"data/elections.csv\")\nelections\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n      loss\n      1.073699\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n      win\n      51.311515\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n182 rows × 6 columns\n\n\n\nLet’s dissect the code above.\n\nWe first import the pandas library into our Python environment, using the alias pd.   import pandas as pd\nThere are a number of ways to read data into a DataFrame. In Data 100, our data are typically stored in a CSV (comma-seperated values) file format. We can import a CSV file into a DataFrame by passing the data path as an argument to the following pandas function.   pd.read_csv(\"elections.csv\")\n\nThis code stores our DataFrame object into the elections variable. Upon inspection, our elections DataFrame has 182 rows and 6 columns. Each row represents a single record - in our example, a presedential candidate in some particular year. Each column represents a single attribute, or feature of the record.\nThe API (application programming interface) for the DataFrame class is enormous. In the next section, we’ll discuss several methods of the DataFrame API that allow us to extract subsets of data."
  },
  {
    "objectID": "pandas_1/pandas_1.html#slicing-in-dataframes",
    "href": "pandas_1/pandas_1.html#slicing-in-dataframes",
    "title": "Pandas I",
    "section": "Slicing in DataFrames",
    "text": "Slicing in DataFrames\nOne of the most important tasks in manipulating a DataFrame is extracting a subset of rows and columns. This is called slicing. We can do so using three primary methods of the DataFrame class:\n\n.loc\n.iloc\n[]\n\n\nIndexing with .loc\nThe .loc operator selects rows and columns in a DataFrame by their row and column labels, respectively. The row label (commonly referred to as the index) is the bold text on the far left of a DataFrame, while the column label is the text found at the top of a DataFrame. By default, pandas assigns row labels as sequential integers beginning from 0. The column labels in our elections DataFrame are the columns Year, Candidate, Party, Popular Vote, Result, %.\n.loc lets us specify the row and column labels to select from our DataFrame as the first and second arguments to the function. For example, to select the the row labeled 0 and the column labeled Candidate from our elections DataFrame:\n\nelections.loc[0, 'Candidate']\n\n'Andrew Jackson'\n\n\nTo select multiple rows and columns, we can use Python slice notation. We can select the first four rows and first four columns.\n\nelections.loc[0:3, 'Year':'Popular vote']\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSuppose that instead, we wanted every column value for the first four rows in the elections DataFrame. The shorthand : comes in great use.\n\nelections.loc[0:3, :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\nA couple of things we should note. Unlike conventional Python, Pandas allows us to slice string values (in our example, the column labels). Secondly, slicing in Pandas is inclusive. Notice how our resulting DataFrame includes every row and column between and including the slice labels we specified.\nEquivalently, we can use a list to obtain multiple rows and columns in our elections DataFrame.\n\nelections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nLastly, we can interchange list and slicing notation.\n\nelections.loc[[0, 1, 2, 3], :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nIndexing with .iloc\nSlicing with .iloc works similarily to .loc, although .iloc uses the integer positions of rows and columns rather the labels. The arguments for the .iloc function also behave similarly - single values, lists, indices, and any combination of these are permitted.\nWe can begin reproducing our results from above. Let’s begin by selecting for the first presedential candidate in our elections DataFrame:\n\n# elections.loc[0, \"Candidate\"] - Previous approach\nelections.iloc[0, 1]\n\n'Andrew Jackson'\n\n\nNotice how the first argument to both .loc and .iloc are the same. This is because the row with a label of 0 is conveniently in the 0th (or first) position of the elections DataFrame. Generally, this is true of any DataFrame where the row labels are incremented in ascending order from 0.\nHowever, when we select for the first four rows and columns using .iloc, we notice something.\n\n# elections.loc[0:3, 'Year':'Popular vote'] - Previous approach\nelections.iloc[0:4, 0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSlicing is no longer inclusive in .iloc - it’s exclusive! Sad to say, this is one of Pandas syntatical subtleties. Don’t worry, you’ll get used to with practice.\nList behavior works just as expected.\n\n#elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']] - Previous Approach\nelections.iloc[[0, 1, 2, 3], [0, 1, 2, 3]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nThis discussion begs the question: when should we use .loc vs .iloc? In most cases, .loc is generally safer to use. You can imagine .iloc may return incorrect values when applied to a dataset where the ordering of data can change.\n\n\nIndexing with []\nThe [] selection operator is the most baffling of all, yet the most commonly used. It only takes a single argument, which may be one of the following:\n\nA slice of row numbers\nA list of column labels\nA single column label\n\nThat is, [] is context dependent. Let’s see some examples.\n\nA slice of row numbers\nSay we wanted the first four rows of our elections DataFrame.\n\nelections[0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nA list of column labels\nSuppose we now want the first four columns.\n\nelections[[\"Year\", \"Candidate\", \"Party\", \"Popular vote\"]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n    \n  \n\n182 rows × 4 columns\n\n\n\n\n\nA single column label\nLastly, if we only want the Candidate column.\n\nelections[\"Candidate\"]\n\n0         Andrew Jackson\n1      John Quincy Adams\n2         Andrew Jackson\n3      John Quincy Adams\n4         Andrew Jackson\n             ...        \n177           Jill Stein\n178         Joseph Biden\n179         Donald Trump\n180         Jo Jorgensen\n181       Howard Hawkins\nName: Candidate, Length: 182, dtype: object\n\n\nThe output looks quite different - it’s no longer a DataFrame! This is a Series. We’ll talk about what a Series is in the next section."
  },
  {
    "objectID": "pandas_1/pandas_1.html#dataframes-series-and-indices",
    "href": "pandas_1/pandas_1.html#dataframes-series-and-indices",
    "title": "Pandas I",
    "section": "DataFrames, Series, and Indices",
    "text": "DataFrames, Series, and Indices\nWe saw that selecting a single column from a DataFrame using the [] operator outputted a new data format, called a Series. Let’s verify this claim.\n\ntype(elections)\n\npandas.core.frame.DataFrame\n\n\n\ntype(elections['Candidate'])\n\npandas.core.series.Series\n\n\nA Series is a one dimensional object that represents a single column of data. It has two components - an index and a column of data. A DataFrame is equivalent to a collection of Series, which all share the same index. Notice how the index is equivalent to the DataFrame index (or row labels) we discussed above.\n\nHowever, a DataFrame index doesn’t have to be an integer, nor does it have to be unique. For example, we can set our index to be the name of presedential candidates. Selecting a new Series from this modified DataFrame yields the following:\n\nTo retrieve the indices of a DataFrame, simple use the .index attribute of the DataFrame class.\n\nelections.set_index(\"Candidate\", inplace=True)\nelections.index\n\nIndex(['Andrew Jackson', 'John Quincy Adams', 'Andrew Jackson',\n       'John Quincy Adams', 'Andrew Jackson', 'Henry Clay', 'William Wirt',\n       'Hugh Lawson White', 'Martin Van Buren', 'William Henry Harrison',\n       ...\n       'Darrell Castle', 'Donald Trump', 'Evan McMullin', 'Gary Johnson',\n       'Hillary Clinton', 'Jill Stein', 'Joseph Biden', 'Donald Trump',\n       'Jo Jorgensen', 'Howard Hawkins'],\n      dtype='object', name='Candidate', length=182)\n\n\n\nelections.reset_index(inplace=True)\n\nEarlier, we mentioned that a Series was just a column of data. What if we wanted a single column as a DataFrame? To do so, we can pass in a list containing a single column to the [] selection operator.\n\nelections[[\"Party\"]] # [\"Party\"] is the argument - a list with a single element\n\n\n\n\n\n  \n    \n      \n      Party\n    \n  \n  \n    \n      0\n      Democratic-Republican\n    \n    \n      1\n      Democratic-Republican\n    \n    \n      2\n      Democratic\n    \n    \n      3\n      National Republican\n    \n    \n      4\n      Democratic\n    \n    \n      ...\n      ...\n    \n    \n      177\n      Green\n    \n    \n      178\n      Democratic\n    \n    \n      179\n      Republican\n    \n    \n      180\n      Libertarian\n    \n    \n      181\n      Green\n    \n  \n\n182 rows × 1 columns"
  },
  {
    "objectID": "pandas_1/pandas_1.html#conditional-selection",
    "href": "pandas_1/pandas_1.html#conditional-selection",
    "title": "Pandas I",
    "section": "Conditional Selection",
    "text": "Conditional Selection\nConditional selection allows us to select a subset of rows in a DataFrame if they follow some specified condition.\nTo understand how to use conditional selection, we must look at another input to the .loc and [] operators - a boolean array. This boolean array must have a length equal to the number of rows in the DataFrame. It will then return all rows with a corresponding True value in the array.\nHere, we will select all even-indexed rows in the first 10 rows of our DataFrame.\n\n# Why is :9 is the correct slice to select the first 10 rows?\nelections_first_10_rows = elections.loc[:9, :]\n\n# Notice how we have exactly 10 elements in our boolean array argument\nelections_first_10_rows[[True, False, True, False, True, \\\n                         False, True, False, True, False]]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      4\n      Andrew Jackson\n      1832\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      6\n      William Wirt\n      1832\n      Anti-Masonic\n      100715\n      loss\n      7.821583\n    \n    \n      8\n      Martin Van Buren\n      1836\n      Democratic\n      763291\n      win\n      52.272472\n    \n  \n\n\n\n\n\nSingle Boolean Selection\nUnfortunately, using this method to select multiple rows in a large DataFrame is infeasible. Instead, we can provide a logical condition as an input to .loc or [] that returns a boolean array with said length.\nFor example, to return all candidates affilliated with the Independent party:\n\nlogical_operator = elections['Party'] == \"Independent\"\nelections[logical_operator]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\nHere, logical_operator evaluates to a Series of boolean values with length 182.\n\nlogical_operator\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n177    False\n178    False\n179    False\n180    False\n181    False\nName: Party, Length: 182, dtype: bool\n\n\nRows 121, 130, 143, 161, 167, and 174 evaluate to True and are thus returned in the DataFrame.\n\n\nCode\nprint(logical_operator.loc[[121, 130, 143, 161, 167, 174]])\n\n\n121    True\n130    True\n143    True\n161    True\n167    True\n174    True\nName: Party, dtype: bool\n\n\nPassing a Series as an argument to elections[] has the same affect as using in a boolean array. In fact, the [] selection operator can take a boolean Series, array, and list as arguments. These three are used interchangeably thoughout the course.\nSimilarly, we can use .loc to achieve similar results.\n\nelections.loc[elections['Party'] == \"Independent\"]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\n\n\nMultiple Boolean Selection\nBoolean conditions can be combined using various operators that allow us to filter results by multiple conditions. Some examples include the & (and) operator and | (or) operator.\nNote When using logical operators, pay careful attention to surround each condition with a set of paranthesis (). Doing so will ensure your code doesn’t throw an error.\nFor example, if we want to return data on all presidential candidates affiliated with the Independent Party before the 21st century, we can do so:\n\nelections[(elections['Party'] == \"Independent\") \\\n          & (elections['Year'] < 2000)]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298"
  },
  {
    "objectID": "pandas_1/pandas_1.html#handy-utility-functions",
    "href": "pandas_1/pandas_1.html#handy-utility-functions",
    "title": "Pandas I",
    "section": "Handy Utility Functions",
    "text": "Handy Utility Functions\nThere are a large number of operations supported by pandas Series and DataFrames that allow us to efficiently manipulate data . In this section, we’ll cover a few.\n\n.head and .tail\n.shape and .size\n.describe\n.sample\n.value_counts\n.unique\n.sort_values\n\n\n.head / .tail\n.head(n) and .tail(n) display the first n and last n rows in a DataFrame, respectively.\n\nelections.head(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      John Quincy Adams\n      1824\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n  \n\n\n\n\n\nelections.tail(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      179\n      Donald Trump\n      2020\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      Jo Jorgensen\n      2020\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      Howard Hawkins\n      2020\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n\n\n\n\n\n.shape / .size\n.shape returns a tuple with the number of rows and columns.  .size returns the total number of data cells. This is the product of the number of rows and columns.\n\nelections.shape\n\n(182, 6)\n\n\n\nnum_rows, num_cols = elections.shape\nassert(elections.size == num_rows * num_cols)\nelections.size\n\n1092\n\n\n\n\n.describe\n.describe() returns a DataFrame of useful summary statistics for each numerical column.\n\nelections.describe()\n\n\n\n\n\n  \n    \n      \n      Year\n      Popular vote\n      %\n    \n  \n  \n    \n      count\n      182.000000\n      1.820000e+02\n      182.000000\n    \n    \n      mean\n      1934.087912\n      1.235364e+07\n      27.470350\n    \n    \n      std\n      57.048908\n      1.907715e+07\n      22.968034\n    \n    \n      min\n      1824.000000\n      1.007150e+05\n      0.098088\n    \n    \n      25%\n      1889.000000\n      3.876395e+05\n      1.219996\n    \n    \n      50%\n      1936.000000\n      1.709375e+06\n      37.677893\n    \n    \n      75%\n      1988.000000\n      1.897775e+07\n      48.354977\n    \n    \n      max\n      2020.000000\n      8.126892e+07\n      61.344703\n    \n  \n\n\n\n\n\n\n.sample\n.sample(n) returns a random sample of n items from the given DataFrame.\n\nelections.sample(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      73\n      Frank Hanly\n      1916\n      Prohibition\n      221302\n      loss\n      1.197041\n    \n    \n      164\n      Chuck Baldwin\n      2008\n      Constitution\n      199750\n      loss\n      0.152398\n    \n    \n      52\n      William Jennings Bryan\n      1896\n      Democratic\n      6509052\n      loss\n      46.871053\n    \n  \n\n\n\n\n\n\n.value_counts\n.value_counts() is called on a Series and returns a Series containing the count of unique values.\n\nelections['Candidate'].value_counts()\n\nNorman Thomas         5\nRalph Nader           4\nFranklin Roosevelt    4\nEugene V. Debs        4\nGrover Cleveland      3\n                     ..\nGeorge Wallace        1\nWinfield Scott        1\nAndre Marrou          1\nHoward Hawkins        1\nLewis Cass            1\nName: Candidate, Length: 132, dtype: int64\nThis code tells us how many times each candidate ran for president of the United States.\n\n\n\n\n.unique\n.unique() is called on a Series and returns an array with the unique values contained in that Series.\n\n# For brevity, we have limited the results to 5 candidates \nelections['Candidate'].unique()[:5]\n\narray(['Andrew Jackson', 'John Quincy Adams', 'Henry Clay',\n       'William Wirt', 'Hugh Lawson White'], dtype=object)\n\n\n\n\n.sort_values\n.sort_values() returns a sorted Series of values from the Series it was called on. Numerical values are in sorted magnitude, while text is sorted in alphabetical order. You may specify optional arguments to sort in ascending or descending order.\n\nelections['Candidate'].sort_values()\n\n75           Aaron S. Watkins\n27            Abraham Lincoln\n23            Abraham Lincoln\n108           Adlai Stevenson\n105           Adlai Stevenson\n                ...          \n19             Winfield Scott\n37     Winfield Scott Hancock\n74             Woodrow Wilson\n70             Woodrow Wilson\n16             Zachary Taylor\nName: Candidate, Length: 182, dtype: object"
  },
  {
    "objectID": "pandas_1/pandas_1.html#parting-note",
    "href": "pandas_1/pandas_1.html#parting-note",
    "title": "Pandas I",
    "section": "Parting Note",
    "text": "Parting Note\nThe pandas library is enormous and contains many useful functions. Here is a link to documentation.\nThis lecture and the next will cover important methods you should be fluent in. However, we want you to get familiar with the real world programming practice of …Googling! Answers to your questions can be found in documentation, Stack Overflow, etc.\nWith that, let’s move on to Pandas II."
  },
  {
    "objectID": "visualization_1/visualization_1.html",
    "href": "visualization_1/visualization_1.html",
    "title": "Visualization I",
    "section": "",
    "text": "In our journey of the data science lifecycle, we have begun to explore the vast world of exploratory data analysis. More recently, we learned how to pre-process data using feature engineering and data manipulation techniques. As we work towards designing complex models, there is one key component missing in our arsenal - the ability to visualize and discern relationships in existing data.\nThese next two lectures will introduce you to various examples of data visualizations and their underlying theory. In doing so, we’ll motivate their usefulness in real-world examples with helpful plotting libraries.\n\nVisualizations in Data 8 and Data 100 (so far)\nYou’ve likely encountered several forms of data visualizations in your studies. You may remember two such examples from Data 8: line charts and histograms. Each of these served a unique purpose. For example, line charts displayed how numerical quantities changed over time, while histograms were useful in understanding a variable’s distribution.\n\n\nLine Chart\n\n\n\n\nHistogram\n\n\n\n\n\nGoals of Visualization\nVisualizations are useful for a number of reasons. In Data 100, we consider two areas in particular:\n\nTo broaden your understanding of the data\n\nKey part in exploratory data analysis\nUseful in investigating relationships between variables\n\nTo communicate your results to others\n\nVisualization theory is especially important here\n\n\nOne of the most common applications of visualizations - and the one that will be covered today - is in understanding a distribution of data.\n\n\nAn Overview of Distributions\nA distribution describes the frequency of unique values in a variable. Distributions must satisfy two properties:\n\nEach data point must belong to only one category.\nThe total frequency of all categories must sum to 100%. In other words, their total count should equal the number of values in consideration.\n\nLet’s look at a couple of examples.\n\n\nNot a Valid Distribution\n\n\n\n\nValid Distribution\n\n\n\nLeft Diagram: This is not a valid distribution. Individuals can belong to more than one category and the total frequency of all categories does not sum up to 100%.\nRight Diagram: This example satisfies the two properties of distributions, so it is a valid distribution.\n\n\nBar Plots\nAs we saw above, bar plots are one of the most common ways of displaying the distribution of a qualitative (categorical) variable. The length of a bar plot encodes the frequency of a category; the width encodes no useful information.\nLet’s contextualize this in an example. We will use the familiar births dataset from Data 8 in our analysis.\n\n\nCode\nimport pandas as pd\n\nbirths = pd.read_csv(\"data/baby.csv\")\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nWe can visualize the distribution of the Maternal Smoker column using a bar plot. There are a few ways to do this.\n\nPlotting in Pandas\n\nbirths['Maternal Smoker'].value_counts().plot(kind = 'bar');\n\n\n\n\nRecall that .value_counts() returns a Series with the total count of each unique value. We call .plot(kind = 'bar') on this result to visualize these counts as a bar plot.\nPlotting methods in pandas are the least preferred and not supported in Data 100, as their functionality is limited. Instead, future examples will focus on other libaries built specifically for visualizing data. The most well-known library here is matplotlib.\n\n\nPlotting in Matplotlib\n\nimport matplotlib.pyplot as plt\n\nms = births['Maternal Smoker'].value_counts()\nplt.bar(ms.index, ms)\nplt.xlabel(\"Maternal Smoker\")\nplt.ylabel(\"Count\");\n\n\n\n\nWhile more code is required to achieve the same result, matplotlib is often used over pandas for its ability to plot more complex visualizations, some of which are discussed shortly.\nHowever, notice how the x-axis is a range of integers rather than the two categories, True and False. This is because matplotlib coerces True to a value of 1 and False to 0. Also, note how we needed to label the axes with plt.xlabel and plt.ylabel - matplotlib does not support automatic axis labeling. To get around these inconveniences, we can use a more effecient plotting library, seaborn.\n\n\nPlotting in Seaborn\n\nimport seaborn as sns\nsns.countplot(data = births, x = \"Maternal Smoker\");\n\n\n\n\nseaborn.countplot both counts and visualizes the number of unique values in a given column. This column is specified by the x argument to sns.countplot, while the DataFrame is specified by the data argument.\nFor the vast majority of visualizations, seaborn is far more concise and aesthetically pleasing than matplotlib. However, the color scheme of this particular bar plot is abritrary - it encodes no additional information about the categories themselves. This is not always true; color may signify meaningful detail in other visualizations. We’ll explore this more in-depth during the next lecture.\n\n\nPlotting in Plotly\n\nplotly is one of the most versatile plottling libraries and widely used in industry. However, plotly has various dependencies that make it difficult to support in Data 100. Therfore, we have intentionally excluded the code to generate the plot above.\nBy now, you’ll have noticed that each of these plotting libraries have a very different syntax. As with pandas, we’ll teach you the important methods in matplotlib and seaborn, but you’ll learn more through documentation.\n\nMatplotlib Documentation\nSeaborn Documentation\n\n\n\n\nHistograms\nHistograms are a natural extension to bar plots; they visualize the distribution of quantitative (numerical) data.\nRevisiting our example with the births DataFrame, let’s plot the distribution of the Maternal Pregnancy Weight column.\n\n\nCode\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nHow should we define our categories for this variable? In the previous example, these were the unique values of the Maternal Smoker column: True and False. If we use similar logic here, our categories are the different numerical weights contained in the Maternal Pregnancy Weight column.\nUnder this assumption, let’s plot this distribution using the seaborn.countplot function.\n\nsns.countplot(data = births, x = 'Maternal Pregnancy Weight');\n\n\n\n\nThis histogram clearly suffers from overplotting. This is somewhat expected for Maternal Pregnancy Weight - it is a quantitative variable that takes on a wide range of values.\nTo combat this problem, statisticians use bins to categorize numerical data. Luckily, seaborn provides a helpful plotting function that automatically bins our data.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\n\n\n\n\nThis diagram is known as a histogram. While it looks more reasonable, notice how we lose fine-grain information on the distribution of data contained within each bin. We can introduce rug plots to minimize this information loss. An overlaid “rug plot” displays the within-bin distribution of our data, as denoted by the thickness of the colored line on the x-axis.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');\n\n\n\n\nYou may have seen histograms drawn differently - perhaps with an overlaid density curve and normalized y-axis. We can display both with a few tweaks to our code.\nTo visualize a density curve, we can set the the kde = True argument of the sns.histplot. Setting the argument stat = \"density\" normalizes our histogram and displays densities, instead of counts, on the y-axis. You’ll notice that the area under the density curve is 1.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\", kde = True, \n             stat = \"density\")\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');\n\n\n\n\n\n\nEvaluating Histograms\nHistograms allow us to assess a distribution by their shape. There are a few properties of histograms we can analyze:\n\nSkewness and Tails\n\nSkewed left vs skewed right\nLeft tail vs right tail\n\nOutliers\n\nDefined arbitrarily for now\n\nModes\n\nMost commonly occuring data\n\n\n\nSkewness and Tails\nIf a distribution has a long right tail (such as Maternal Pregancy Weight), it is skewed right. In a right-skewed distribution, the few large outliers “pull” the mean to the right of the median.\nIf a distribution has a long left tail, it is skewed left. In a left-skewed distribution, the few small outliers “pull” the mean to the left of the median.\nIn the case where a distribution has equal-sized right and left tails, it is symmetric. The mean is approximately equal to the median.\n\n\nOutliers\nLoosely speaking, an outlier is defined as a data point that lies an abnormally large distance away from other values. We’ll define the statistical measure for this shortly.\nOutliers disproportionately influce the mean because their magnitude is directly involved in computing the average. However, the median is largely unaffected - the magnitude of an outlier is irrelevant; we only care that it is some non-zero distance away from the midpoint of the data.\n\n\nModes\nA mode of a distribution is a local or global maximum. A distribution with a single clear maximum is unimodal, distributions with two modes are bimodal, and those with 3 or more are multimodal.\nFor example, the distribution of birth weights for maternal smokers is (weakly) multimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == True]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');\n\n\n\n\nOn the other hand, the distribution of birth weights for maternal non-smokers is unimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');\n\n\n\n\n\n\n\nBox Plots and Violin Plots\n\nBoxplots\nBoxplots are an alternative to histograms that visualize numerical distributions. They are especially useful in graphicaly summarizing several characteristics of a distribution. These include:\n\nLower Quartile (\\(1\\)st Quartile)\nMedian (\\(2\\)nd Quartile)\nUpper Quartile (\\(3\\)rd Quartile)\nInterquartile Range (IQR)\nWhiskers\nOutliers\n\nThe lower quartile, median, and uper quartile are the \\(25\\)th, \\(50\\)th, and \\(75\\)th percentiles of data, respectively. The interquartile range measures the spread of the middle \\(50\\)% of the distribution, calculated as the (\\(3\\)rd Quartile \\(-\\) \\(1\\)st Quartile).\nThe whiskers of a box-plot are the two points that lie at the \\(1\\)st Quartile \\(-\\) (\\(1.5\\) * IQR), and the \\(3\\)rd Quartile \\(+\\) (\\(1.5\\) * IQR). They are the lower and upper ranges of “normal” data (the points excluding outliers). Subsequently, the outliers are the data points that fall beyond the whiskers, or further than (\\(1.5\\) \\(*\\) IQR) from the extreme quartiles.\nLet’s visualize a box-plot of the Birth Weight column.\n\n\nCode\nimport numpy as np\n\nsns.boxplot(data = births, y = \"Birth Weight\");\n\nbweights = births['Birth Weight']\nq1 = np.percentile(bweights, 25)\nq2 = np.percentile(bweights, 50)\nq3 = np.percentile(bweights, 75)\niqr = q3 - q1\nwhisk1 = q1 - (1.5 * iqr)\nwhisk2 = q3 + (1.5 * iqr)\n\nprint(\"The first quartile is {}\".format(q1))\nprint(\"The second quartile is {}\".format(q2))\nprint(\"The third quartile is {}\".format(q3))\nprint(\"The interquartile range is {}\".format(iqr))\nprint(\"The whiskers are {} and {}\".format(whisk1, whisk2))\n\n\nThe first quartile is 108.0\nThe second quartile is 120.0\nThe third quartile is 131.0\nThe interquartile range is 23.0\nThe whiskers are 73.5 and 165.5\n\n\n\n\n\nHere is a helpful visual that summarizes our discussion above.\n\n\n\nViolin Plots\nAnother diagram that is useful in visualizing a variable’s distribution is the violin plot. A violin plot supplements a box-plot with a smoothed density curve on either side of the plot. These density curves highlight the relative frequency of variable’s possible values. If you look closely, you’ll be able to discern the quartiles, whiskers, and other hallmark features of the box-plot.\n\nsns.violinplot(data = births, y = 'Birth Weight');\n\n\n\n\n\n\n\nComparing Quantitative Distributions\nEarlier in our discussion of the mode, we visualized two histograms that described the distribution of birth weights for maternal smokers and non-smokers. However, comparing these histograms was difficult because they were displayed on seperate plots. Can we overlay the two to tell a more compelling story?\nIn seaborn, multiple calls to a plotting library in the same code cell will overlay the plots. For example:\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nbirths_non_maternal_smoker = births[births['Maternal Smoker'] == True]\n\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight',\n             color = 'orange', label = 'smoker')\nsns.histplot(data = births_non_maternal_smoker, x= 'Birth Weight',\n             color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nHowever, notice how this diagram suffers from overplotting. We can fix this with a call to sns.kdeplot. This will remove the bins and overlay the histogram with a density curve that better summarizes the distribution.\n\nsns.kdeplot(data = births_maternal_smoker, x= 'Birth Weight', color = 'orange', label = 'smoker')\nsns.kdeplot(data = births_non_maternal_smoker, x= 'Birth Weight', color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nUnfortunately, we lose critical information in our distribution by removing small details. Therefore, we typically prefer to use box-plots and violin plots when comparing distributions. These are more concise and allow us to compare summary statistics across many distributions.\n\nsns.violinplot(data=births, x='Maternal Smoker', y='Birth Weight');\n# The following line of code plots a box-plot\n#sns.boxplot(data=births, x='Maternal Smoker', y='Birth Weight');\n\n\n\n\n\n\nRelationships Between Quantitative Variables\nUp until now, we’ve discussed how to visualize single-variable distributions. Going beyond this, we want to understand the relationship between pairs of numerical variables.\n\nScatter Plots\nScatter plots are one of the most useful tools in representing the relationship between two quantitative variables. They are particularly important in gauging the strength, or correlation between variables. Knowledge of these relationships can then motivate decisions in our modeling process.\nFor example, let’s plot a scatter plot comparing the Maternal Pregnancy Weight and Birth Weight colums, using both matplotlib and seaborn.\n\n# Matplotlib Example\nplt.scatter(births['Maternal Pregnancy Weight'], births['Birth Weight'])\n# For brevity, we have excluded code to label the axes\n\n<matplotlib.collections.PathCollection at 0x7ff7c3c21bb0>\n\n\n\n\n\n\n# Seaborn Example\nsns.scatterplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\",\n                hue = \"Maternal Smoker\")\n\n<AxesSubplot: xlabel='Maternal Pregnancy Weight', ylabel='Birth Weight'>\n\n\n\n\n\nThis is an example where color is used to add a third dimension to our plot. This is possible with the hue paramater in seaborn, which adds a categorical column encoding to an existing visualization. This way, we can look for relationships in Maternal Pregnancy Weight and Birth Weight in both maternal smokers and non-smokers. If we wish to see the relationship’s strength more clearly, we can use sns.lmplot.\n\nsns.lmplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\", \n           hue=\"Maternal Smoker\", ci=False);\n\n\n\n\nWe can make out a weak, positive relationship in pregnancy weight and birth weight for both maternal smokers and non-smokers (slightly more positive in maternal smokers).\n\n\nHex Plots and Contour Plots\nUnfortunately, our scatter plots above suffered from overplotting, which made them hard to interpret. And with a large number of points, jittering is unlikely to resolve the issue. Instead, we can look to hex plots and contour plots.\nHex Plots can be thought of as a two dimensional histogram that shows the joint distribution between two variables. This is particularly useful working with very dense data.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'hex')\n\n<seaborn.axisgrid.JointGrid at 0x7ff7c3c87f70>\n\n\n\n\n\nThe axes are evidently binned into hexagons, which makes the linear relationship easier to decipher. Darker regions generally indicate a higher density of points.\nOn the other hand, contour plots are two dimensional versions of density curves with marginal distributions of each variable on the axes. We’ve used very similar code here to generate our contour plots, with the addition of the kind = 'kde' and fill = True arguments.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'kde', fill = True)\n\n<seaborn.axisgrid.JointGrid at 0x7ff7c42a3040>"
  },
  {
    "objectID": "visualization_1/visualization_1.html#visualizations-in-data-8-and-data-100-so-far",
    "href": "visualization_1/visualization_1.html#visualizations-in-data-8-and-data-100-so-far",
    "title": "Visualization I",
    "section": "Visualizations in Data 8 and Data 100 (so far)",
    "text": "Visualizations in Data 8 and Data 100 (so far)\nYou’ve likely encountered several forms of data visualizations in your studies. You may remember two such examples from Data 8: line charts and histograms. Each of these served a unique purpose. For example, line charts displayed how numerical quantities changed over time, while histograms were useful in understanding a variable’s distribution.\n\n\nLine Chart\n\n\n\n\nHistogram"
  },
  {
    "objectID": "visualization_1/visualization_1.html#goals-of-visualization",
    "href": "visualization_1/visualization_1.html#goals-of-visualization",
    "title": "Visualization I",
    "section": "Goals of Visualization",
    "text": "Goals of Visualization\nVisualizations are useful for a number of reasons. In Data 100, we consider two areas in particular:\n\nTo broaden your understanding of the data\n\nKey part in exploratory data analysis\nUseful in investigating relationships between variables\n\nTo communicate your results to others\n\nVisualization theory is especially important here\n\n\nOne of the most common applications of visualizations - and the one that will be covered today - is in understanding a distribution of data."
  },
  {
    "objectID": "visualization_1/visualization_1.html#an-overview-of-distributions",
    "href": "visualization_1/visualization_1.html#an-overview-of-distributions",
    "title": "Visualization I",
    "section": "An Overview of Distributions",
    "text": "An Overview of Distributions\nA distribution describes the frequency of unique values in a variable. Distributions must satisfy two properties:\n\nEach data point must belong to only one category.\nThe total frequency of all categories must sum to 100%. In other words, their total count should equal the number of values in consideration.\n\nLet’s look at a couple of examples.\n\n\nNot a Valid Distribution\n\n\n\n\nValid Distribution\n\n\n\nLeft Diagram: This is not a valid distribution. Individuals can belong to more than one category and the total frequency of all categories does not sum up to 100%.\nRight Diagram: This example satisfies the two properties of distributions, so it is a valid distribution."
  },
  {
    "objectID": "visualization_1/visualization_1.html#bar-plots",
    "href": "visualization_1/visualization_1.html#bar-plots",
    "title": "Visualization I",
    "section": "Bar Plots",
    "text": "Bar Plots\nAs we saw above, bar plots are one of the most common ways of displaying the distribution of a qualitative (categorical) variable. The length of a bar plot encodes the frequency of a category; the width encodes no useful information.\nLet’s contextualize this in an example. We will use the familiar births dataset from Data 8 in our analysis.\n\n\nCode\nimport pandas as pd\n\nbirths = pd.read_csv(\"data/baby.csv\")\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nWe can visualize the distribution of the Maternal Smoker column using a bar plot. There are a few ways to do this.\n\nPlotting in Pandas\n\nbirths['Maternal Smoker'].value_counts().plot(kind = 'bar');\n\n\n\n\nRecall that .value_counts() returns a Series with the total count of each unique value. We call .plot(kind = 'bar') on this result to visualize these counts as a bar plot.\nPlotting methods in pandas are the least preferred and not supported in Data 100, as their functionality is limited. Instead, future examples will focus on other libaries built specifically for visualizing data. The most well-known library here is matplotlib.\n\n\nPlotting in Matplotlib\n\nimport matplotlib.pyplot as plt\n\nms = births['Maternal Smoker'].value_counts()\nplt.bar(ms.index, ms)\nplt.xlabel(\"Maternal Smoker\")\nplt.ylabel(\"Count\");\n\n\n\n\nWhile more code is required to achieve the same result, matplotlib is often used over pandas for its ability to plot more complex visualizations, some of which are discussed shortly.\nHowever, notice how the x-axis is a range of integers rather than the two categories, True and False. This is because matplotlib coerces True to a value of 1 and False to 0. Also, note how we needed to label the axes with plt.xlabel and plt.ylabel - matplotlib does not support automatic axis labeling. To get around these inconveniences, we can use a more effecient plotting library, seaborn.\n\n\nPlotting in Seaborn\n\nimport seaborn as sns\nsns.countplot(data = births, x = \"Maternal Smoker\");\n\n\n\n\nseaborn.countplot both counts and visualizes the number of unique values in a given column. This column is specified by the x argument to sns.countplot, while the DataFrame is specified by the data argument.\nFor the vast majority of visualizations, seaborn is far more concise and aesthetically pleasing than matplotlib. However, the color scheme of this particular bar plot is abritrary - it encodes no additional information about the categories themselves. This is not always true; color may signify meaningful detail in other visualizations. We’ll explore this more in-depth during the next lecture.\n\n\nPlotting in Plotly\n\nplotly is one of the most versatile plottling libraries and widely used in industry. However, plotly has various dependencies that make it difficult to support in Data 100. Therfore, we have intentionally excluded the code to generate the plot above.\nBy now, you’ll have noticed that each of these plotting libraries have a very different syntax. As with pandas, we’ll teach you the important methods in matplotlib and seaborn, but you’ll learn more through documentation.\n\nMatplotlib Documentation\nSeaborn Documentation"
  },
  {
    "objectID": "visualization_1/visualization_1.html#histograms",
    "href": "visualization_1/visualization_1.html#histograms",
    "title": "Visualization I",
    "section": "Histograms",
    "text": "Histograms\nHistograms are a natural extension to bar plots; they visualize the distribution of quantitative (numerical) data.\nRevisiting our example with the births DataFrame, let’s plot the distribution of the Maternal Pregnancy Weight column.\n\n\nCode\nbirths.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Birth Weight\n      Gestational Days\n      Maternal Age\n      Maternal Height\n      Maternal Pregnancy Weight\n      Maternal Smoker\n    \n  \n  \n    \n      0\n      120\n      284\n      27\n      62\n      100\n      False\n    \n    \n      1\n      113\n      282\n      33\n      64\n      135\n      False\n    \n    \n      2\n      128\n      279\n      28\n      64\n      115\n      True\n    \n    \n      3\n      108\n      282\n      23\n      67\n      125\n      True\n    \n    \n      4\n      136\n      286\n      25\n      62\n      93\n      False\n    \n  \n\n\n\n\nHow should we define our categories for this variable? In the previous example, these were the unique values of the Maternal Smoker column: True and False. If we use similar logic here, our categories are the different numerical weights contained in the Maternal Pregnancy Weight column.\nUnder this assumption, let’s plot this distribution using the seaborn.countplot function.\n\nsns.countplot(data = births, x = 'Maternal Pregnancy Weight');\n\n\n\n\nThis histogram clearly suffers from overplotting. This is somewhat expected for Maternal Pregnancy Weight - it is a quantitative variable that takes on a wide range of values.\nTo combat this problem, statisticians use bins to categorize numerical data. Luckily, seaborn provides a helpful plotting function that automatically bins our data.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\n\n\n\n\nThis diagram is known as a histogram. While it looks more reasonable, notice how we lose fine-grain information on the distribution of data contained within each bin. We can introduce rug plots to minimize this information loss. An overlaid “rug plot” displays the within-bin distribution of our data, as denoted by the thickness of the colored line on the x-axis.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\");\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');\n\n\n\n\nYou may have seen histograms drawn differently - perhaps with an overlaid density curve and normalized y-axis. We can display both with a few tweaks to our code.\nTo visualize a density curve, we can set the the kde = True argument of the sns.histplot. Setting the argument stat = \"density\" normalizes our histogram and displays densities, instead of counts, on the y-axis. You’ll notice that the area under the density curve is 1.\n\nsns.histplot(data = births, x = \"Maternal Pregnancy Weight\", kde = True, \n             stat = \"density\")\nsns.rugplot(data = births, x = \"Maternal Pregnancy Weight\", color = 'red');"
  },
  {
    "objectID": "visualization_1/visualization_1.html#evaluating-histograms",
    "href": "visualization_1/visualization_1.html#evaluating-histograms",
    "title": "Visualization I",
    "section": "Evaluating Histograms",
    "text": "Evaluating Histograms\nHistograms allow us to assess a distribution by their shape. There are a few properties of histograms we can analyze:\n\nSkewness and Tails\n\nSkewed left vs skewed right\nLeft tail vs right tail\n\nOutliers\n\nDefined arbitrarily for now\n\nModes\n\nMost commonly occuring data\n\n\n\nSkewness and Tails\nIf a distribution has a long right tail (such as Maternal Pregancy Weight), it is skewed right. In a right-skewed distribution, the few large outliers “pull” the mean to the right of the median.\nIf a distribution has a long left tail, it is skewed left. In a left-skewed distribution, the few small outliers “pull” the mean to the left of the median.\nIn the case where a distribution has equal-sized right and left tails, it is symmetric. The mean is approximately equal to the median.\n\n\nOutliers\nLoosely speaking, an outlier is defined as a data point that lies an abnormally large distance away from other values. We’ll define the statistical measure for this shortly.\nOutliers disproportionately influce the mean because their magnitude is directly involved in computing the average. However, the median is largely unaffected - the magnitude of an outlier is irrelevant; we only care that it is some non-zero distance away from the midpoint of the data.\n\n\nModes\nA mode of a distribution is a local or global maximum. A distribution with a single clear maximum is unimodal, distributions with two modes are bimodal, and those with 3 or more are multimodal.\nFor example, the distribution of birth weights for maternal smokers is (weakly) multimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == True]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');\n\n\n\n\nOn the other hand, the distribution of birth weights for maternal non-smokers is unimodal.\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight');"
  },
  {
    "objectID": "visualization_1/visualization_1.html#box-plots-and-violin-plots",
    "href": "visualization_1/visualization_1.html#box-plots-and-violin-plots",
    "title": "Visualization I",
    "section": "Box Plots and Violin Plots",
    "text": "Box Plots and Violin Plots\n\nBoxplots\nBoxplots are an alternative to histograms that visualize numerical distributions. They are especially useful in graphicaly summarizing several characteristics of a distribution. These include:\n\nLower Quartile (\\(1\\)st Quartile)\nMedian (\\(2\\)nd Quartile)\nUpper Quartile (\\(3\\)rd Quartile)\nInterquartile Range (IQR)\nWhiskers\nOutliers\n\nThe lower quartile, median, and uper quartile are the \\(25\\)th, \\(50\\)th, and \\(75\\)th percentiles of data, respectively. The interquartile range measures the spread of the middle \\(50\\)% of the distribution, calculated as the (\\(3\\)rd Quartile \\(-\\) \\(1\\)st Quartile).\nThe whiskers of a box-plot are the two points that lie at the \\(1\\)st Quartile \\(-\\) (\\(1.5\\) * IQR), and the \\(3\\)rd Quartile \\(+\\) (\\(1.5\\) * IQR). They are the lower and upper ranges of “normal” data (the points excluding outliers). Subsequently, the outliers are the data points that fall beyond the whiskers, or further than (\\(1.5\\) \\(*\\) IQR) from the extreme quartiles.\nLet’s visualize a box-plot of the Birth Weight column.\n\n\nCode\nimport numpy as np\n\nsns.boxplot(data = births, y = \"Birth Weight\");\n\nbweights = births['Birth Weight']\nq1 = np.percentile(bweights, 25)\nq2 = np.percentile(bweights, 50)\nq3 = np.percentile(bweights, 75)\niqr = q3 - q1\nwhisk1 = q1 - (1.5 * iqr)\nwhisk2 = q3 + (1.5 * iqr)\n\nprint(\"The first quartile is {}\".format(q1))\nprint(\"The second quartile is {}\".format(q2))\nprint(\"The third quartile is {}\".format(q3))\nprint(\"The interquartile range is {}\".format(iqr))\nprint(\"The whiskers are {} and {}\".format(whisk1, whisk2))\n\n\nThe first quartile is 108.0\nThe second quartile is 120.0\nThe third quartile is 131.0\nThe interquartile range is 23.0\nThe whiskers are 73.5 and 165.5\n\n\n\n\n\nHere is a helpful visual that summarizes our discussion above.\n\n\n\nViolin Plots\nAnother diagram that is useful in visualizing a variable’s distribution is the violin plot. A violin plot supplements a box-plot with a smoothed density curve on either side of the plot. These density curves highlight the relative frequency of variable’s possible values. If you look closely, you’ll be able to discern the quartiles, whiskers, and other hallmark features of the box-plot.\n\nsns.violinplot(data = births, y = 'Birth Weight');"
  },
  {
    "objectID": "visualization_1/visualization_1.html#comparing-quantitative-distributions",
    "href": "visualization_1/visualization_1.html#comparing-quantitative-distributions",
    "title": "Visualization I",
    "section": "Comparing Quantitative Distributions",
    "text": "Comparing Quantitative Distributions\nEarlier in our discussion of the mode, we visualized two histograms that described the distribution of birth weights for maternal smokers and non-smokers. However, comparing these histograms was difficult because they were displayed on seperate plots. Can we overlay the two to tell a more compelling story?\nIn seaborn, multiple calls to a plotting library in the same code cell will overlay the plots. For example:\n\nbirths_maternal_smoker = births[births['Maternal Smoker'] == False]\nbirths_non_maternal_smoker = births[births['Maternal Smoker'] == True]\n\nsns.histplot(data = births_maternal_smoker, x= 'Birth Weight',\n             color = 'orange', label = 'smoker')\nsns.histplot(data = births_non_maternal_smoker, x= 'Birth Weight',\n             color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nHowever, notice how this diagram suffers from overplotting. We can fix this with a call to sns.kdeplot. This will remove the bins and overlay the histogram with a density curve that better summarizes the distribution.\n\nsns.kdeplot(data = births_maternal_smoker, x= 'Birth Weight', color = 'orange', label = 'smoker')\nsns.kdeplot(data = births_non_maternal_smoker, x= 'Birth Weight', color = 'blue', label = 'nonsmoker')\nplt.legend();\n\n\n\n\nUnfortunately, we lose critical information in our distribution by removing small details. Therefore, we typically prefer to use box-plots and violin plots when comparing distributions. These are more concise and allow us to compare summary statistics across many distributions.\n\nsns.violinplot(data=births, x='Maternal Smoker', y='Birth Weight');\n# The following line of code plots a box-plot\n#sns.boxplot(data=births, x='Maternal Smoker', y='Birth Weight');"
  },
  {
    "objectID": "visualization_1/visualization_1.html#relationships-between-quantitative-variables",
    "href": "visualization_1/visualization_1.html#relationships-between-quantitative-variables",
    "title": "Visualization I",
    "section": "Relationships Between Quantitative Variables",
    "text": "Relationships Between Quantitative Variables\nUp until now, we’ve discussed how to visualize single-variable distributions. Going beyond this, we want to understand the relationship between pairs of numerical variables.\n\nScatter Plots\nScatter plots are one of the most useful tools in representing the relationship between two quantitative variables. They are particularly important in gauging the strength, or correlation between variables. Knowledge of these relationships can then motivate decisions in our modeling process.\nFor example, let’s plot a scatter plot comparing the Maternal Pregnancy Weight and Birth Weight colums, using both matplotlib and seaborn.\n\n# Matplotlib Example\nplt.scatter(births['Maternal Pregnancy Weight'], births['Birth Weight'])\n# For brevity, we have excluded code to label the axes\n\n<matplotlib.collections.PathCollection at 0x7fd51c55a5b0>\n\n\n\n\n\n\n# Seaborn Example\nsns.scatterplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\",\n                hue = \"Maternal Smoker\")\n\n<AxesSubplot: xlabel='Maternal Pregnancy Weight', ylabel='Birth Weight'>\n\n\n\n\n\nThis is an example where color is used to add a third dimension to our plot. This is possible with the hue paramater in seaborn, which adds a categorical column encoding to an existing visualization. This way, we can look for relationships in Maternal Pregnancy Weight and Birth Weight in both maternal smokers and non-smokers. If we wish to see the relationship’s strength more clearly, we can use sns.lmplot.\n\nsns.lmplot(data = births, x = \"Maternal Pregnancy Weight\", y = \"Birth Weight\", \n           hue=\"Maternal Smoker\", ci=False);\n\n\n\n\nWe can make out a weak, positive relationship in pregnancy weight and birth weight for both maternal smokers and non-smokers (slightly more positive in maternal smokers).\n\n\nHex Plots and Contour Plots\nUnfortunately, our scatter plots above suffered from overplotting, which made them hard to interpret. And with a large number of points, jittering is unlikely to resolve the issue. Instead, we can look to hex plots and contour plots.\nHex Plots can be thought of as a two dimensional histogram that shows the joint distribution between two variables. This is particularly useful working with very dense data.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'hex')\n\n<seaborn.axisgrid.JointGrid at 0x7fd51c566700>\n\n\n\n\n\nThe axes are evidently binned into hexagons, which makes the linear relationship easier to decipher. Darker regions generally indicate a higher density of points.\nOn the other hand, contour plots are two dimensional versions of density curves with marginal distributions of each variable on the axes. We’ve used very similar code here to generate our contour plots, with the addition of the kind = 'kde' and fill = True arguments.\n\nsns.jointplot(data = births, x = \"Maternal Pregnancy Weight\", \n              y = \"Birth Weight\", kind = 'kde', fill = True)\n\n<seaborn.axisgrid.JointGrid at 0x7fd5080ad7f0>"
  },
  {
    "objectID": "visualization_2/visualization_2.html",
    "href": "visualization_2/visualization_2.html",
    "title": "Visualization II",
    "section": "",
    "text": "In the last lecture, we learned that density curves are smooth, continuous functions that represent a distribution of values. In this section, we’ll learn how to construct density curves using Kernel Density Estimation.\n\n\nKernel Density Estimation involves a technique called smoothing - a process applied to a distribution of values that allows us to analyze the more general structure of the dataset.\nMany of the visualizations we learned during the last lecture are examples of this. Histograms are smoothed versions of one-dimensional rug plots, and hex plots are smoother alternatives to two-dimensional scatter plots. They remove the detail from individual observations so we can visualize the patterns in our distribution.\n\n\n\nKernel Density Estimation is a smoothing technique that allows us to estimate a density curve (also known as a probability density function) from a set of observations. There are a few steps in this process:\n\nPlace a kernel at each data point\nNormalize kernels to have total area of 1\nSum kernels together\n\nSuppose we have 5 data points: \\([2.2, 2.8, 3.7, 5.3, 5.7]\\). We wish to recreate the following Kernel Density Estimate:\n\n\nCode\nimport seaborn as sns\n\ndata = [2.2, 2.8, 3.7, 5.3, 5.7]\nsns.kdeplot(data);\n\n\n\n\n\nLet’s walk through each step to construct this density curve.\n\n\nTo begin generating a density curve, we need to choose a kernel and bandwidth value. What are these exactly? A kernel is a density curve itself, and the bandwidth is a measure of the kernel’s width. Recall that a valid density has an area of 1.\nAt each of our 5 points (depicted in the rug plot on the left), we’ve placed a Gaussian kernel with a bandwidth parameter of alpha = 1. We’ll explore what these are in the next section.\n\n\nRugplot of Data\n\n\n\n\nKernelized Data\n\n\n\n\n\n\nNotice how these 5 kernels are density curves - meaning they each have an area of 1. In Step 3, we will be summing each these kernels, and we want the result to be a valid density that has an area of 1. Therefore, it makes sense to normalize our current set of kernels by multiplying each by \\(\\frac{1}{5}\\).\n\n\nKernelized Data\n\n\n\n\nNormalized Kernels\n\n\n\n\n\n\nOur kernel density estimate (KDE) is the vertical sum of the normalized kernels along the x-axis. It is depicted below on the right.\n\n\nNormalized Kernels\n\n\n\n\nKernel Density Estimate\n\n\n\n\n\n\n\n\n\n\nA kernel (for our purposes) is a valid density function. This means it:\n\nMust be non-negative for all inputs.\nMust integrate to 1.\n\n\n\nThe most common kernel is the Gaussian kernel. The Gaussian kernel is equivalent to the Gaussian probability density function (the Normal distribution), centered at the observed value \\(x_i\\) with a standard deviation of \\(\\alpha\\) (this is known as the bandwidth parameter).\n\\(K_a(x, x_i) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}}}e^{-\\frac{(x-x_i)^{2}}{2a^{2}}}\\)$\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt \n\ndef gaussian_kernel(alpha, x, z):\n    return 1.0/np.sqrt(2. * np.pi * alpha**2) * np.exp(-(x - z) ** 2 / (2.0 * alpha**2))\n\nxs = np.linspace(-5, 5, 200)\nalpha = 1\nkde_curve = [gaussian_kernel(alpha, x, 0) for x in xs]\nplt.plot(xs, kde_curve);\n\n\n\n\n\nThe Gaussian kernel centered at 0 with bandwidth \\(\\alpha\\) = 1.\n\n\n\n\nIf you’ve taken a probability class, you’ll recognize that the mean of this Gaussian kernel is \\(x_i\\) and the standard deviation is \\(\\alpha\\). Increasing \\(\\alpha\\) - equivalently, the bandwidth - smoothens the density curve. Larger values of \\(\\alpha\\) are typically easier to understand; however, we begin to lose important distributional information as \\(\\alpha\\) increases.\nHere is how adjusting \\(\\alpha\\) affects a distribution in some variable from an arbitrary dataset.\n\n\nGaussian Kernel, Alpha = 0.1\n\n\n\n\nGaussian Kernel, Alpha = 1\n\n\n\n\n\nGaussian Kernel, Alpha = 2\n\n\n\n\nGaussian Kernel, Alpha = 10\n\n\n\n\n\n\nAnother example of a kernel is the Boxcar kernel. The boxcar kernel assigns a uniform density to points within a “window” of the observation, and a density of 0 elsewhere.\n\\(K_a(x, x_i) = \\begin{cases}  \\frac{1}{\\alpha}, & |x - x_i| \\le \\frac{\\alpha}{2}\\\\  0, & \\text{else }  \\end{cases}\\)\n\n\nCode\ndef boxcar_kernel(alpha, x, z):\n    return (((x-z)>=-alpha/2)&((x-z)<=alpha/2))/alpha\n\nxs = np.linspace(-5, 5, 200)\nalpha=1\nkde_curve = [boxcar_kernel(alpha, x, 0) for x in xs]\nplt.plot(xs, kde_curve);\n\n\n\n\n\nThe Boxcar kernel centered at 0 with bandwidth \\(\\alpha\\) = 1.\n\n\n\n\nThe diagram on the right is how the density curve for our 5 point dataset would have looked had we used the Boxcar kernel with bandwidth \\(\\alpha\\) = 1."
  },
  {
    "objectID": "visualization_2/visualization_2.html#visualization-theory",
    "href": "visualization_2/visualization_2.html#visualization-theory",
    "title": "Visualization II",
    "section": "Visualization Theory",
    "text": "Visualization Theory\nThis section marks a pivot to the second major topic of this lecture - visualization theory. We’ll discuss the abstract nature of visualizations, which will help us make informed decisions to construct them.\nRemember, we had two goals for visualizing data. This section is particularly important in motivating\n\nHelp our understanding of the data and results\nCommunicating our results and conclusions with others\n\n\nInformation Channels\nThere are various channels of information in visualizations - these include encodings, color, and scale, to name a few. In constructing good visuals, we should utilize these channels to convey information that answers our questions.\nFor example, we learned a few ways to picture a distribution: rugplots, KDEs, and histograms. Neither is strictle better than any other; they all convey varying levels of detail, and some may be more advantageous depending on the application.\n\nEncodings in Rugplots\nOne detail that we may have overlooked in our earlier discussion of rugplots is the importance of encodings. Rugplots are effective visuals because they utilize encodings in line thickness to convey frequency. Consider the following diagram:\n\n\n\nMulti-Dimensional Data\nEncodings are useful in representing complex"
  },
  {
    "objectID": "pandas_1/pandas_1.html",
    "href": "pandas_1/pandas_1.html",
    "title": "Pandas I",
    "section": "",
    "text": "DataFrames\nTabular data is one of the most common data formats used in data science. We’ll primarily be looking at tabular data in Data 100.\nIn Data 8, you encountered the Table class of the datascience library. In Data 100, we’ll be using the DataFrame class of the pandas library to represent tabular data.\nHere is an example of a DataFrame containing election data.\n\nimport pandas as pd\n\nelections = pd.read_csv(\"data/elections.csv\")\nelections\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n      loss\n      1.073699\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n      win\n      51.311515\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n182 rows × 6 columns\n\n\n\nLet’s dissect the code above.\n\nWe first import the pandas library into our Python environment, using the alias pd.   import pandas as pd\nThere are a number of ways to read data into a DataFrame. In Data 100, our data are typically stored in a CSV (comma-seperated values) file format. We can import a CSV file into a DataFrame by passing the data path as an argument to the following pandas function.   pd.read_csv(\"elections.csv\")\n\nThis code stores our DataFrame object into the elections variable. Upon inspection, our elections DataFrame has 182 rows and 6 columns. Each row represents a single record - in our example, a presedential candidate in some particular year. Each column represents a single attribute, or feature of the record.\nThe API (application programming interface) for the DataFrame class is enormous. In the next section, we’ll discuss several methods of the DataFrame API that allow us to extract subsets of data.\n\n\nSlicing in DataFrames\nOne of the most important tasks in manipulating a DataFrame is extracting a subset of rows and columns. This is called slicing. We can do so using three primary methods of the DataFrame class:\n\n.loc\n.iloc\n[]\n\n\nIndexing with .loc\nThe .loc operator selects rows and columns in a DataFrame by their row and column labels, respectively. The row label (commonly referred to as the index) is the bold text on the far left of a DataFrame, while the column label is the text found at the top of a DataFrame. By default, pandas assigns row labels as sequential integers beginning from 0. The column labels in our elections DataFrame are the columns Year, Candidate, Party, Popular Vote, Result, %.\n.loc lets us specify the row and column labels to select from our DataFrame as the first and second arguments to the function. For example, to select the the row labeled 0 and the column labeled Candidate from our elections DataFrame:\n\nelections.loc[0, 'Candidate']\n\n'Andrew Jackson'\n\n\nTo select multiple rows and columns, we can use Python slice notation. We can select the first four rows and first four columns.\n\nelections.loc[0:3, 'Year':'Popular vote']\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSuppose that instead, we wanted every column value for the first four rows in the elections DataFrame. The shorthand : comes in great use.\n\nelections.loc[0:3, :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\nA couple of things we should note. Unlike conventional Python, Pandas allows us to slice string values (in our example, the column labels). Secondly, slicing in Pandas is inclusive. Notice how our resulting DataFrame includes every row and column between and including the slice labels we specified.\nEquivalently, we can use a list to obtain multiple rows and columns in our elections DataFrame.\n\nelections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nLastly, we can interchange list and slicing notation.\n\nelections.loc[[0, 1, 2, 3], :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nIndexing with .iloc\nSlicing with .iloc works similarily to .loc, although .iloc uses the integer positions of rows and columns rather the labels. The arguments for the .iloc function also behave similarly - single values, lists, indices, and any combination of these are permitted.\nWe can begin reproducing our results from above. Let’s begin by selecting for the first presedential candidate in our elections DataFrame:\n\n# elections.loc[0, \"Candidate\"] - Previous approach\nelections.iloc[0, 1]\n\n'Andrew Jackson'\n\n\nNotice how the first argument to both .loc and .iloc are the same. This is because the row with a label of 0 is conveniently in the 0th (or first) position of the elections DataFrame. Generally, this is true of any DataFrame where the row labels are incremented in ascending order from 0.\nHowever, when we select for the first four rows and columns using .iloc, we notice something.\n\n# elections.loc[0:3, 'Year':'Popular vote'] - Previous approach\nelections.iloc[0:4, 0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSlicing is no longer inclusive in .iloc - it’s exclusive! Sad to say, this is one of Pandas syntatical subtleties. Don’t worry, you’ll get used to with practice.\nList behavior works just as expected.\n\n#elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']] - Previous Approach\nelections.iloc[[0, 1, 2, 3], [0, 1, 2, 3]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nThis discussion begs the question: when should we use .loc vs .iloc? In most cases, .loc is generally safer to use. You can imagine .iloc may return incorrect values when applied to a dataset where the ordering of data can change.\n\n\nIndexing with []\nThe [] selection operator is the most baffling of all, yet the most commonly used. It only takes a single argument, which may be one of the following:\n\nA slice of row numbers\nA list of column labels\nA single column label\n\nThat is, [] is context dependent. Let’s see some examples.\n\nA slice of row numbers\nSay we wanted the first four rows of our elections DataFrame.\n\nelections[0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nA list of column labels\nSuppose we now want the first four columns.\n\nelections[[\"Year\", \"Candidate\", \"Party\", \"Popular vote\"]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n    \n  \n\n182 rows × 4 columns\n\n\n\n\n\nA single column label\nLastly, if we only want the Candidate column.\n\nelections[\"Candidate\"]\n\n0         Andrew Jackson\n1      John Quincy Adams\n2         Andrew Jackson\n3      John Quincy Adams\n4         Andrew Jackson\n             ...        \n177           Jill Stein\n178         Joseph Biden\n179         Donald Trump\n180         Jo Jorgensen\n181       Howard Hawkins\nName: Candidate, Length: 182, dtype: object\n\n\nThe output looks quite different - it’s no longer a DataFrame! This is a Series. We’ll talk about what a Series is in the next section.\n\n\n\n\nDataFrames, Series, and Indices\nWe saw that selecting a single column from a DataFrame using the [] operator outputted a new data format, called a Series. Let’s verify this claim.\n\ntype(elections)\n\npandas.core.frame.DataFrame\n\n\n\ntype(elections['Candidate'])\n\npandas.core.series.Series\n\n\nA Series is a one dimensional object that represents a single column of data. It has two components - an index and a column of data. A DataFrame is equivalent to a collection of Series, which all share the same index. Notice how the index is equivalent to the DataFrame index (or row labels) we discussed above.\n\nHowever, a DataFrame index doesn’t have to be an integer, nor does it have to be unique. For example, we can set our index to be the name of presedential candidates. Selecting a new Series from this modified DataFrame yields the following:\n\nTo retrieve the indices of a DataFrame, simple use the .index attribute of the DataFrame class.\n\nelections.set_index(\"Candidate\", inplace=True)\nelections.index\n\nIndex(['Andrew Jackson', 'John Quincy Adams', 'Andrew Jackson',\n       'John Quincy Adams', 'Andrew Jackson', 'Henry Clay', 'William Wirt',\n       'Hugh Lawson White', 'Martin Van Buren', 'William Henry Harrison',\n       ...\n       'Darrell Castle', 'Donald Trump', 'Evan McMullin', 'Gary Johnson',\n       'Hillary Clinton', 'Jill Stein', 'Joseph Biden', 'Donald Trump',\n       'Jo Jorgensen', 'Howard Hawkins'],\n      dtype='object', name='Candidate', length=182)\n\n\n\nelections.reset_index(inplace=True)\n\nEarlier, we mentioned that a Series was just a column of data. What if we wanted a single column as a DataFrame? To do so, we can pass in a list containing a single column to the [] selection operator.\n\nelections[[\"Party\"]] # [\"Party\"] is the argument - a list with a single element\n\n\n\n\n\n  \n    \n      \n      Party\n    \n  \n  \n    \n      0\n      Democratic-Republican\n    \n    \n      1\n      Democratic-Republican\n    \n    \n      2\n      Democratic\n    \n    \n      3\n      National Republican\n    \n    \n      4\n      Democratic\n    \n    \n      ...\n      ...\n    \n    \n      177\n      Green\n    \n    \n      178\n      Democratic\n    \n    \n      179\n      Republican\n    \n    \n      180\n      Libertarian\n    \n    \n      181\n      Green\n    \n  \n\n182 rows × 1 columns\n\n\n\n\n\nConditional Selection\nConditional selection allows us to select a subset of rows in a DataFrame if they follow some specified condition.\nTo understand how to use conditional selection, we must look at another input to the .loc and [] operators - a boolean array. This boolean array must have a length equal to the number of rows in the DataFrame. It will then return all rows with a corresponding True value in the array.\nHere, we will select all even-indexed rows in the first 10 rows of our DataFrame.\n\n# Why is :9 is the correct slice to select the first 10 rows?\nelections_first_10_rows = elections.loc[:9, :]\n\n# Notice how we have exactly 10 elements in our boolean array argument\nelections_first_10_rows[[True, False, True, False, True, \\\n                         False, True, False, True, False]]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      4\n      Andrew Jackson\n      1832\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      6\n      William Wirt\n      1832\n      Anti-Masonic\n      100715\n      loss\n      7.821583\n    \n    \n      8\n      Martin Van Buren\n      1836\n      Democratic\n      763291\n      win\n      52.272472\n    \n  \n\n\n\n\nUnfortunately, using this method to select multiple rows in a large DataFrame is infeasible. Instead, we can provide a logical condition as an input to .loc or [] that returns a boolean array with said length.\nFor example, to return all candidates affilliated with the Independent party:\n\nlogical_operator = elections['Party'] == \"Independent\"\nelections[logical_operator]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\nHere, logical_operator evaluates to a Series of boolean values with length 182.\n\nlogical_operator\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n177    False\n178    False\n179    False\n180    False\n181    False\nName: Party, Length: 182, dtype: bool\n\n\nRows 121, 130, 143, 161, 167, and 174 evaluate to True and are thus returned in the DataFrame.\n\n\nCode\nprint(logical_operator.loc[[121, 130, 143, 161, 167, 174]])\n\n\n121    True\n130    True\n143    True\n161    True\n167    True\n174    True\nName: Party, dtype: bool\n\n\nPassing a Series as an argument to elections[] has the same affect as using in a boolean array. In fact, the [] selection operator can take a boolean Series, array, and list as arguments. These three are used interchangeably thoughout the course.\nSimilarly, we can use .loc to achieve similar results.\n\nelections.loc[elections['Party'] == \"Independent\"]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\nBoolean conditions can be combined using various operators that allow us to filter results by multiple conditions. Some examples include the & (and) operator and | (or) operator.\nNote When using logical operators, pay careful attention to surround each condition with a set of paranthesis (). Doing so will ensure your code doesn’t throw an error.\nFor example, if we want to return data on all presidential candidates affiliated with the Independent Party before the 21st century, we can do so:\n\nelections[(elections['Party'] == \"Independent\") \\\n          & (elections['Year'] < 2000)]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n  \n\n\n\n\n\n\nHandy Utility Functions\nThere are a large number of operations supported by pandas Series and DataFrames that allow us to efficiently manipulate data . In this section, we’ll cover a few.\n\n.head and .tail\n.shape and .size\n.describe\n.sample\n.value_counts\n.unique\n.sort_values\n\n\n.head / .tail\n.head(n) and .tail(n) display the first n and last n rows in a DataFrame, respectively.\n\nelections.head(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      John Quincy Adams\n      1824\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n  \n\n\n\n\n\nelections.tail(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      179\n      Donald Trump\n      2020\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      Jo Jorgensen\n      2020\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      Howard Hawkins\n      2020\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n\n\n\n\n\n.shape / .size\n.shape returns a tuple with the number of rows and columns.  .size returns the total number of data cells. This is the product of the number of rows and columns.\n\nelections.shape\n\n(182, 6)\n\n\n\nnum_rows, num_cols = elections.shape\nassert(elections.size == num_rows * num_cols)\nelections.size\n\n1092\n\n\n\n\n.describe\n.describe() returns a DataFrame of useful summary statistics for each numerical column.\n\nelections.describe()\n\n\n\n\n\n  \n    \n      \n      Year\n      Popular vote\n      %\n    \n  \n  \n    \n      count\n      182.000000\n      1.820000e+02\n      182.000000\n    \n    \n      mean\n      1934.087912\n      1.235364e+07\n      27.470350\n    \n    \n      std\n      57.048908\n      1.907715e+07\n      22.968034\n    \n    \n      min\n      1824.000000\n      1.007150e+05\n      0.098088\n    \n    \n      25%\n      1889.000000\n      3.876395e+05\n      1.219996\n    \n    \n      50%\n      1936.000000\n      1.709375e+06\n      37.677893\n    \n    \n      75%\n      1988.000000\n      1.897775e+07\n      48.354977\n    \n    \n      max\n      2020.000000\n      8.126892e+07\n      61.344703\n    \n  \n\n\n\n\n\n\n.sample\n.sample(n) returns a random sample of n items from the given DataFrame.\n\nelections.sample(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      75\n      Aaron S. Watkins\n      1920\n      Prohibition\n      188787\n      loss\n      0.708351\n    \n    \n      96\n      Wendell Willkie\n      1940\n      Republican\n      22347744\n      loss\n      44.894561\n    \n    \n      156\n      David Cobb\n      2004\n      Green\n      119859\n      loss\n      0.098088\n    \n  \n\n\n\n\n\n\n.value_counts\n.value_counts() is called on a Series and returns a Series containing the count of unique values.\n\nelections['Candidate'].value_counts()\n\nNorman Thomas         5\nRalph Nader           4\nFranklin Roosevelt    4\nEugene V. Debs        4\nMartin Van Buren      3\n                     ..\nStephen A. Douglas    1\nAl Smith              1\nBenjamin Butler       1\nJohn St. John         1\nWendell Willkie       1\nName: Candidate, Length: 132, dtype: int64\nThis code tells us how many times each candidate ran for president of the United States.\n\n\n\n\n.unique\n.unique() is called on a Series and returns an array with the unique values contained in that Series.\n\n# For brevity, we have limited the results to 5 candidates \nelections['Candidate'].unique()[:5]\n\narray(['Andrew Jackson', 'John Quincy Adams', 'Henry Clay',\n       'William Wirt', 'Hugh Lawson White'], dtype=object)\n\n\n\n\n.sort_values\n.sort_values() returns a sorted Series of values from the Series it was called on. Numerical values are in sorted magnitude, while text is sorted in alphabetical order. You may specify optional arguments to sort in ascending or descending order.\n\nelections['Candidate'].sort_values()\n\n75           Aaron S. Watkins\n27            Abraham Lincoln\n23            Abraham Lincoln\n108           Adlai Stevenson\n105           Adlai Stevenson\n                ...          \n19             Winfield Scott\n37     Winfield Scott Hancock\n74             Woodrow Wilson\n70             Woodrow Wilson\n16             Zachary Taylor\nName: Candidate, Length: 182, dtype: object\n\n\n\n\n\nParting Note\nThe pandas library is enormous and contains many useful functions. Here is a link to documentation.\nThis lecture and the next will cover important methods you should be fluent in. However, we want you to get familiar with the real world programming practice of …Googling! Answers to your questions can be found in documentation, Stack Overflow, etc.\nWith that, let’s move on to Pandas II."
  },
  {
    "objectID": "pandas_1/pandas_1_copy.html#slicing-in-dataframes",
    "href": "pandas_1/pandas_1_copy.html#slicing-in-dataframes",
    "title": "Pandas I",
    "section": "Slicing in DataFrames",
    "text": "Slicing in DataFrames\nOne of the most important tasks in manipulating a DataFrame is extracting a subset of rows and columns. This is called slicing. We can do so using three primary methods of the DataFrame class:\n\n.loc\n.iloc\n[]\n\n\nIndexing with .loc\nThe .loc operator selects rows and columns in a DataFrame by their row and column labels, respectively. The row label (commonly referred to as the index) is the bold text on the far left of a DataFrame, while the column label is the text found at the top of a DataFrame. By default, pandas assigns row labels as sequential integers beginning from 0. The column labels in our elections DataFrame are the columns Year, Candidate, Party, Popular Vote, Result, %.\n.loc lets us specify the row and column labels to select from our DataFrame as the first and second arguments to the function. For example, to select the the row labeled 0 and the column labeled Candidate from our elections DataFrame:\n\nelections.loc[0, 'Candidate']\n\n'Andrew Jackson'\n\n\nTo select multiple rows and columns, we can use Python slice notation. We can select the first four rows and first four columns.\n\nelections.loc[0:3, 'Year':'Popular vote']\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSuppose that instead, we wanted every column value for the first four rows in the elections DataFrame. The shorthand : comes in great use.\n\nelections.loc[0:3, :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\nA couple of things we should note. Unlike conventional Python, Pandas allows us to slice string values (in our example, the column labels). Secondly, slicing in Pandas is inclusive. Notice how our resulting DataFrame includes every row and column between and including the slice labels we specified.\nEquivalently, we can use a list to obtain multiple rows and columns in our elections DataFrame.\n\nelections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nLastly, we can interchange list and slicing notation.\n\nelections.loc[[0, 1, 2, 3], :]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nIndexing with .iloc\nSlicing with .iloc works similarily to .loc, although .iloc uses the integer positions of rows and columns rather the labels. The arguments for the .iloc function also behave similarly - single values, lists, indices, and any combination of these are permitted.\nWe can begin reproducing our results from above. Let’s begin by selecting for the first presedential candidate in our elections DataFrame:\n\n# elections.loc[0, \"Candidate\"] - Previous approach\nelections.iloc[0, 1]\n\n'Andrew Jackson'\n\n\nNotice how the first argument to both .loc and .iloc are the same. This is because the row with a label of 0 is conveniently in the 0th (or first) position of the elections DataFrame. Generally, this is true of any DataFrame where the row labels are incremented in ascending order from 0.\nHowever, when we select for the first four rows and columns using .iloc, we notice something.\n\n# elections.loc[0:3, 'Year':'Popular vote'] - Previous approach\nelections.iloc[0:4, 0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nSlicing is no longer inclusive in .iloc - it’s exclusive! Sad to say, this is one of Pandas syntatical subtleties. Don’t worry, you’ll get used to with practice.\nList behavior works just as expected.\n\n#elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']] - Previous Approach\nelections.iloc[[0, 1, 2, 3], [0, 1, 2, 3]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n  \n\n\n\n\nThis discussion begs the question: when should we use .loc vs .iloc? In most cases, .loc is generally safer to use. You can imagine .iloc may return incorrect values when applied to a dataset where the ordering of data can change.\n\n\nIndexing with []\nThe [] selection operator is the most baffling of all, yet the most commonly used. It only takes a single argument, which may be one of the following:\n\nA slice of row numbers\nA list of column labels\nA single column label\n\nThat is, [] is context dependent. Let’s see some examples.\n\nA slice of row numbers\nSay we wanted the first four rows of our elections DataFrame.\n\nelections[0:4]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n  \n\n\n\n\n\n\nA list of column labels\nSuppose we now want the first four columns.\n\nelections[[\"Year\", \"Candidate\", \"Party\", \"Popular vote\"]]\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      177\n      2016\n      Jill Stein\n      Green\n      1457226\n    \n    \n      178\n      2020\n      Joseph Biden\n      Democratic\n      81268924\n    \n    \n      179\n      2020\n      Donald Trump\n      Republican\n      74216154\n    \n    \n      180\n      2020\n      Jo Jorgensen\n      Libertarian\n      1865724\n    \n    \n      181\n      2020\n      Howard Hawkins\n      Green\n      405035\n    \n  \n\n182 rows × 4 columns\n\n\n\n\n\nA single column label\nLastly, if we only want the Candidate column.\n\nelections[\"Candidate\"]\n\n0         Andrew Jackson\n1      John Quincy Adams\n2         Andrew Jackson\n3      John Quincy Adams\n4         Andrew Jackson\n             ...        \n177           Jill Stein\n178         Joseph Biden\n179         Donald Trump\n180         Jo Jorgensen\n181       Howard Hawkins\nName: Candidate, Length: 182, dtype: object\n\n\nThe output looks quite different - it’s no longer a DataFrame! This is a Series. We’ll talk about what a Series is in the next section."
  },
  {
    "objectID": "pandas_1/pandas_1_copy.html#dataframes-series-and-indices",
    "href": "pandas_1/pandas_1_copy.html#dataframes-series-and-indices",
    "title": "Pandas I",
    "section": "DataFrames, Series, and Indices",
    "text": "DataFrames, Series, and Indices\nWe saw that selecting a single column from a DataFrame using the [] operator outputted a new data format, called a Series. Let’s verify this claim.\n\ntype(elections)\n\npandas.core.frame.DataFrame\n\n\n\ntype(elections['Candidate'])\n\npandas.core.series.Series\n\n\nA Series is a one dimensional object that represents a single column of data. It has two components - an index and a column of data. A DataFrame is equivalent to a collection of Series, which all share the same index. Notice how the index is equivalent to the DataFrame index (or row labels) we discussed above.\n\nHowever, a DataFrame index doesn’t have to be an integer, nor does it have to be unique. For example, we can set our index to be the name of presedential candidates. Selecting a new Series from this modified DataFrame yields the following:\n\nTo retrieve the indices of a DataFrame, simple use the .index attribute of the DataFrame class.\n\nelections.set_index(\"Candidate\", inplace=True)\nelections.index\n\nIndex(['Andrew Jackson', 'John Quincy Adams', 'Andrew Jackson',\n       'John Quincy Adams', 'Andrew Jackson', 'Henry Clay', 'William Wirt',\n       'Hugh Lawson White', 'Martin Van Buren', 'William Henry Harrison',\n       ...\n       'Darrell Castle', 'Donald Trump', 'Evan McMullin', 'Gary Johnson',\n       'Hillary Clinton', 'Jill Stein', 'Joseph Biden', 'Donald Trump',\n       'Jo Jorgensen', 'Howard Hawkins'],\n      dtype='object', name='Candidate', length=182)\n\n\n\nelections.reset_index(inplace=True)\n\nEarlier, we mentioned that a Series was just a column of data. What if we wanted a single column as a DataFrame? To do so, we can pass in a list containing a single column to the [] selection operator.\n\nelections[[\"Party\"]] # [\"Party\"] is the argument - a list with a single element\n\n\n\n\n\n  \n    \n      \n      Party\n    \n  \n  \n    \n      0\n      Democratic-Republican\n    \n    \n      1\n      Democratic-Republican\n    \n    \n      2\n      Democratic\n    \n    \n      3\n      National Republican\n    \n    \n      4\n      Democratic\n    \n    \n      ...\n      ...\n    \n    \n      177\n      Green\n    \n    \n      178\n      Democratic\n    \n    \n      179\n      Republican\n    \n    \n      180\n      Libertarian\n    \n    \n      181\n      Green\n    \n  \n\n182 rows × 1 columns"
  },
  {
    "objectID": "pandas_1/pandas_1_copy.html#conditional-selection",
    "href": "pandas_1/pandas_1_copy.html#conditional-selection",
    "title": "Pandas I",
    "section": "Conditional Selection",
    "text": "Conditional Selection\nConditional selection allows us to select a subset of rows in a DataFrame if they follow some specified condition.\nTo understand how to use conditional selection, we must look at another input to the .loc and [] operators - a boolean array. This boolean array must have a length equal to the number of rows in the DataFrame. It will then return all rows with a corresponding True value in the array.\nHere, we will select all even-indexed rows in the first 10 rows of our DataFrame.\n\n# Why is :9 is the correct slice to select the first 10 rows?\nelections_first_10_rows = elections.loc[:9, :]\n\n# Notice how we have exactly 10 elements in our boolean array argument\nelections_first_10_rows[[True, False, True, False, True, \\\n                         False, True, False, True, False]]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      4\n      Andrew Jackson\n      1832\n      Democratic\n      702735\n      win\n      54.574789\n    \n    \n      6\n      William Wirt\n      1832\n      Anti-Masonic\n      100715\n      loss\n      7.821583\n    \n    \n      8\n      Martin Van Buren\n      1836\n      Democratic\n      763291\n      win\n      52.272472\n    \n  \n\n\n\n\n\nSingle Boolean Selection\nUnfortunately, using this method to select multiple rows in a large DataFrame is infeasible. Instead, we can provide a logical condition as an input to .loc or [] that returns a boolean array with said length.\nFor example, to return all candidates affilliated with the Independent party:\n\nlogical_operator = elections['Party'] == \"Independent\"\nelections[logical_operator]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\nHere, logical_operator evaluates to a Series of boolean values with length 182.\n\nlogical_operator\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n177    False\n178    False\n179    False\n180    False\n181    False\nName: Party, Length: 182, dtype: bool\n\n\nRows 121, 130, 143, 161, 167, and 174 evaluate to True and are thus returned in the DataFrame.\n\n\nCode\nprint(logical_operator.loc[[121, 130, 143, 161, 167, 174]])\n\n\n121    True\n130    True\n143    True\n161    True\n167    True\n174    True\nName: Party, dtype: bool\n\n\nPassing a Series as an argument to elections[] has the same affect as using in a boolean array. In fact, the [] selection operator can take a boolean Series, array, and list as arguments. These three are used interchangeably thoughout the course.\nSimilarly, we can use .loc to achieve similar results.\n\nelections.loc[elections['Party'] == \"Independent\"]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298\n    \n    \n      161\n      Ralph Nader\n      2004\n      Independent\n      465151\n      loss\n      0.380663\n    \n    \n      167\n      Ralph Nader\n      2008\n      Independent\n      739034\n      loss\n      0.563842\n    \n    \n      174\n      Evan McMullin\n      2016\n      Independent\n      732273\n      loss\n      0.539546\n    \n  \n\n\n\n\n\n\nMultiple Boolean Selection\nBoolean conditions can be combined using various operators that allow us to filter results by multiple conditions. Some examples include the & (and) operator and | (or) operator.\nNote When using logical operators, pay careful attention to surround each condition with a set of paranthesis (). Doing so will ensure your code doesn’t throw an error.\nFor example, if we want to return data on all presidential candidates affiliated with the Independent Party before the 21st century, we can do so:\n\nelections[(elections['Party'] == \"Independent\") \\\n          & (elections['Year'] < 2000)]\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      121\n      Eugene McCarthy\n      1976\n      Independent\n      740460\n      loss\n      0.911649\n    \n    \n      130\n      John B. Anderson\n      1980\n      Independent\n      5719850\n      loss\n      6.631143\n    \n    \n      143\n      Ross Perot\n      1992\n      Independent\n      19743821\n      loss\n      18.956298"
  },
  {
    "objectID": "pandas_1/pandas_1_copy.html#handy-utility-functions",
    "href": "pandas_1/pandas_1_copy.html#handy-utility-functions",
    "title": "Pandas I",
    "section": "Handy Utility Functions",
    "text": "Handy Utility Functions\nThere are a large number of operations supported by pandas Series and DataFrames that allow us to efficiently manipulate data . In this section, we’ll cover a few.\n\n.head and .tail\n.shape and .size\n.describe\n.sample\n.value_counts\n.unique\n.sort_values\n\n\n.head / .tail\n.head(n) and .tail(n) display the first n and last n rows in a DataFrame, respectively.\n\nelections.head(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      Andrew Jackson\n      1824\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      John Quincy Adams\n      1824\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n  \n\n\n\n\n\nelections.tail(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      179\n      Donald Trump\n      2020\n      Republican\n      74216154\n      loss\n      46.858542\n    \n    \n      180\n      Jo Jorgensen\n      2020\n      Libertarian\n      1865724\n      loss\n      1.177979\n    \n    \n      181\n      Howard Hawkins\n      2020\n      Green\n      405035\n      loss\n      0.255731\n    \n  \n\n\n\n\n\n\n.shape / .size\n.shape returns a tuple with the number of rows and columns.  .size returns the total number of data cells. This is the product of the number of rows and columns.\n\nelections.shape\n\n(182, 6)\n\n\n\nnum_rows, num_cols = elections.shape\nassert(elections.size == num_rows * num_cols)\nelections.size\n\n1092\n\n\n\n\n.describe\n.describe() returns a DataFrame of useful summary statistics for each numerical column.\n\nelections.describe()\n\n\n\n\n\n  \n    \n      \n      Year\n      Popular vote\n      %\n    \n  \n  \n    \n      count\n      182.000000\n      1.820000e+02\n      182.000000\n    \n    \n      mean\n      1934.087912\n      1.235364e+07\n      27.470350\n    \n    \n      std\n      57.048908\n      1.907715e+07\n      22.968034\n    \n    \n      min\n      1824.000000\n      1.007150e+05\n      0.098088\n    \n    \n      25%\n      1889.000000\n      3.876395e+05\n      1.219996\n    \n    \n      50%\n      1936.000000\n      1.709375e+06\n      37.677893\n    \n    \n      75%\n      1988.000000\n      1.897775e+07\n      48.354977\n    \n    \n      max\n      2020.000000\n      8.126892e+07\n      61.344703\n    \n  \n\n\n\n\n\n\n.sample\n.sample(n) returns a random sample of n items from the given DataFrame.\n\nelections.sample(3)\n\n\n\n\n\n  \n    \n      \n      Candidate\n      Year\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      160\n      Michael Peroutka\n      2004\n      Constitution\n      143630\n      loss\n      0.117542\n    \n    \n      151\n      Al Gore\n      2000\n      Democratic\n      50999897\n      loss\n      48.491813\n    \n    \n      2\n      Andrew Jackson\n      1828\n      Democratic\n      642806\n      win\n      56.203927\n    \n  \n\n\n\n\n\n\n.value_counts\n.value_counts() is called on a Series and returns a Series containing the count of unique values.\n\nelections['Candidate'].value_counts()\n\nNorman Thomas         5\nRalph Nader           4\nEugene V. Debs        4\nFranklin Roosevelt    4\nAndrew Jackson        3\n                     ..\nJohn G. Woolley       1\nJohn G. Schmitz       1\nSilas C. Swallow      1\nStephen A. Douglas    1\nAlf Landon            1\nName: Candidate, Length: 132, dtype: int64\nThis code tells us how many times each candidate ran for president of the United States.\n\n\n\n\n.unique\n.unique() is called on a Series and returns an array with the unique values contained in that Series.\n\n# For brevity, we have limited the results to 5 candidates \nelections['Candidate'].unique()[:5]\n\narray(['Andrew Jackson', 'John Quincy Adams', 'Henry Clay',\n       'William Wirt', 'Hugh Lawson White'], dtype=object)\n\n\n\n\n.sort_values\n.sort_values() returns a sorted Series of values from the Series it was called on. Numerical values are in sorted magnitude, while text is sorted in alphabetical order. You may specify optional arguments to sort in ascending or descending order.\n\nelections['Candidate'].sort_values()\n\n75           Aaron S. Watkins\n27            Abraham Lincoln\n23            Abraham Lincoln\n108           Adlai Stevenson\n105           Adlai Stevenson\n                ...          \n19             Winfield Scott\n37     Winfield Scott Hancock\n74             Woodrow Wilson\n70             Woodrow Wilson\n16             Zachary Taylor\nName: Candidate, Length: 182, dtype: object"
  },
  {
    "objectID": "pandas_1/pandas_1_copy.html#parting-note",
    "href": "pandas_1/pandas_1_copy.html#parting-note",
    "title": "Pandas I",
    "section": "Parting Note",
    "text": "Parting Note\nThe pandas library is enormous and contains many useful functions. Here is a link to documentation.\nThis lecture and the next will cover important methods you should be fluent in. However, we want you to get familiar with the real world programming practice of …Googling! Answers to your questions can be found in documentation, Stack Overflow, etc.\nWith that, let’s move on to Pandas II."
  },
  {
    "objectID": "pandas_2/pandas_2.html",
    "href": "pandas_2/pandas_2.html",
    "title": "Pandas II",
    "section": "",
    "text": "Last time, we introduced the Pandas library as a toolkit for processing data. We learned the DataFrame and Series data structures, familiarized ourselves with the basic syntax for manipulating tabular data, and began writing our first lines of Pandas code.\nIn this lecture, we’ll start to dive into some advanced Pandas syntax. You may find it helpful to follow along with a notebook of your own as we walk through these new pieces of code.\nWe’ll start by loading the babynames dataset."
  },
  {
    "objectID": "pandas_2/pandas_2.html#sorting-with-a-custom-key",
    "href": "pandas_2/pandas_2.html#sorting-with-a-custom-key",
    "title": "Pandas II",
    "section": "Sorting With a Custom Key",
    "text": "Sorting With a Custom Key\nIn the last lecture, we learned how to sort a DataFrame by the values in one or more of its columns using .sort_values. Pandas automatically sorted values in order according to numeric value (for number data) or alphabetical order (for string data).\n\n# Sort names by reverse-alphabetical order\n# Recall that `.head(5)` displays the first five rows in the DataFrame\nbabynames.sort_values(\"Name\", ascending=False).head(5) \n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n    \n  \n  \n    \n      400761\n      CA\n      M\n      2021\n      Zyrus\n      5\n    \n    \n      197519\n      CA\n      F\n      2011\n      Zyrah\n      5\n    \n    \n      232144\n      CA\n      F\n      2020\n      Zyrah\n      5\n    \n    \n      217415\n      CA\n      F\n      2016\n      Zyrah\n      5\n    \n    \n      220674\n      CA\n      F\n      2017\n      Zyrah\n      6\n    \n  \n\n\n\n\nThis offers us a lot of functionality, but what if we need to sort by some other metric? For example, what if we wanted to find the longest names in the DataFrame?\nWe can do this by specifying the key parameter of .sort_values. The key parameter is assigned to a function of our choice. This function is then applied to each value in the specified column. Pandas will, finally, sort the DataFrame by the values outputted by the function.\n\n# Here, a lambda function is applied to find the length of each value, `x`, in the \"Name\" column\nbabynames.sort_values(\"Name\", key = lambda x: x.str.len(), ascending=False).head(5)\n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n    \n  \n  \n    \n      313143\n      CA\n      M\n      1989\n      Franciscojavier\n      6\n    \n    \n      333732\n      CA\n      M\n      1997\n      Ryanchristopher\n      5\n    \n    \n      330421\n      CA\n      M\n      1996\n      Franciscojavier\n      8\n    \n    \n      323615\n      CA\n      M\n      1993\n      Johnchristopher\n      5\n    \n    \n      310235\n      CA\n      M\n      1988\n      Franciscojavier\n      10"
  },
  {
    "objectID": "pandas_2/pandas_2.html#adding-and-removing-columns",
    "href": "pandas_2/pandas_2.html#adding-and-removing-columns",
    "title": "Pandas II",
    "section": "Adding and Removing Columns",
    "text": "Adding and Removing Columns\nTo add a new column to a DataFrame, we use a syntax similar to that used when accessing an existing column. Specify the name of the new column by writing dataframe[\"new_column\"], then assign this to a Series or Array containing the values that will populate this column.\n\n# Add a column named \"Length\" that includes the length of each name\nbabynames[\"Length\"] = babynames[\"Name\"].str.len()\nbabynames.head(5)\n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n      Length\n    \n  \n  \n    \n      0\n      CA\n      F\n      1910\n      Mary\n      295\n      4\n    \n    \n      1\n      CA\n      F\n      1910\n      Helen\n      239\n      5\n    \n    \n      2\n      CA\n      F\n      1910\n      Dorothy\n      220\n      7\n    \n    \n      3\n      CA\n      F\n      1910\n      Margaret\n      163\n      8\n    \n    \n      4\n      CA\n      F\n      1910\n      Frances\n      134\n      7\n    \n  \n\n\n\n\nIn the example above, we made use of an in-built function given to us by the str accessor. What if we had wanted to generate the values in our new column using a function of our own making?\nWe can do this using the Series .map method. .map takes in a function as input, and will apply this function to each value of a Series.\nFor example, say we wanted to find the number of occurrences of the sequence “dr” or “ea” in each name.\n\n# First, define a function to count the number of times \"dr\" or \"ea\" appear in each name\ndef dr_ea_count(string):\n    return string.count(\"dr\") + string.count(\"ea\")\n\n# Then, use `map` to apply `dr_ea_count` to each name in the \"Name\" column\nbabynames[\"dr_ea_count\"] = babynames[\"Name\"].map(dr_ea_count)\n\n# Sort the DataFrame by the new \"dr_ea_count\" column so we can see our handiwork\nbabynames.sort_values(by = \"dr_ea_count\", ascending = False).head(5)\n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n      Length\n      dr_ea_count\n    \n  \n  \n    \n      101969\n      CA\n      F\n      1986\n      Deandrea\n      6\n      8\n      3\n    \n    \n      115950\n      CA\n      F\n      1990\n      Deandrea\n      5\n      8\n      3\n    \n    \n      131022\n      CA\n      F\n      1994\n      Leandrea\n      5\n      8\n      3\n    \n    \n      304390\n      CA\n      M\n      1985\n      Deandrea\n      6\n      8\n      3\n    \n    \n      108723\n      CA\n      F\n      1988\n      Deandrea\n      5\n      8\n      3\n    \n  \n\n\n\n\nIf we want to remove a column or row of a DataFrame, we can call the .drop method. Use the axis parameter to specify whether a column or row should be dropped. Unless otherwise specified, Pandas will assume that we are dropping a row by default.\n\n# Drop the row of the DataFrame with label 2\nbabynames = babynames.drop(2, axis=\"rows\")\n\n# Drop our \"dr_ea_count\" and \"length\" columns from the DataFrame\nbabynames = babynames.drop([\"dr_ea_count\", \"Length\"], axis=\"columns\")\nbabynames.head(5)\n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n    \n  \n  \n    \n      0\n      CA\n      F\n      1910\n      Mary\n      295\n    \n    \n      1\n      CA\n      F\n      1910\n      Helen\n      239\n    \n    \n      3\n      CA\n      F\n      1910\n      Margaret\n      163\n    \n    \n      4\n      CA\n      F\n      1910\n      Frances\n      134\n    \n    \n      5\n      CA\n      F\n      1910\n      Ruth\n      128\n    \n  \n\n\n\n\nNotice that we reassigned babynames to the result of babynames.drop(...). This is a subtle, but important point: Pandas table operations do not occur in-place. Calling dataframe.drop(...) will output a copy of dataframe with the row/column of interest removed, without modifying the original dataframe table.\nIn other words, if we simply call:\n\n# This creates a copy of `babynames` and removes the row with label 3...\nbabynames.drop(3, axis=\"rows\")\n\n# ...but the original `babynames` is unchanged! \n# Notice that the row with label 3 is still present\nbabynames.head(5)\n\n\n\n\n\n  \n    \n      \n      State\n      Sex\n      Year\n      Name\n      Count\n    \n  \n  \n    \n      0\n      CA\n      F\n      1910\n      Mary\n      295\n    \n    \n      1\n      CA\n      F\n      1910\n      Helen\n      239\n    \n    \n      3\n      CA\n      F\n      1910\n      Margaret\n      163\n    \n    \n      4\n      CA\n      F\n      1910\n      Frances\n      134\n    \n    \n      5\n      CA\n      F\n      1910\n      Ruth\n      128\n    \n  \n\n\n\n\nOur original babynames DataFrame will remain unmodified."
  },
  {
    "objectID": "pandas_2/pandas_2.html#aggregating-data-with-groupby",
    "href": "pandas_2/pandas_2.html#aggregating-data-with-groupby",
    "title": "Pandas II",
    "section": "Aggregating Data with GroupBy",
    "text": "Aggregating Data with GroupBy\nUp until this point, we have been working with individual rows of DataFrames. As Data Scientists, we often wish to investigate trends across a larger subset of our data. For example, we may want to compute some summary statistic (the mean, median, mode, etc.) for a group of rows in our DataFrame. To do this, we’ll use Pandas GroupBy objects.\nLet’s say we wanted to aggregate all rows in babynames for a given year.\n\nbabynames.groupby(\"Year\")\n\n<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f99631d2d30>\n\n\nWhat does this strange output mean? Calling .groupby has generated a GroupBy object. You can imagine this as a set of “mini” DataFrames, where each mini DataFrame contains all of the rows from babynames that correspond to a particular year.\nThe diagram below shows a simplified view of babynames to help illustrate this idea.\n\n\n\nCreating a GroupBy object\n\n\nWe can’t work with a GroupBy object directly – that is why you saw that strange output earlier, rather than a standard view of a DataFrame. To actually manipulate values within these “mini” DataFrames, we’ll need to call an aggregation method. This is a method that tells Pandas how to aggregate the values within the GroupBy object. Once the aggregation is applied, Pandas will return a normal (now grouped) DataFrame.\nThe first aggregation method we’ll consider is .agg. The .agg method takes in a function as its argument; this function is then applied to each column of a “mini” grouped DataFrame. We end up with a new DataFrame with one aggregated row per subframe. Let’s see this in action by finding the sum of all counts for each year in babynames – this is equivalent to finding the number of babies born in each year.\n\nbabynames.groupby(\"Year\").agg(sum).head(5)\n\n\n\n\n\n  \n    \n      \n      Count\n    \n    \n      Year\n      \n    \n  \n  \n    \n      1910\n      8943\n    \n    \n      1911\n      9983\n    \n    \n      1912\n      17946\n    \n    \n      1913\n      22094\n    \n    \n      1914\n      26926\n    \n  \n\n\n\n\nWe can relate this back to the diagram we used above. Remember that the diagram uses a simplified version of babynames, which is why we see smaller values for the summed counts.\n\n\n\nPerforming an aggregation\n\n\nCalling .agg has condensed each subframe back into a single row. This gives us our final output: a DataFrame that is now indexed by \"Year\", with a single row for each year in the original babynames DataFrame.\nYou may be wondering: where did the \"State\", \"Sex\", and \"Name\" columns go? Logically, it doesn’t make sense to sum the string data in these columns (how would we add “Mary” + “Ann”?). Because of this, Pandas will simply omit these columns when it performs the aggregation on the DataFrame. Since this happens implicitly, without the user specifying that these columns should be ignored, it’s easy to run into troubling situations where columns are removed without the programmer noticing. It is better coding practice to select only the columns we care about before performing the aggregation.\n\n# Same result, but now we explicitly tell Pandas to only consider the \"Count\" column when summing\nbabynames.groupby(\"Year\")[[\"Count\"]].agg(sum).head(5)\n\n\n\n\n\n  \n    \n      \n      Count\n    \n    \n      Year\n      \n    \n  \n  \n    \n      1910\n      8943\n    \n    \n      1911\n      9983\n    \n    \n      1912\n      17946\n    \n    \n      1913\n      22094\n    \n    \n      1914\n      26926\n    \n  \n\n\n\n\nThere is a whole host of aggregation methods we can use other than .agg. Some useful options are:\n\n.max: creates a new DataFrame with the maximum value of each group\n.mean: creates a new DataFrame with the mean value of each group\n.size: creates a new Series with the number of entries in each group\n.filter: creates a copy of the original DataFrame, keeping only the rows from subframes that obey a provided condition"
  },
  {
    "objectID": "pandas_2/pandas_2.html#aggregating-data-with-pivot-tables",
    "href": "pandas_2/pandas_2.html#aggregating-data-with-pivot-tables",
    "title": "Pandas II",
    "section": "Aggregating Data with Pivot Tables",
    "text": "Aggregating Data with Pivot Tables"
  },
  {
    "objectID": "pandas_2/pandas_2.html#joining-tables",
    "href": "pandas_2/pandas_2.html#joining-tables",
    "title": "Pandas II",
    "section": "Joining Tables",
    "text": "Joining Tables"
  }
]