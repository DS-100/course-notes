{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Pandas II\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 5\n",
    "    toc-location: right\n",
    "    code-fold: false\n",
    "    theme:\n",
    "      - cosmo\n",
    "      - cerulean\n",
    "    callout-icon: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "## Learning Outcomes\n",
    "* Build familiarity with advanced `pandas` syntax\n",
    "* Extract data from a DataFrame using conditional selection\n",
    "* Recognize situations where aggregation is useful and identify the correct technique for performing an aggregation\n",
    ":::\n",
    "\n",
    "Last time, we introduced the `pandas` library as a toolkit for processing data. We learned the DataFrame and Series data structures, familiarized ourselves with the basic syntax for manipulating tabular data, and began writing our first lines of `pandas` code.\n",
    "\n",
    "\n",
    "In this lecture, we'll start to dive into some advanced `pandas` syntax. You may find it helpful to follow along with a notebook of your own as we walk through these new pieces of code.\n",
    "\n",
    "We'll start by loading the `babynames` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os.path\n",
    "import zipfile\n",
    "\n",
    "data_url = \"https://www.ssa.gov/oact/babynames/state/namesbystate.zip\"\n",
    "local_filename = \"babynamesbystate.zip\"\n",
    "if not os.path.exists(local_filename): # if the data exists don't download again\n",
    "    with urllib.request.urlopen(data_url) as resp, open(local_filename, 'wb') as f:\n",
    "        f.write(resp.read())\n",
    "\n",
    "zf = zipfile.ZipFile(local_filename, 'r')\n",
    "\n",
    "ca_name = 'CA.TXT'\n",
    "field_names = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "with zf.open(ca_name) as fh:\n",
    "    babynames = pd.read_csv(fh, header=None, names=field_names)\n",
    "\n",
    "babynames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Selection\n",
    "\n",
    "Conditional selection allows us to select a subset of rows in a DataFrame if they follow some specified condition.\n",
    "\n",
    "To understand how to use conditional selection, we must look at another possible input of the `.loc` and `[]` methods – a boolean array, which is simply an array where each element is either `True` or `False`. This boolean array must have a length equal to the number of rows in the DataFrame. It will return all rows in the position of a corresponding True value in the array.\n",
    "\n",
    "To see this in action, let's select all even-indexed rows in the first 10 rows of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Ask yourself: why is :9 is the correct slice to select the first 10 rows?\n",
    "babynames_first_10_rows = babynames.loc[:9, :]\n",
    "\n",
    "# Notice how we have exactly 10 elements in our boolean array argument\n",
    "babynames_first_10_rows[[True, False, True, False, True, False, True, False, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a similar operation using `.loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "babynames_first_10_rows.loc[[True, False, True, False, True, False, True, False, True, False], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These techniques worked well in this example, but you can imagine how tedious it might be to list out `True`s and `False`s for every row in a larger DataFrame. To make things easier, we can instead provide a logical condition as an input to `.loc` or `[]` that returns a boolean array with the necessary length.\n",
    "\n",
    "For example, to return all names associated with `F` sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "# First, use a logical condition to generate a boolean array\n",
    "logical_operator = (babynames[\"Sex\"] == \"F\")\n",
    "\n",
    "# Then, use this boolean array to filter the DataFrame\n",
    "babynames[logical_operator].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `logical_operator` evaluates to a Series of boolean values with length 400762."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "print(\"There are a total of {} values in 'logical_operator'\".format(len(logical_operator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows starting at row 0 and ending at row 235790 evaluate to `True` and are thus returned in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "print(\"The 0th item in this 'logical_operator' is: {}\".format(logical_operator.iloc[0]))\n",
    "print(\"The 235790th item in this 'logical_operator' is: {}\".format(logical_operator.iloc[235790]))\n",
    "print(\"The 235791th item in this 'logical_operator' is: {}\".format(logical_operator.iloc[235791]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a Series as an argument to `babynames[]` has the same affect as using a boolean array. In fact, the `[]` selection operator can take a boolean Series, array, and list as arguments. These three are used interchangeably thoughout the course.\n",
    "\n",
    "We can also use `.loc` to achieve similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "babynames.loc[babynames[\"Sex\"] == \"F\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean conditions can be combined using various operators that allow us to filter results by multiple conditions. Some examples include the `&` (and) operator and the `|` (or) operator.\n",
    "\n",
    "**Note:** When combining multiple conditions with logical operators, be sure to surround each condition with a set of parenthesis `()`. If you forget, your code will throw an error.\n",
    "\n",
    "For example, if we want to return data on all females born before the 21st century, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "babynames[(babynames[\"Sex\"] == \"F\") & (babynames[\"Year\"] < 2000)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean array selection is a useful tool, but can lead to overly verbose code for complex conditions. `Pandas` provide many alternatives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "(\n",
    "    babynames[(babynames[\"Name\"] == \"Bella\") | \n",
    "              (babynames[\"Name\"] == \"Alex\") |\n",
    "              (babynames[\"Name\"] == \"Ani\") |\n",
    "              (babynames[\"Name\"] == \"Lisa\")]\n",
    ").head()\n",
    "# Note: The parentheses surrounding the code make it possible to break the code on to multiple lines for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.isin` function can be used to filter dataframes. The method helps in selecting rows with having a particular (or multiple) value in a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "names = [\"Bella\", \"Alex\", \"Ani\", \"Lisa\"]\n",
    "babynames[babynames[\"Name\"].isin(names)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `str.startswith` can be used to define a filter based on string values in a `Series` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[babynames[\"Name\"].str.startswith(\"N\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Utility Functions\n",
    "\n",
    "`pandas` contains an extensive library of functions that can help shorten the process of setting and getting information from its data structures. In the following section, we will give overviews of each of the main utility functions that will help us in Data 100.\n",
    "\n",
    "- `Numpy` and built-in function support\n",
    "- `.shape`\n",
    "- `.size`\n",
    "- `.describe() `\n",
    "- `.sample()`\n",
    "- `.value_counts()`\n",
    "- `.unique()`\n",
    "- `.sort_values()`\n",
    "\n",
    "### `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "bella_counts = babynames[babynames[\"Name\"] == \"Bella\"][\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "# Average number of babies named Bella each year\n",
    "np.mean(bella_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "# Max number of babies named Bella born on a given year\n",
    "max(bella_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.shape` and `.size`\n",
    "\n",
    "`.shape` and `.size` are attributes of Series and DataFrames that measure the \"amount\" of data stored in the structure. Calling `.shape` returns a tuple containing the number of rows and columns present in the DataFrame or Series. `.size` is used to find the total number of elements in a structure, equivalent to the number of rows times the number of columns. \n",
    "\n",
    "Many functions strictly require the dimensions of the arguments along certain axes to match. Calling these dimension-finding functions is much faster than counting all of the items by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.describe()`\n",
    "\n",
    "If many statistics are required from a DataFrame (minimum value, maximum value, mean value, etc.), then [`.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) can be used to compute all of them at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different set of statistics will be reported if `.describe()` is called on a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[\"Sex\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.sample()`\n",
    "\n",
    "As we will see later in the semester, random processes are at the heart of many data science techniques (for example, train-test splits, bootstrapping, and cross-validation). [`.sample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) lets us quickly select random entries (a row if called from a DataFrame, or a value if called from a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.sample(5).iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[babynames[\"Year\"] == 2000].sample(4, replace = True).iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.value_counts()`\n",
    "\n",
    "When we want to know the distribution of the items in a Series (for example, what items are most/least common), we use [`.value-counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) to get a breakdown of the unique *values* and their *counts*. In the example below, we can determine the name with the most years in which at least one person has taken that name by counting the number of times each name appears in the `\"Name\"` column of `babynames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[\"Name\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.unique()`\n",
    "\n",
    "If we have a Series with many repeated values, then [`.unique()`](https://pandas.pydata.org/docs/reference/api/pandas.unique.html)  can be used to identify only the *unique* values. Here we can get a list of all the names in `babynames`. \n",
    "\n",
    "**Exercise:** what function can we call on the Series below to get the number of unique names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[\"Name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.sort_values()`\n",
    "\n",
    "Ordering a DataFrame can be useful for isolating extreme values. For example, the first 5 entries of a row sorted in descending order (that is, from highest to lowest) are the largest 5 values. [`.sort_values`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) allows us to order a DataFrame or Series by a specified rule. For DataFrames, we must specify the column by which we want to compare the rows and the function will return such rows. We can choose to either receive the rows in `ascending` order (default) or `descending` order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames.sort_values(by = \"Count\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to explicitly specify the column used for sorting when calling `.value_counts()` on a Series. We can still specify the ordering paradigm – that is, whether values are sorted in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "babynames[\"Name\"].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting With a Custom Key\n",
    "\n",
    "Using `.sort_values` can be useful in many situations, but it many not cover all use cases. This is because `pandas` automatically sorts values in order according to numeric value (for number data) or alphabetical order (for string data). The following code finds the top 5 most popular names in California in 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Sort names by count in year 2021\n",
    "# Recall that `.head(5)` displays the first five rows in the DataFrame\n",
    "babynames[babynames[\"Year\"] == 2021].sort_values(\"Count\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This offers us a lot of functionality, but what if we need to sort by some other metric? For example, what if we wanted to find the longest names in the DataFrame?\n",
    "\n",
    "We can do this by specifying the `key` parameter of `.sort_values`. The `key` parameter is assigned to a function of our choice. This function is then applied to each value in the specified column. `pandas` will, finally, sort the DataFrame by the values outputted by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Here, a lambda function is applied to find the length of each value, `x`, in the \"Name\" column\n",
    "babynames.sort_values(\"Name\", key=lambda x: x.str.len(), ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and Removing Columns\n",
    "\n",
    "To add a new column to a DataFrame, we use a syntax similar to that used when accessing an existing column. Specify the name of the new column by writing `dataframe[\"new_column\"]`, then assign this to a Series or Array containing the values that will populate this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Add a column named \"name_lengths\" that includes the length of each name\n",
    "babynames[\"name_lengths\"] = babynames[\"Name\"].str.len()\n",
    "babynames.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the temporary column\n",
    "babynames = babynames.sort_values(by = \"name_lengths\", ascending=False)\n",
    "babynames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we made use of an in-built function given to us by the `str` accessor for getting the length of names. Then we used `name_length` column to sort the dataframe. What if we had wanted to generate the values in our new column using a function of our own making?\n",
    "\n",
    "We can do this using the Series [`.map`](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html) method. `.map` takes in a function as input, and will apply this function to each value of a Series. \n",
    "\n",
    "For example, say we wanted to find the number of occurrences of the sequence \"dr\" or \"ea\" in each name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# First, define a function to count the number of times \"dr\" or \"ea\" appear in each name\n",
    "def dr_ea_count(string):\n",
    "    return string.count(\"dr\") + string.count(\"ea\")\n",
    "\n",
    "# Then, use `map` to apply `dr_ea_count` to each name in the \"Name\" column\n",
    "babynames[\"dr_ea_count\"] = babynames[\"Name\"].map(dr_ea_count)\n",
    "\n",
    "# Sort the DataFrame by the new \"dr_ea_count\" column so we can see our handiwork\n",
    "babynames.sort_values(by = \"dr_ea_count\", ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remove a column or row of a DataFrame, we can call the [`.drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) method. Use the `axis` parameter to specify whether a column or row should be dropped. Unless otherwise specified, `pandas` will assume that we are dropping a row by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "# Drop our \"dr_ea_count\" and \"length\" columns from the DataFrame\n",
    "babynames = babynames.drop([\"dr_ea_count\", \"name_lengths\"], axis=\"columns\")\n",
    "babynames.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we reassigned `babynames` to the result of `babynames.drop(...)`. This is a subtle, but important point: `pandas` table operations **do not occur in-place**. Calling `dataframe.drop(...)` will output a *copy* of `dataframe` with the row/column of interest removed, without modifying the original `dataframe` table. \n",
    "\n",
    "In other words, if we simply call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# This creates a copy of `babynames` and removes the row with label 3...\n",
    "babynames.drop(3, axis=\"rows\")\n",
    "\n",
    "# ...but the original `babynames` is unchanged! \n",
    "# Notice that the row with label 3 is still present\n",
    "babynames.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data with GroupBy\n",
    "\n",
    "Up until this point, we have been working with individual rows of DataFrames. As data scientists, we often wish to investigate trends across a larger *subset* of our data. For example, we may want to compute some summary statistic (the mean, median, sum, etc.) for a group of rows in our DataFrame. To do this, we'll use `pandas` `GroupBy` objects.\n",
    "\n",
    "Let's say we wanted to aggregate all rows in `babynames` for a given year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "babynames.groupby(\"Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this strange output mean? Calling [`.groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) has generated a `GroupBy` object. You can imagine this as a set of \"mini\" sub-DataFrames, where each subframe contains all of the rows from `babynames` that correspond to a particular year. \n",
    "\n",
    "The diagram below shows a simplified view of `babynames` to help illustrate this idea.\n",
    "\n",
    "![Creating a GroupBy object](images/gb.png)\n",
    "\n",
    "We can't work with a `GroupBy` object directly – that is why you saw that strange output earlier, rather than a standard view of a DataFrame. To actually manipulate values within these \"mini\" DataFrames, we'll need to call an *aggregation method*. This is a method that tells `pandas` how to aggregate the values within the `GroupBy` object. Once the aggregation is applied, `pandas` will return a normal (now grouped) DataFrame.\n",
    "\n",
    "The first aggregation method we'll consider is `.agg`. The `.agg` method takes in a function as its argument; this function is then applied to each column of a \"mini\" grouped DataFrame. We end up with a new DataFrame with one aggregated row per subframe. Let's see this in action by finding the `sum` of all counts for each year in `babynames` – this is equivalent to finding the number of babies born in each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "babynames.groupby(\"Year\").agg(sum).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can relate this back to the diagram we used above. Remember that the diagram uses a simplified version of `babynames`, which is why we see smaller values for the summed counts.\n",
    "\n",
    "![Performing an aggregation](images/agg.png)\n",
    "\n",
    "Calling `.agg` has condensed each subframe back into a single row. This gives us our final output: a DataFrame that is now indexed by `\"Year\"`, with a single row for each unique year in the original `babynames` DataFrame.\n",
    "\n",
    "You may be wondering: where did the `\"State\"`, `\"Sex\"`, and `\"Name\"` columns go? Logically, it doesn't make sense to `sum` the string data in these columns (how would we add \"Mary\" + \"Ann\"?). Because of this, `pandas` will simply omit these columns when it performs the aggregation on the DataFrame. Since this happens implicitly, without the user specifying that these columns should be ignored, it's easy to run into troubling situations where columns are removed without the programmer noticing. It is better coding practice to select *only* the columns we care about before performing the aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Same result, but now we explicitly tell Pandas to only consider the \"Count\" column when summing\n",
    "babynames.groupby(\"Year\")[[\"Count\"]].agg(sum).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parting note\n",
    "\n",
    "Manipulating `DataFrames` is a skill that is not mastered in just one day. Due to the flexibility of `pandas`, there are many different ways to get from a point A to a point B. We recommend trying multiple different ways to solve the same problem to gain even more practice and reach that point of mastery sooner.  \n",
    "\n",
    "Next, we will start digging deeper into the mechanics behind grouping data. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
