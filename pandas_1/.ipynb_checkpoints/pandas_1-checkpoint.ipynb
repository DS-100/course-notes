{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Pandas I\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 5\n",
    "    toc-location: right\n",
    "    code-fold: false\n",
    "    theme:\n",
    "      - cosmo\n",
    "      - cerulean\n",
    "    callout-icon: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "## Learning Outcomes\n",
    "\n",
    "- Build familiarity with basic `pandas` syntax\n",
    "- Learn the methods of selecting and filtering data from a DataFrame.\n",
    "- Understand the differences between DataFrames and Series\n",
    ":::\n",
    "\n",
    "Data scientists work with data stored in a variety of formats. The primary focus of this class is in understanding tabular data -- one of the most widely used formats in data science. This note introduces DataFrames, which are among the most popular representations of tabular data. Weâ€™ll also introduce `pandas`, the standard Python package for manipulating data in DataFrames.\n",
    "\n",
    "## Introduction to Exploratory Data Analysis\n",
    "\n",
    "Imagine you collected, or have been given a box of data. What do you do next? \n",
    "\n",
    "<img src=\"images/understand_data.png\" alt='understand_data' width='500'>\n",
    "\n",
    "The first step is to clean your data. **Data cleaning** often corrects issues in the structure and formatting of data, including missing values and unit conversions.\n",
    "\n",
    "Data scientists have coined the term **exploratory data analysis (EDA)** to describe the process of transforming raw data to insightful observations. EDA is an *open-ended* analysis of transforming, visualizing, and summarizing patterns in data. In order to conduct EDA, we first need to familiarize ourselves with `pandas` -- an important programming tool.\n",
    "\n",
    "## Introduction to Pandas\n",
    "\n",
    "`pandas` is a data analysis library to make data cleaning and analysis fast and convenient in Python. \n",
    "\n",
    "The `pandas` library adopts many coding idioms from `NumPy`. The biggest difference is that `pandas` is designed for working with tabular data, one of the most common data formats (and the focus of Data 100).\n",
    "\n",
    "Before writing any code, we must import `pandas` into our Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `pd` is the conventional alias for Pandas, as `np` is for NumPy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series, DataFrames, and Indices\n",
    "\n",
    "There are three fundamental data structures in `pandas`:\n",
    "\n",
    "1. **Series**: 1D labeled array data; best thought of as columnar data\n",
    "2. **DataFrame**: 2D tabular data with rows and columns\n",
    "3. **Index**: A sequence of row/column labels\n",
    "\n",
    "DataFrames, Series, and Indices can be represented visually in the following diagram.\n",
    "\n",
    "![](images/df_series_index.png)\n",
    "\n",
    "Notice how the **DataFrame** is a two dimensional object -- it contains both rows and columns. The **Series** above is a singular column of this DataFrame, namely the `Candidate` column. Both contain an **Index**, or a shared list of row labels (the integers from 0 to 5, inclusive).\n",
    "\n",
    "### Series\n",
    "\n",
    "A Series represents a column of a DataFrame; more generally, it can be any 1-dimensional array-like object containing values of the same type with associated data labels, called its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([-1, 10, 2])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.array # Data contained within the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index # The Index of the Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, row indices in `pandas` are a sequential list of integers beginning from 0. Optionally, a list of desired indices can be passed to the `index` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([-1, 10, 2], index = [\"a\", \"b\", \"c\"])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices can also be changed after initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index = [\"first\", \"second\", \"third\"]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection in Series\n",
    "\n",
    "Similar to an array, we can select a single value or a set of values from a Series. There are 3 primary methods of selecting data.\n",
    "\n",
    "1. A single index label\n",
    "2. A list of index labels\n",
    "3. A filtering condition\n",
    "\n",
    "Let's define the following Series `ser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([4, -2, 0, 6], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Single Index Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ser[\"a\"]) # Notice how the return value is a single array element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A List of Index Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[[\"a\", \"c\"]] # Notice how the return value is another Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Filtering Condition\n",
    "\n",
    "Perhaps the most interesting (and useful) method of selecting data from a Series is with a filtering condition. \n",
    "\n",
    "We first must apply a vectorized boolean operation to our Series that encodes the filter conditon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser > 0 # Filter condition: select all elements greater than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon \"indexing\" in our Series with this condition, `pandas` selects only the rows with `True` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[ser > 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "\n",
    "In Data 8, you encountered the `Table` class of the `datascience` library, which represented tabular data. In Data 100, we'll be using the `DataFrame` class of the `pandas` library.\n",
    "\n",
    "Here is an example of a DataFrame that contains election data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dissect the code above. \n",
    "\n",
    "1. We first import the ````pandas```` library into our Python environment, using the alias `pd`. <br> &emsp;```` import pandas as pd ````\n",
    "\n",
    "2. There are a number of ways to read data into a DataFrame. In Data 100, our data are typically stored in a CSV (comma-seperated values) file format. We can import a CSV file into a DataFrame by passing the data path as an argument to the following ````pandas```` function. \n",
    "<br> &emsp;```` pd.read_csv(\"elections.csv\") ```` \n",
    "\n",
    "This code stores our DataFrame object in the ````elections```` variable. Upon inspection, our ````elections```` DataFrame has 182 rows and 6 columns (`Year`, `Candidate`, `Party`, `Popular Vote`, `Result`, `%`). Each row represents a single record -- in our example, a presedential candidate from some particular year. Each column represents a single attribute, or feature of the record.\n",
    "\n",
    "In the example above, we constructed a DataFrame object using data from a CSV file. As we'll explore in the next section, we can create a DataFrame with data of our own.\n",
    "\n",
    "#### Creating a DataFrame\n",
    "\n",
    "There are many ways to create a DataFrame. Here, we will cover the most popular approaches.\n",
    "\n",
    "1. Using a list and column names\n",
    "2. From a dictionary\n",
    "3. From a Series\n",
    "\n",
    "##### Using a List and Column Names\n",
    "\n",
    "Consider the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.DataFrame([1, 2, 3], columns=[\"Numbers\"])\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code cell creates a DataFrame with a single column `Numbers`, while the second creates a DataFrame with an additional column `Description`. Notice how a 2D list of values is required to initialize the second DataFrame -- each nested list represents a single row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.DataFrame([[1, \"one\"], [2, \"two\"]], columns = [\"Number\", \"Description\"])\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From a Dictionary\n",
    "\n",
    "A second (and more common) way to create a DataFrame is with a dictionary. The dictionary keys represent the column names, and the dictionary values represent the column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.DataFrame({\"Fruit\": [\"Strawberry\", \"Orange\"], \"Price\": [5.49, 3.99]})\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From a Series\n",
    "\n",
    "Earlier, we explained how a Series was synonymous to a column in a DataFrame. It follows then, that a DataFrame is equivalent to a collection of Series, which all share the same index. \n",
    "\n",
    "In fact, we can initialize a DataFrame by merging two or more Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how our indices, or row labels, are the same\n",
    "\n",
    "s_a = pd.Series([\"a1\", \"a2\", \"a3\"], index = [\"r1\", \"r2\", \"r3\"])\n",
    "s_b = pd.Series([\"b1\", \"b2\", \"b3\"], index = [\"r1\", \"r2\", \"r3\"])\n",
    "\n",
    "pd.DataFrame({\"A-column\": s_a, \"B-column\": s_b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices\n",
    "\n",
    "The major takeaway: we can think of a **DataFrame** as a collection of **Series** that all share the same **Index**.\n",
    "\n",
    "On a more technical note, an Index doesn't have to be an integer, nor does it have to be unique. For example, we can set the index of the `elections` Dataframe to be the name of presedential candidates. Selecting a new Series from this modified DataFrame yields the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the index to the \"Candidate\" column\n",
    "elections.set_index(\"Candidate\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/index_comparison_2.png)\n",
    "\n",
    "To retrieve the indices of a DataFrame, simply use the `.index` attribute of the DataFrame class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This resets the index to be the default list of integers\n",
    "elections.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing in DataFrames\n",
    "\n",
    "Now that we've learned how to create DataFrames, let's dive deeper into their capabilities. \n",
    "\n",
    "The API (application programming interface) for the DataFrame class is enormous. In this section, we'll discuss several methods of the DataFrame API that allow us to extract subsets of data.\n",
    "\n",
    "The simplest way to manipulate a DataFrame is to extract a subset of rows and columns, known as **slicing**. We will do so with three primary methods of the DataFrame class:\n",
    "\n",
    "1. `.loc`\n",
    "2. `.iloc`\n",
    "3. `[]`\n",
    "\n",
    "### Indexing with .loc\n",
    "\n",
    "The `.loc` operator selects rows and columns in a DataFrame by their row and column label(s), respectively. The **row labels** (commonly referred to as the **indices**) are the bold text on the far *left* of a DataFrame, while the **column labels** are the column names found at the *top* of a DataFrame.\n",
    "\n",
    "To grab data with `.loc`, we must specify the row and column label(s) where the data exists. The row labels are the first argument to the `.loc` function; the column labels are the second. For example, we can select the the row labeled `0` and the column labeled `Candidate` from the `elections` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.loc[0, 'Candidate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select *multiple* rows and columns, we can use Python slice notation. Here, we select both the first four rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.loc[0:3, 'Year':'Popular vote']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that instead, we wanted *every* column value for the first four rows in the `elections` DataFrame. The shorthand `:` is useful for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.loc[0:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things we should note. Unlike conventional Python, Pandas allows us to slice string values (in our example, the column labels). Secondly, slicing with `.loc` is *inclusive*. Notice how our resulting DataFrame includes every row and column between and including the slice labels we specified.\n",
    "\n",
    "Equivalently, we can use a list to obtain multiple rows and columns in our `elections` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can interchange list and slicing notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.loc[[0, 1, 2, 3], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing with .iloc\n",
    "\n",
    "Slicing with `.iloc` works similarily to `.loc`, although `.iloc` uses the integer positions of rows and columns rather the labels. The arguments to the `.iloc` function also behave similarly - single values, lists, indices, and any combination of these are permitted. \n",
    "\n",
    "Let's begin reproducing our results from above. We'll begin by selecting for the first presedential candidate in our `elections` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elections.loc[0, \"Candidate\"] - Previous approach\n",
    "elections.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the first argument to both `.loc` and `.iloc` are the same. This is because the row with a label of 0 is conveniently in the 0^th^ (or first) position of the `elections` DataFrame. Generally, this is true of any DataFrame where the row labels are incremented in ascending order from 0.\n",
    "\n",
    "However, when we select the first four rows and columns using `.iloc`, we notice something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elections.loc[0:3, 'Year':'Popular vote'] - Previous approach\n",
    "elections.iloc[0:4, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing is no longer inclusive in `.iloc` - it's *exclusive*. This is one of Pandas syntatical subtleties; you'll get used to with practice.\n",
    "\n",
    "List behavior works just as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elections.loc[[0, 1, 2, 3], ['Year', 'Candidate', 'Party', 'Popular vote']] - Previous Approach\n",
    "elections.iloc[[0, 1, 2, 3], [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discussion begs the question: when should we use `.loc` vs `.iloc`? In most cases, `.loc` is generally safer to use. You can imagine `.iloc` may return incorrect values when applied to a dataset where the ordering of data can change. \n",
    "\n",
    "### Indexing with []\n",
    "\n",
    "The `[]` selection operator is the most baffling of all, yet the commonly used. It only takes a single argument, which may be one of the following:\n",
    "\n",
    "1. A slice of row numbers\n",
    "2. A list of column labels\n",
    "3. A single column label\n",
    "\n",
    "That is, `[]` is *context dependent*. Let's see some examples.\n",
    "\n",
    "#### A slice of row numbers\n",
    "\n",
    "Say we wanted the first four rows of our `elections` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of column labels\n",
    "\n",
    "Suppose we now want the first four columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[[\"Year\", \"Candidate\", \"Party\", \"Popular vote\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A single column label\n",
    "\n",
    "Lastly, if we only want the `Candidate` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[\"Candidate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks like a Series! In this course, we'll become very comfortable with `[]`, especially for selecting columns. In practice, `[]` is much more common than `.loc`.\n",
    "\n",
    "## Parting Note\n",
    "\n",
    "The `pandas` library is enormous and contains many useful functions. Here is a link to [documentation](https://pandas.pydata.org/docs/).\n",
    "\n",
    "The introductory `pandas` lectures will cover important data structures and methods you should be fluent in. However, we want you to get familiar with the real world programming practice of ...Googling! Answers to your questions can be found in documentation, Stack Overflow, etc. \n",
    "\n",
    "With that, let's move on to Pandas II.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
