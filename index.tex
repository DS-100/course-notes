% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Principles and Techniques of Data Science},
  pdfauthor={Kanu Grover; Bella Crouch},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Principles and Techniques of Data Science}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Data 100}
\author{Kanu Grover \and Bella Crouch}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, frame hidden, breakable, enhanced, sharp corners, interior hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{welcome}{%
\chapter*{Welcome}\label{welcome}}
\addcontentsline{toc}{chapter}{Welcome}

\markboth{Welcome}{Welcome}

\hypertarget{about-the-course-notes}{%
\section*{About the Course Notes}\label{about-the-course-notes}}
\addcontentsline{toc}{section}{About the Course Notes}

\markright{About the Course Notes}

This text was developed for the Spring 2023 Edition of the UC Berkeley
course Data 100: Principles and Techniques of Data Science.

As this project is in development during the Spring 2023 semester, the
course notes may be in flux. We appreciate your understanding. If you
spot any errors or would like to suggest any changes, please email us.
\textbf{Email}: data100.instructors@berkeley.edu

\bookmarksetup{startatroot}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, left=2mm, colback=white, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, coltitle=black, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, toprule=.15mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacityback=0, opacitybacktitle=0.6]

\begin{itemize}
\tightlist
\item
  Understand the stages of the data science lifecycle.
\end{itemize}

\end{tcolorbox}

Data science is an interdisciplinary field with a variety of
applications. The field is rapidly evolving; many of the key technical
underpinnings in modern-day data science have been popularized during
the early 21\textsuperscript{st} century.

A true mastery of data science requires a deep theoretical understanding
and strong grasp of domain expertise. This course will help you build on
the former -- specifically, the foundation of your technical knowledge.
To do so, we've organized concepts in Data 100 around the \textbf{data
science lifecycle}: an iterative process that encompasses the various
statistical and computational building blocks of data science.

\hypertarget{data-science-lifecycle}{%
\section{Data Science Lifecycle}\label{data-science-lifecycle}}

The data science lifecycle is a high-level overview of the data science
workflow. It's a cycle of stages that a data scientist should explore as
they conduct a thorough analysis of a data-driven problem.

There are many variations of the key ideas present in the data science
lifecycle. In Data 100, we visualize the stages of the lifecycle using a
flow diagram. Notice how there are two entry points.

\hypertarget{ask-a-question}{%
\subsection{Ask a Question}\label{ask-a-question}}

Whether by curiosity or necessity, data scientists will constantly ask
questions. For example, in the business world, data scientists may be
interested in predicting the profit generated by a certain investment.
In the field of medicine, they may ask whether some patients are more
likely than others to benefit from a treatment.

Posing questions is one of the primary ways the data science lifecycle
begins. It helps to fully define the question. Here are some things you
should ask yourself before framing a question.

\begin{itemize}
\tightlist
\item
  What do we want to know?

  \begin{itemize}
  \tightlist
  \item
    A question that is too ambiguous may lead to confusion.
  \end{itemize}
\item
  What problems are we trying to solve?

  \begin{itemize}
  \tightlist
  \item
    The goal of asking a question should be clear in order to justify
    your efforts to stakeholders.
  \end{itemize}
\item
  What are the hypotheses we want to test?

  \begin{itemize}
  \tightlist
  \item
    This gives a clear perspective from which to analyze final results.
  \end{itemize}
\item
  What are the metrics for our success?

  \begin{itemize}
  \tightlist
  \item
    This gives a clear point to know when to finish the project.
  \end{itemize}
\end{itemize}

\hypertarget{obtain-data}{%
\subsection{Obtain Data}\label{obtain-data}}

The second entry point to the lifecycle is by obtaining data. A careful
analysis of any problem requires the use of data. Data may be readily
available to us, or we may have to embark on a process to collect it.
When doing so, its crucial to ask the following:

\begin{itemize}
\tightlist
\item
  What data do we have and what data do we need?

  \begin{itemize}
  \tightlist
  \item
    Define the units of the data (people, cities, points in time, etc.)
    and what features to measure.
  \end{itemize}
\item
  How will we sample more data?

  \begin{itemize}
  \tightlist
  \item
    Scrape the web, collect manually, etc.
  \end{itemize}
\item
  Is our data representative of the population we want to study?

  \begin{itemize}
  \tightlist
  \item
    If our data is not representative of our population of interest,
    then we can come to incorrect conclusions.
  \end{itemize}
\end{itemize}

Key procedures: \emph{data acquisition}, \emph{data cleaning}

\hypertarget{understand-the-data}{%
\subsection{Understand the Data}\label{understand-the-data}}

Raw data itself is not inherently useful. It's impossible to discern all
the patterns and relationships between variables without carefully
investigating them. Therefore, translating pure data to actionable
insights is a key job of a data scientist. For example, we may choose to
ask:

\begin{itemize}
\tightlist
\item
  How is our data organized and what does it contain?

  \begin{itemize}
  \tightlist
  \item
    Knowing what the data says about the world helps us better
    understand the world.
  \end{itemize}
\item
  Do we have relevant data?

  \begin{itemize}
  \tightlist
  \item
    If the data we have collected is not useful to the question at hand,
    then we must collected more data.
  \end{itemize}
\item
  What are the biases, anomalies, or other issues with the data?

  \begin{itemize}
  \tightlist
  \item
    These can lead to many false conclusions if ignored, so data
    scientists must always be aware of these issues.
  \end{itemize}
\item
  How do we transform the data to enable effective analysis?

  \begin{itemize}
  \tightlist
  \item
    Data is not always easy to interpret at first glance, so a data
    scientist should reveal these hidden insights.
  \end{itemize}
\end{itemize}

Key procedures: \emph{exploratory data analysis}, \emph{data
visualization}.

\hypertarget{understand-the-world}{%
\subsection{Understand the World}\label{understand-the-world}}

After observing the patterns in our data, we can begin answering our
question. This may require that we predict a quantity (machine
learning), or measure the effect of some treatment (inference).

From here, we may choose to report our results, or possibly conduct more
analysis. We may not be satisfied by our findings, or our initial
exploration may have brought up new questions that require a new data.

\begin{itemize}
\tightlist
\item
  What does the data say about the world?

  \begin{itemize}
  \tightlist
  \item
    Given our models, the data will lead us to certain conclusions about
    the real world.\\
  \end{itemize}
\item
  Does it answer our questions or accurately solve the problem?

  \begin{itemize}
  \tightlist
  \item
    If our model and data can not accomplish our goals, then we must
    reform our question, model, or both.\\
  \end{itemize}
\item
  How robust are our conclusions and can we trust the predictions?

  \begin{itemize}
  \tightlist
  \item
    Inaccurate models can lead to untrue conclusions.
  \end{itemize}
\end{itemize}

Key procedures: \emph{model creation}, \emph{prediction},
\emph{inference}.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

The data science lifecycle is meant to be a set of general guidelines
rather than a hard list of requirements. In our journey exploring the
lifecycle, we'll cover both the underlying theory and technologies used
in data science, and we hope you'll build an appreciation for the field.

With that, let's begin by introducing one of the most important tools in
exploratory data analysis: \texttt{pandas}.

\bookmarksetup{startatroot}

\hypertarget{pandas-i}{%
\chapter{Pandas I}\label{pandas-i}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, left=2mm, colback=white, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, coltitle=black, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, toprule=.15mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacityback=0, opacitybacktitle=0.6]

\begin{itemize}
\tightlist
\item
  Build familiarity with basic \texttt{pandas} syntax
\item
  Learn the methods of selecting and filtering data from a DataFrame.
\item
  Understand the differences between DataFrames and Series
\end{itemize}

\end{tcolorbox}

Data scientists work with data stored in a variety of formats. The
primary focus of this class is in understanding tabular data -- one of
the most widely used formats in data science. This note introduces
DataFrames, which are among the most popular representations of tabular
data. We'll also introduce \texttt{pandas}, the standard Python package
for manipulating data in DataFrames.

\hypertarget{introduction-to-exploratory-data-analysis}{%
\section{Introduction to Exploratory Data
Analysis}\label{introduction-to-exploratory-data-analysis}}

Imagine you collected, or have been given a box of data. What do you do
next?

The first step is to clean your data. \textbf{Data cleaning} often
corrects issues in the structure and formatting of data, including
missing values and unit conversions.

Data scientists have coined the term \textbf{exploratory data analysis
(EDA)} to describe the process of transforming raw data to insightful
observations. EDA is an \emph{open-ended} analysis of transforming,
visualizing, and summarizing patterns in data. In order to conduct EDA,
we first need to familiarize ourselves with \texttt{pandas} -- an
important programming tool.

\hypertarget{introduction-to-pandas}{%
\section{Introduction to Pandas}\label{introduction-to-pandas}}

\texttt{pandas} is a data analysis library to make data cleaning and
analysis fast and convenient in Python.

The \texttt{pandas} library adopts many coding idioms from
\texttt{NumPy}. The biggest difference is that \texttt{pandas} is
designed for working with tabular data, one of the most common data
formats (and the focus of Data 100).

Before writing any code, we must import \texttt{pandas} into our Python
environment.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \textasciigrave{}pd\textasciigrave{} is the conventional alias for Pandas, as \textasciigrave{}np\textasciigrave{} is for NumPy}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{series-dataframes-and-indices}{%
\section{Series, DataFrames, and
Indices}\label{series-dataframes-and-indices}}

There are three fundamental data structures in \texttt{pandas}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Series}: 1D labeled array data; best thought of as columnar
  data
\item
  \textbf{DataFrame}: 2D tabular data with rows and columns
\item
  \textbf{Index}: A sequence of row/column labels
\end{enumerate}

DataFrames, Series, and Indices can be represented visually in the
following diagram.

\includegraphics{pandas_1/images/df_series_index.png}

Notice how the \textbf{DataFrame} is a two dimensional object -- it
contains both rows and columns. The \textbf{Series} above is a singular
column of this DataFrame, namely the \texttt{Candidate} column. Both
contain an \textbf{Index}, or a shared list of row labels (the integers
from 0 to 5, inclusive).

\hypertarget{series}{%
\subsection{Series}\label{series}}

A Series represents a column of a DataFrame; more generally, it can be
any 1-dimensional array-like object containing values of the same type
with associated data labels, called its index.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(s)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    -1
1    10
2     2
dtype: int64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s.array }\CommentTok{\# Data contained within the Series}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<PandasArray>
[-1, 10, 2]
Length: 3, dtype: int64
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s.index }\CommentTok{\# The Index of the Series}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
RangeIndex(start=0, stop=3, step=1)
\end{verbatim}

By default, row indices in \texttt{pandas} are a sequential list of
integers beginning from 0. Optionally, a list of desired indices can be
passed to the \texttt{index} argument.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{], index }\OperatorTok{=}\NormalTok{ [}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(s)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    -1
b    10
c     2
dtype: int64
\end{verbatim}

Indices can also be changed after initialization.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s.index }\OperatorTok{=}\NormalTok{ [}\StringTok{"first"}\NormalTok{, }\StringTok{"second"}\NormalTok{, }\StringTok{"third"}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(s)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
first     -1
second    10
third      2
dtype: int64
\end{verbatim}

\hypertarget{selection-in-series}{%
\subsubsection{Selection in Series}\label{selection-in-series}}

Similar to an array, we can select a single value or a set of values
from a Series. There are 3 primary methods of selecting data.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A single index label
\item
  A list of index labels
\item
  A filtering condition
\end{enumerate}

Let's define the following Series \texttt{ser}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ser }\OperatorTok{=}\NormalTok{ pd.Series([}\DecValTok{4}\NormalTok{, }\OperatorTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{], index }\OperatorTok{=}\NormalTok{ [}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(ser)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
a    4
b   -2
c    0
d    6
dtype: int64
\end{verbatim}

\hypertarget{a-single-index-label}{%
\paragraph{A Single Index Label}\label{a-single-index-label}}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(ser[}\StringTok{"a"}\NormalTok{]) }\CommentTok{\# Notice how the return value is a single array element}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
4
\end{verbatim}

\hypertarget{a-list-of-index-labels}{%
\paragraph{A List of Index Labels}\label{a-list-of-index-labels}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ser[[}\StringTok{"a"}\NormalTok{, }\StringTok{"c"}\NormalTok{]] }\CommentTok{\# Notice how the return value is another Series}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  0 \\
\midrule
a &  4 \\
c &  0 \\
\bottomrule
\end{tabular}

\hypertarget{a-filtering-condition}{%
\paragraph{A Filtering Condition}\label{a-filtering-condition}}

Perhaps the most interesting (and useful) method of selecting data from
a Series is with a filtering condition.

We first must apply a vectorized boolean operation to our Series that
encodes the filter conditon.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ser }\OperatorTok{\textgreater{}} \DecValTok{0} \CommentTok{\# Filter condition: select all elements greater than 0}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{ll}
\toprule
{} &      0 \\
\midrule
a &   True \\
b &  False \\
c &  False \\
d &   True \\
\bottomrule
\end{tabular}

Upon ``indexing'' in our Series with this condition, \texttt{pandas}
selects only the rows with \texttt{True} values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ser[ser }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{] }
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  0 \\
\midrule
a &  4 \\
d &  6 \\
\bottomrule
\end{tabular}

\hypertarget{dataframes}{%
\subsection{DataFrames}\label{dataframes}}

In Data 8, you encountered the \texttt{Table} class of the
\texttt{datascience} library, which represented tabular data. In Data
100, we'll be using the \texttt{DataFrame} class of the \texttt{pandas}
library.

Here is an example of a DataFrame that contains election data.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{elections }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/elections.csv"}\NormalTok{)}
\NormalTok{elections.head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 &    win &  56.203927 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 &   loss &  43.796073 \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 &    win &  54.574789 \\
\bottomrule
\end{tabular}

Let's dissect the code above.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We first import the \texttt{pandas} library into our Python
  environment, using the alias \texttt{pd}.
   \texttt{import\ pandas\ as\ pd}
\item
  There are a number of ways to read data into a DataFrame. In Data 100,
  our data are typically stored in a CSV (comma-seperated values) file
  format. We can import a CSV file into a DataFrame by passing the data
  path as an argument to the following \texttt{pandas} function.
   \texttt{pd.read\_csv("elections.csv")}
\end{enumerate}

This code stores our DataFrame object in the \texttt{elections}
variable. Upon inspection, our \texttt{elections} DataFrame has 182 rows
and 6 columns (\texttt{Year}, \texttt{Candidate}, \texttt{Party},
\texttt{Popular\ Vote}, \texttt{Result}, \texttt{\%}). Each row
represents a single record -- in our example, a presedential candidate
from some particular year. Each column represents a single attribute, or
feature of the record.

In the example above, we constructed a DataFrame object using data from
a CSV file. As we'll explore in the next section, we can create a
DataFrame with data of our own.

\hypertarget{creating-a-dataframe}{%
\subsubsection{Creating a DataFrame}\label{creating-a-dataframe}}

There are many ways to create a DataFrame. Here, we will cover the most
popular approaches.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using a list and column names
\item
  From a dictionary
\item
  From a Series
\end{enumerate}

\hypertarget{using-a-list-and-column-names}{%
\paragraph{Using a List and Column
Names}\label{using-a-list-and-column-names}}

Consider the following examples.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_list }\OperatorTok{=}\NormalTok{ pd.DataFrame([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], columns}\OperatorTok{=}\NormalTok{[}\StringTok{"Numbers"}\NormalTok{])}
\NormalTok{df\_list}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  Numbers \\
\midrule
0 &        1 \\
1 &        2 \\
2 &        3 \\
\bottomrule
\end{tabular}

The first code cell creates a DataFrame with a single column
\texttt{Numbers}, while the second creates a DataFrame with an
additional column \texttt{Description}. Notice how a 2D list of values
is required to initialize the second DataFrame -- each nested list
represents a single row of data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_list }\OperatorTok{=}\NormalTok{ pd.DataFrame([[}\DecValTok{1}\NormalTok{, }\StringTok{"one"}\NormalTok{], [}\DecValTok{2}\NormalTok{, }\StringTok{"two"}\NormalTok{]], columns }\OperatorTok{=}\NormalTok{ [}\StringTok{"Number"}\NormalTok{, }\StringTok{"Description"}\NormalTok{])}
\NormalTok{df\_list}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrl}
\toprule
{} &  Number & Description \\
\midrule
0 &       1 &         one \\
1 &       2 &         two \\
\bottomrule
\end{tabular}

\hypertarget{from-a-dictionary}{%
\paragraph{From a Dictionary}\label{from-a-dictionary}}

A second (and more common) way to create a DataFrame is with a
dictionary. The dictionary keys represent the column names, and the
dictionary values represent the column values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_dict }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"Fruit"}\NormalTok{: [}\StringTok{"Strawberry"}\NormalTok{, }\StringTok{"Orange"}\NormalTok{], }\StringTok{"Price"}\NormalTok{: [}\FloatTok{5.49}\NormalTok{, }\FloatTok{3.99}\NormalTok{]\})}
\NormalTok{df\_dict}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llr}
\toprule
{} &       Fruit &  Price \\
\midrule
0 &  Strawberry &   5.49 \\
1 &      Orange &   3.99 \\
\bottomrule
\end{tabular}

\hypertarget{from-a-series}{%
\paragraph{From a Series}\label{from-a-series}}

Earlier, we explained how a Series was synonymous to a column in a
DataFrame. It follows then, that a DataFrame is equivalent to a
collection of Series, which all share the same index.

In fact, we can initialize a DataFrame by merging two or more Series.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Notice how our indices, or row labels, are the same}

\NormalTok{s\_a }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{"a1"}\NormalTok{, }\StringTok{"a2"}\NormalTok{, }\StringTok{"a3"}\NormalTok{], index }\OperatorTok{=}\NormalTok{ [}\StringTok{"r1"}\NormalTok{, }\StringTok{"r2"}\NormalTok{, }\StringTok{"r3"}\NormalTok{])}
\NormalTok{s\_b }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{"b1"}\NormalTok{, }\StringTok{"b2"}\NormalTok{, }\StringTok{"b3"}\NormalTok{], index }\OperatorTok{=}\NormalTok{ [}\StringTok{"r1"}\NormalTok{, }\StringTok{"r2"}\NormalTok{, }\StringTok{"r3"}\NormalTok{])}

\NormalTok{pd.DataFrame(\{}\StringTok{"A{-}column"}\NormalTok{: s\_a, }\StringTok{"B{-}column"}\NormalTok{: s\_b\})}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lll}
\toprule
{} & A-column & B-column \\
\midrule
r1 &       a1 &       b1 \\
r2 &       a2 &       b2 \\
r3 &       a3 &       b3 \\
\bottomrule
\end{tabular}

\hypertarget{indices}{%
\subsection{Indices}\label{indices}}

The major takeaway: we can think of a \textbf{DataFrame} as a collection
of \textbf{Series} that all share the same \textbf{Index}.

On a more technical note, an Index doesn't have to be an integer, nor
does it have to be unique. For example, we can set the index of the
\texttt{elections} Dataframe to be the name of presedential candidates.
Selecting a new Series from this modified DataFrame yields the
following.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This sets the index to the "Candidate" column}
\NormalTok{elections.set\_index(}\StringTok{"Candidate"}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pandas_1/images/index_comparison_2.png}

To retrieve the indices of a DataFrame, simply use the \texttt{.index}
attribute of the DataFrame class.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.head().index}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Index(['Andrew Jackson', 'John Quincy Adams', 'Andrew Jackson',
       'John Quincy Adams', 'Andrew Jackson'],
      dtype='object', name='Candidate')
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This resets the index to be the default list of integers}
\NormalTok{elections.reset\_index(inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{slicing-in-dataframes}{%
\section{Slicing in DataFrames}\label{slicing-in-dataframes}}

Now that we've learned how to create DataFrames, let's dive deeper into
their capabilities.

The API (application programming interface) for the DataFrame class is
enormous. In this section, we'll discuss several methods of the
DataFrame API that allow us to extract subsets of data.

The simplest way to manipulate a DataFrame is to extract a subset of
rows and columns, known as \textbf{slicing}. We will do so with three
primary methods of the DataFrame class:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{.loc}
\item
  \texttt{.iloc}
\item
  \texttt{{[}{]}}
\end{enumerate}

\hypertarget{indexing-with-.loc}{%
\subsection{Indexing with .loc}\label{indexing-with-.loc}}

The \texttt{.loc} operator selects rows and columns in a DataFrame by
their row and column label(s), respectively. The \textbf{row labels}
(commonly referred to as the \textbf{indices}) are the bold text on the
far \emph{left} of a DataFrame, while the \textbf{column labels} are the
column names found at the \emph{top} of a DataFrame.

To grab data with \texttt{.loc}, we must specify the row and column
label(s) where the data exists. The row labels are the first argument to
the \texttt{.loc} function; the column labels are the second. For
example, we can select the the row labeled \texttt{0} and the column
labeled \texttt{Candidate} from the \texttt{elections} DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.loc[}\DecValTok{0}\NormalTok{, }\StringTok{\textquotesingle{}Candidate\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'Andrew Jackson'
\end{verbatim}

To select \emph{multiple} rows and columns, we can use Python slice
notation. Here, we select both the first four rows and columns.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.loc[}\DecValTok{0}\NormalTok{:}\DecValTok{3}\NormalTok{, }\StringTok{\textquotesingle{}Year\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}Popular vote\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrlr}
\toprule
{} &  Year &                  Party &  Popular vote \\
\midrule
0 &  1824 &  Democratic-Republican &        151271 \\
1 &  1824 &  Democratic-Republican &        113142 \\
2 &  1828 &             Democratic &        642806 \\
3 &  1828 &    National Republican &        500897 \\
\bottomrule
\end{tabular}

Suppose that instead, we wanted \emph{every} column value for the first
four rows in the \texttt{elections} DataFrame. The shorthand \texttt{:}
is useful for this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.loc[}\DecValTok{0}\NormalTok{:}\DecValTok{3}\NormalTok{, :]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llrlrlr}
\toprule
{} &          Candidate &  Year &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &     Andrew Jackson &  1824 &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  John Quincy Adams &  1824 &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &     Andrew Jackson &  1828 &             Democratic &        642806 &    win &  56.203927 \\
3 &  John Quincy Adams &  1828 &    National Republican &        500897 &   loss &  43.796073 \\
\bottomrule
\end{tabular}

There are a couple of things we should note. Unlike conventional Python,
Pandas allows us to slice string values (in our example, the column
labels). Secondly, slicing with \texttt{.loc} is \emph{inclusive}.
Notice how our resulting DataFrame includes every row and column between
and including the slice labels we specified.

Equivalently, we can use a list to obtain multiple rows and columns in
our \texttt{elections} DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.loc[[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], [}\StringTok{\textquotesingle{}Year\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Candidate\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Party\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Popular vote\textquotesingle{}}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 \\
\bottomrule
\end{tabular}

Lastly, we can interchange list and slicing notation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.loc[[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], :]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llrlrlr}
\toprule
{} &          Candidate &  Year &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &     Andrew Jackson &  1824 &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  John Quincy Adams &  1824 &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &     Andrew Jackson &  1828 &             Democratic &        642806 &    win &  56.203927 \\
3 &  John Quincy Adams &  1828 &    National Republican &        500897 &   loss &  43.796073 \\
\bottomrule
\end{tabular}

\hypertarget{indexing-with-.iloc}{%
\subsection{Indexing with .iloc}\label{indexing-with-.iloc}}

Slicing with \texttt{.iloc} works similarily to \texttt{.loc}, although
\texttt{.iloc} uses the integer positions of rows and columns rather the
labels. The arguments to the \texttt{.iloc} function also behave
similarly - single values, lists, indices, and any combination of these
are permitted.

Let's begin reproducing our results from above. We'll begin by selecting
for the first presedential candidate in our \texttt{elections}
DataFrame:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# elections.loc[0, "Candidate"] {-} Previous approach}
\NormalTok{elections.iloc[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
1824
\end{verbatim}

Notice how the first argument to both \texttt{.loc} and \texttt{.iloc}
are the same. This is because the row with a label of 0 is conveniently
in the 0\textsuperscript{th} (or first) position of the
\texttt{elections} DataFrame. Generally, this is true of any DataFrame
where the row labels are incremented in ascending order from 0.

However, when we select the first four rows and columns using
\texttt{.iloc}, we notice something.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# elections.loc[0:3, \textquotesingle{}Year\textquotesingle{}:\textquotesingle{}Popular vote\textquotesingle{}] {-} Previous approach}
\NormalTok{elections.iloc[}\DecValTok{0}\NormalTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{0}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llrlr}
\toprule
{} &          Candidate &  Year &                  Party &  Popular vote \\
\midrule
0 &     Andrew Jackson &  1824 &  Democratic-Republican &        151271 \\
1 &  John Quincy Adams &  1824 &  Democratic-Republican &        113142 \\
2 &     Andrew Jackson &  1828 &             Democratic &        642806 \\
3 &  John Quincy Adams &  1828 &    National Republican &        500897 \\
\bottomrule
\end{tabular}

Slicing is no longer inclusive in \texttt{.iloc} - it's
\emph{exclusive}. This is one of Pandas syntatical subtleties; you'll
get used to with practice.

List behavior works just as expected.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#elections.loc[[0, 1, 2, 3], [\textquotesingle{}Year\textquotesingle{}, \textquotesingle{}Candidate\textquotesingle{}, \textquotesingle{}Party\textquotesingle{}, \textquotesingle{}Popular vote\textquotesingle{}]] {-} Previous Approach}
\NormalTok{elections.iloc[[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llrlr}
\toprule
{} &          Candidate &  Year &                  Party &  Popular vote \\
\midrule
0 &     Andrew Jackson &  1824 &  Democratic-Republican &        151271 \\
1 &  John Quincy Adams &  1824 &  Democratic-Republican &        113142 \\
2 &     Andrew Jackson &  1828 &             Democratic &        642806 \\
3 &  John Quincy Adams &  1828 &    National Republican &        500897 \\
\bottomrule
\end{tabular}

This discussion begs the question: when should we use \texttt{.loc} vs
\texttt{.iloc}? In most cases, \texttt{.loc} is generally safer to use.
You can imagine \texttt{.iloc} may return incorrect values when applied
to a dataset where the ordering of data can change.

\hypertarget{indexing-with}{%
\subsection{Indexing with {[}{]}}\label{indexing-with}}

The \texttt{{[}{]}} selection operator is the most baffling of all, yet
the commonly used. It only takes a single argument, which may be one of
the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A slice of row numbers
\item
  A list of column labels
\item
  A single column label
\end{enumerate}

That is, \texttt{{[}{]}} is \emph{context dependent}. Let's see some
examples.

\hypertarget{a-slice-of-row-numbers}{%
\subsubsection{A slice of row numbers}\label{a-slice-of-row-numbers}}

Say we wanted the first four rows of our \texttt{elections} DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections[}\DecValTok{0}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llrlrlr}
\toprule
{} &          Candidate &  Year &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &     Andrew Jackson &  1824 &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  John Quincy Adams &  1824 &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &     Andrew Jackson &  1828 &             Democratic &        642806 &    win &  56.203927 \\
3 &  John Quincy Adams &  1828 &    National Republican &        500897 &   loss &  43.796073 \\
\bottomrule
\end{tabular}

\hypertarget{a-list-of-column-labels}{%
\subsubsection{A list of column labels}\label{a-list-of-column-labels}}

Suppose we now want the first four columns.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections[[}\StringTok{"Year"}\NormalTok{, }\StringTok{"Candidate"}\NormalTok{, }\StringTok{"Party"}\NormalTok{, }\StringTok{"Popular vote"}\NormalTok{]].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 \\
\bottomrule
\end{tabular}

\hypertarget{a-single-column-label}{%
\subsubsection{A single column label}\label{a-single-column-label}}

Lastly, if we only want the \texttt{Candidate} column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections[}\StringTok{"Candidate"}\NormalTok{].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{ll}
\toprule
{} &          Candidate \\
\midrule
0 &     Andrew Jackson \\
1 &  John Quincy Adams \\
2 &     Andrew Jackson \\
3 &  John Quincy Adams \\
4 &     Andrew Jackson \\
\bottomrule
\end{tabular}

The output looks like a Series! In this course, we'll become very
comfortable with \texttt{{[}{]}}, especially for selecting columns. In
practice, \texttt{{[}{]}} is much more common than \texttt{.loc}.

\hypertarget{parting-note}{%
\section{Parting Note}\label{parting-note}}

The \texttt{pandas} library is enormous and contains many useful
functions. Here is a link to
\href{https://pandas.pydata.org/docs/}{documentation}.

The introductory \texttt{pandas} lectures will cover important data
structures and methods you should be fluent in. However, we want you to
get familiar with the real world programming practice of
\ldots Googling! Answers to your questions can be found in
documentation, Stack Overflow, etc.

With that, let's move on to Pandas II.

\bookmarksetup{startatroot}

\hypertarget{pandas-ii}{%
\chapter{Pandas II}\label{pandas-ii}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, left=2mm, colback=white, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, coltitle=black, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, toprule=.15mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacityback=0, opacitybacktitle=0.6]

\begin{itemize}
\tightlist
\item
  Build familiarity with advanced \texttt{pandas} syntax
\item
  Extract data from a DataFrame using conditional selection
\item
  Recognize situations where aggregation is useful and identify the
  correct technique for performing an aggregation
\end{itemize}

\end{tcolorbox}

Last time, we introduced the \texttt{pandas} library as a toolkit for
processing data. We learned the DataFrame and Series data structures,
familiarized ourselves with the basic syntax for manipulating tabular
data, and began writing our first lines of \texttt{pandas} code.

In this lecture, we'll start to dive into some advanced \texttt{pandas}
syntax. You may find it helpful to follow along with a notebook of your
own as we walk through these new pieces of code.

We'll start by loading the \texttt{babynames} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ urllib.request}
\ImportTok{import}\NormalTok{ os.path}
\ImportTok{import}\NormalTok{ zipfile}

\NormalTok{data\_url }\OperatorTok{=} \StringTok{"https://www.ssa.gov/oact/babynames/state/namesbystate.zip"}
\NormalTok{local\_filename }\OperatorTok{=} \StringTok{"babynamesbystate.zip"}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ os.path.exists(local\_filename): }\CommentTok{\# if the data exists don\textquotesingle{}t download again}
    \ControlFlowTok{with}\NormalTok{ urllib.request.urlopen(data\_url) }\ImportTok{as}\NormalTok{ resp, }\BuiltInTok{open}\NormalTok{(local\_filename, }\StringTok{\textquotesingle{}wb\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{        f.write(resp.read())}

\NormalTok{zf }\OperatorTok{=}\NormalTok{ zipfile.ZipFile(local\_filename, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{)}

\NormalTok{ca\_name }\OperatorTok{=} \StringTok{\textquotesingle{}CA.TXT\textquotesingle{}}
\NormalTok{field\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}State\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sex\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Year\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Name\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Count\textquotesingle{}}\NormalTok{]}
\ControlFlowTok{with}\NormalTok{ zf.}\BuiltInTok{open}\NormalTok{(ca\_name) }\ImportTok{as}\NormalTok{ fh:}
\NormalTok{    babynames }\OperatorTok{=}\NormalTok{ pd.read\_csv(fh, header}\OperatorTok{=}\VariableTok{None}\NormalTok{, names}\OperatorTok{=}\NormalTok{field\_names)}

\NormalTok{babynames.head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &      Name &  Count \\
\midrule
0 &    CA &   F &  1910 &      Mary &    295 \\
1 &    CA &   F &  1910 &     Helen &    239 \\
2 &    CA &   F &  1910 &   Dorothy &    220 \\
3 &    CA &   F &  1910 &  Margaret &    163 \\
4 &    CA &   F &  1910 &   Frances &    134 \\
\bottomrule
\end{tabular}

\hypertarget{conditional-selection}{%
\section{Conditional Selection}\label{conditional-selection}}

Conditional selection allows us to select a subset of rows in a
DataFrame if they follow some specified condition.

To understand how to use conditional selection, we must look at another
possible input of the \texttt{.loc} and \texttt{{[}{]}} methods -- a
boolean array, which is simply an array where each element is either
\texttt{True} or \texttt{False}. This boolean array must have a length
equal to the number of rows in the DataFrame. It will return all rows in
the position of a corresponding True value in the array.

To see this in action, let's select all even-indexed rows in the first
10 rows of our DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ask yourself: why is :9 is the correct slice to select the first 10 rows?}
\NormalTok{babynames\_first\_10\_rows }\OperatorTok{=}\NormalTok{ babynames.loc[:}\DecValTok{9}\NormalTok{, :]}

\CommentTok{\# Notice how we have exactly 10 elements in our boolean array argument}
\NormalTok{babynames\_first\_10\_rows[[}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &      Name &  Count \\
\midrule
0 &    CA &   F &  1910 &      Mary &    295 \\
2 &    CA &   F &  1910 &   Dorothy &    220 \\
4 &    CA &   F &  1910 &   Frances &    134 \\
6 &    CA &   F &  1910 &    Evelyn &    126 \\
8 &    CA &   F &  1910 &  Virginia &    101 \\
\bottomrule
\end{tabular}

We can perform a similar operation using \texttt{.loc}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames\_first\_10\_rows.loc[[}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{], :]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &      Name &  Count \\
\midrule
0 &    CA &   F &  1910 &      Mary &    295 \\
2 &    CA &   F &  1910 &   Dorothy &    220 \\
4 &    CA &   F &  1910 &   Frances &    134 \\
6 &    CA &   F &  1910 &    Evelyn &    126 \\
8 &    CA &   F &  1910 &  Virginia &    101 \\
\bottomrule
\end{tabular}

These techniques worked well in this example, but you can imagine how
tedious it might be to list out \texttt{True}s and \texttt{False}s for
every row in a larger DataFrame. To make things easier, we can instead
provide a logical condition as an input to \texttt{.loc} or
\texttt{{[}{]}} that returns a boolean array with the necessary length.

For example, to return all names associated with \texttt{M} sex:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First, use a logical condition to generate a boolean array}
\NormalTok{logical\_operator }\OperatorTok{=}\NormalTok{ (babynames[}\StringTok{"Sex"}\NormalTok{] }\OperatorTok{==} \StringTok{"M"}\NormalTok{)}

\CommentTok{\# Then, use this boolean array to filter the DataFrame}
\NormalTok{babynames[logical\_operator].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &     Name &  Count \\
\midrule
235791 &    CA &   M &  1910 &     John &    237 \\
235792 &    CA &   M &  1910 &  William &    170 \\
235793 &    CA &   M &  1910 &    James &    159 \\
235794 &    CA &   M &  1910 &   Robert &    141 \\
235795 &    CA &   M &  1910 &   George &    138 \\
\bottomrule
\end{tabular}

Here, \texttt{logical\_operator} evaluates to a Series of boolean values
with length 400762, of which 235791 are \texttt{False}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logical\_operator.describe()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{ll}
\toprule
{} &     Sex \\
\midrule
count  &  400762 \\
unique &       2 \\
top    &   False \\
freq   &  235791 \\
\bottomrule
\end{tabular}

Rows starting at row 235791 and ending at row 400761 evaluate to
\texttt{True} and are thus returned in the DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[logical\_operator].tail()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &   Name &  Count \\
\midrule
400757 &    CA &   M &  2021 &   Zyan &      5 \\
400758 &    CA &   M &  2021 &  Zyion &      5 \\
400759 &    CA &   M &  2021 &  Zyire &      5 \\
400760 &    CA &   M &  2021 &   Zylo &      5 \\
400761 &    CA &   M &  2021 &  Zyrus &      5 \\
\bottomrule
\end{tabular}

Passing a Series as an argument to \texttt{babynames{[}{]}} has the same
affect as using a boolean array. In fact, the \texttt{{[}{]}} selection
operator can take a boolean Series, array, and list as arguments. These
three are used interchangeably thoughout the course.

We can also use \texttt{.loc} to achieve similar results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.loc[babynames[}\StringTok{"Sex"}\NormalTok{] }\OperatorTok{==} \StringTok{"F"}\NormalTok{].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &      Name &  Count \\
\midrule
0 &    CA &   F &  1910 &      Mary &    295 \\
1 &    CA &   F &  1910 &     Helen &    239 \\
2 &    CA &   F &  1910 &   Dorothy &    220 \\
3 &    CA &   F &  1910 &  Margaret &    163 \\
4 &    CA &   F &  1910 &   Frances &    134 \\
\bottomrule
\end{tabular}

Boolean conditions can be combined using various operators that allow us
to filter results by multiple conditions. Some examples include the
\texttt{\&} (and) operator and the \texttt{\textbar{}} (or) operator.

\textbf{Note:} When combining multiple conditions with logical
operators, be sure to surround each condition with a set of parenthesis
\texttt{()}. If you forget, your code will throw an error.

For example, if we want to return data on all females born in the 21st
century, we can write:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[(babynames[}\StringTok{"Sex"}\NormalTok{] }\OperatorTok{==} \StringTok{"F"}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (babynames[}\StringTok{"Year"}\NormalTok{] }\OperatorTok{\textgreater{}} \DecValTok{2000}\NormalTok{)].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &      Name &  Count \\
\midrule
152816 &    CA &   F &  2001 &     Emily &   2928 \\
152817 &    CA &   F &  2001 &    Ashley &   2717 \\
152818 &    CA &   F &  2001 &  Samantha &   2535 \\
152819 &    CA &   F &  2001 &   Jessica &   2244 \\
152820 &    CA &   F &  2001 &    Alyssa &   2059 \\
\bottomrule
\end{tabular}

Boolean array selection is a useful tool, but can lead to overly verbose
code for complex conditions. \texttt{Pandas} provide many alternatives:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}
\NormalTok{    babynames[(babynames[}\StringTok{"Name"}\NormalTok{] }\OperatorTok{==} \StringTok{"Bella"}\NormalTok{) }\OperatorTok{|} 
\NormalTok{              (babynames[}\StringTok{"Name"}\NormalTok{] }\OperatorTok{==} \StringTok{"Alex"}\NormalTok{) }\OperatorTok{|}
\NormalTok{              (babynames[}\StringTok{"Name"}\NormalTok{] }\OperatorTok{==} \StringTok{"Ani"}\NormalTok{) }\OperatorTok{|}
\NormalTok{              (babynames[}\StringTok{"Name"}\NormalTok{] }\OperatorTok{==} \StringTok{"Lisa"}\NormalTok{)]}
\NormalTok{).head()}
\CommentTok{\# Note: The parentheses surrounding the code make it possible to break the code on to multiple lines for readability}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &   Name &  Count \\
\midrule
6289  &    CA &   F &  1923 &  Bella &      5 \\
7512  &    CA &   F &  1925 &  Bella &      8 \\
12368 &    CA &   F &  1932 &   Lisa &      5 \\
14741 &    CA &   F &  1936 &   Lisa &      8 \\
17084 &    CA &   F &  1939 &   Lisa &      5 \\
\bottomrule
\end{tabular}

The \texttt{.isin} function can be used to filter dataframes. The method
helps in selecting rows with having a particular (or multiple) value in
a particular column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{names }\OperatorTok{=}\NormalTok{ [}\StringTok{"Bella"}\NormalTok{, }\StringTok{"Alex"}\NormalTok{, }\StringTok{"Ani"}\NormalTok{, }\StringTok{"Lisa"}\NormalTok{]}
\NormalTok{babynames[babynames[}\StringTok{"Name"}\NormalTok{].isin(names)].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &   Name &  Count \\
\midrule
6289  &    CA &   F &  1923 &  Bella &      5 \\
7512  &    CA &   F &  1925 &  Bella &      8 \\
12368 &    CA &   F &  1932 &   Lisa &      5 \\
14741 &    CA &   F &  1936 &   Lisa &      8 \\
17084 &    CA &   F &  1939 &   Lisa &      5 \\
\bottomrule
\end{tabular}

The function \texttt{str.startswith} can be used to define a filter
based on string values in a \texttt{Series} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[babynames[}\StringTok{"Name"}\NormalTok{].}\BuiltInTok{str}\NormalTok{.startswith(}\StringTok{"N"}\NormalTok{)].head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &    Name &  Count \\
\midrule
76  &    CA &   F &  1910 &   Norma &     23 \\
83  &    CA &   F &  1910 &  Nellie &     20 \\
127 &    CA &   F &  1910 &    Nina &     11 \\
198 &    CA &   F &  1910 &    Nora &      6 \\
310 &    CA &   F &  1911 &  Nellie &     23 \\
\bottomrule
\end{tabular}

\hypertarget{handy-utility-functions}{%
\section{Handy Utility Functions}\label{handy-utility-functions}}

\texttt{pandas} contains an extensive library of functions that can help
shorten the process of setting and getting information from its data
structures. In the following section, we will give overviews of each of
the main utility functions that will help us in Data 100.

\begin{itemize}
\tightlist
\item
  \texttt{Numpy} and built-in function support
\item
  \texttt{.shape}
\item
  \texttt{.size}
\item
  \texttt{.describe()}
\item
  \texttt{.sample()}
\item
  \texttt{.value\_counts()}
\item
  \texttt{.unique()}
\item
  \texttt{.sort\_values()}
\end{itemize}

\hypertarget{numpy}{%
\subsection{\texorpdfstring{\texttt{Numpy}}{Numpy}}\label{numpy}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bella\_counts }\OperatorTok{=}\NormalTok{ babynames[babynames[}\StringTok{"Name"}\NormalTok{] }\OperatorTok{==} \StringTok{"Bella"}\NormalTok{][}\StringTok{"Count"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Average number of babies named Bella each year}
\NormalTok{np.mean(bella\_counts)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
270.1860465116279
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Max number of babies named Bella born on a given year}
\BuiltInTok{max}\NormalTok{(bella\_counts)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
902
\end{verbatim}

\hypertarget{shape-and-.size}{%
\subsection{\texorpdfstring{\texttt{.shape} and
\texttt{.size}}{.shape and .size}}\label{shape-and-.size}}

\texttt{.shape} and \texttt{.size} are attributes of Series and
DataFrames that measure the ``amount'' of data stored in the structure.
Calling \texttt{.shape} returns a tuple containing the number of rows
and columns present in the DataFrame or Series. \texttt{.size} is used
to find the total number of elements in a structure, equivalent to the
number of rows times the number of columns.

Many functions strictly require the dimensions of the arguments along
certain axes to match. Calling these dimension-finding functions is much
faster than counting all of the items by hand.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.shape}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(400762, 5)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.size}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2003810
\end{verbatim}

\hypertarget{describe}{%
\subsection{\texorpdfstring{\texttt{.describe()}}{.describe()}}\label{describe}}

If many statistics are required from a DataFrame (minimum value, maximum
value, mean value, etc.), then
\href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html}{\texttt{.describe()}}
can be used to compute all of them at once.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.describe()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrr}
\toprule
{} &           Year &          Count \\
\midrule
count &  400762.000000 &  400762.000000 \\
mean  &    1985.131287 &      79.953781 \\
std   &      26.821004 &     295.414618 \\
min   &    1910.000000 &       5.000000 \\
25\%   &    1968.000000 &       7.000000 \\
50\%   &    1991.000000 &      13.000000 \\
75\%   &    2007.000000 &      38.000000 \\
max   &    2021.000000 &    8262.000000 \\
\bottomrule
\end{tabular}

A different set of statistics will be reported if \texttt{.describe()}
is called on a Series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[}\StringTok{"Sex"}\NormalTok{].describe()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{ll}
\toprule
{} &     Sex \\
\midrule
count  &  400762 \\
unique &       2 \\
top    &       F \\
freq   &  235791 \\
\bottomrule
\end{tabular}

\hypertarget{sample}{%
\subsection{\texorpdfstring{\texttt{.sample()}}{.sample()}}\label{sample}}

As we will see later in the semester, random processes are at the heart
of many data science techniques (for example, train-test splits,
bootstrapping, and cross-validation).
\href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html}{\texttt{.sample()}}
lets us quickly select random entries (a row if called from a DataFrame,
or a value if called from a Series).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.sample()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &     Name &  Count \\
\midrule
228461 &    CA &   F &  2019 &  Sincere &      5 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.sample(}\DecValTok{5}\NormalTok{).iloc[:, }\DecValTok{2}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrlr}
\toprule
{} &  Year &     Name &  Count \\
\midrule
338726 &  2000 &    Jason &   1554 \\
76004  &  1977 &  Christy &    275 \\
33990  &  1954 &    Renea &      6 \\
359478 &  2007 &   Sascha &      7 \\
12155  &  1932 &    Belia &     10 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[babynames[}\StringTok{"Year"}\NormalTok{] }\OperatorTok{==} \DecValTok{2000}\NormalTok{].sample(}\DecValTok{4}\NormalTok{, replace }\OperatorTok{=} \VariableTok{True}\NormalTok{).iloc[:, }\DecValTok{2}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrlr}
\toprule
{} &  Year &     Name &  Count \\
\midrule
338713 &  2000 &     Luis &   2287 \\
151766 &  2000 &   Kailin &      7 \\
149894 &  2000 &  Beverly &     37 \\
149438 &  2000 &  Darlene &    108 \\
\bottomrule
\end{tabular}

\hypertarget{value_counts}{%
\subsection{\texorpdfstring{\texttt{.value\_counts()}}{.value\_counts()}}\label{value_counts}}

When we want to know the distribution of the items in a Series (for
example, what items are most/least common), we use
\href{https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html}{\texttt{.value-counts()}}
to get a breakdown of the unique \emph{values} and their \emph{counts}.
In the example below, we can determine the name with the most years in
which at least one person has taken that name by counting the number of
times each name appears in the \texttt{"Name"} column of
\texttt{babynames}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[}\StringTok{"Name"}\NormalTok{].head().value\_counts()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  Name \\
\midrule
Mary     &     1 \\
Margaret &     1 \\
Helen    &     1 \\
Frances  &     1 \\
Dorothy  &     1 \\
\bottomrule
\end{tabular}

\hypertarget{unique}{%
\subsection{\texorpdfstring{\texttt{.unique()}}{.unique()}}\label{unique}}

If we have a Series with many repeated values, then
\href{https://pandas.pydata.org/docs/reference/api/pandas.unique.html}{\texttt{.unique()}}
can be used to identify only the \emph{unique} values. Here we can get a
list of all the names in \texttt{babynames}.

\textbf{Exercise:} what function can we call on the Series below to get
the number of unique names?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[}\StringTok{"Name"}\NormalTok{].unique()[:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array(['Mary', 'Helen', 'Dorothy', 'Margaret', 'Frances'], dtype=object)
\end{verbatim}

\hypertarget{sort_values}{%
\subsection{\texorpdfstring{\texttt{.sort\_values()}}{.sort\_values()}}\label{sort_values}}

Ordering a DataFrame can be useful for isolating extreme values. For
example, the first 5 entries of a row sorted in descending order (that
is, from highest to lowest) are the largest 5 values.
\href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html}{\texttt{.sort\_values}}
allows us to order a DataFrame or Series by a specified rule. For
DataFrames, we must specify the column by which we want to compare the
rows and the function will return such rows. We can choose to either
receive the rows in \texttt{ascending} order (default) or
\texttt{descending} order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.sort\_values(by }\OperatorTok{=} \StringTok{"Count"}\NormalTok{, ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{).head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &     Name &  Count \\
\midrule
263272 &    CA &   M &  1956 &  Michael &   8262 \\
264297 &    CA &   M &  1957 &  Michael &   8250 \\
313644 &    CA &   M &  1990 &  Michael &   8247 \\
278109 &    CA &   M &  1969 &  Michael &   8244 \\
279405 &    CA &   M &  1970 &  Michael &   8197 \\
\bottomrule
\end{tabular}

We do not need to explicitly specify the column used for sorting when
calling \texttt{.value\_counts()} on a Series. We can still specify the
ordering paradigm -- that is, whether values are sorted in ascending or
descending order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames[}\StringTok{"Name"}\NormalTok{].sort\_values(ascending}\OperatorTok{=}\VariableTok{True}\NormalTok{).head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{ll}
\toprule
{} &     Name \\
\midrule
380256 &    Aadan \\
362255 &    Aadan \\
365374 &    Aadan \\
394460 &  Aadarsh \\
366561 &    Aaden \\
\bottomrule
\end{tabular}

\hypertarget{sorting-with-a-custom-key}{%
\subsubsection{Sorting With a Custom
Key}\label{sorting-with-a-custom-key}}

Using \texttt{.sort\_values} can be useful in many situations, but it
many not cover all use cases. This is because \texttt{pandas}
automatically sorts values in order according to numeric value (for
number data) or alphabetical order (for string data). The following code
finds the top 5 most popular names in California in 2021.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sort names by count in year 2021}
\CommentTok{\# Recall that \textasciigrave{}.head(5)\textasciigrave{} displays the first five rows in the DataFrame}
\NormalTok{babynames[babynames[}\StringTok{"Year"}\NormalTok{] }\OperatorTok{==} \DecValTok{2021}\NormalTok{].sort\_values(}\StringTok{"Count"}\NormalTok{, ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{).head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &    Name &  Count \\
\midrule
397909 &    CA &   M &  2021 &    Noah &   2591 \\
397910 &    CA &   M &  2021 &    Liam &   2469 \\
232145 &    CA &   F &  2021 &  Olivia &   2395 \\
232146 &    CA &   F &  2021 &    Emma &   2171 \\
397911 &    CA &   M &  2021 &   Mateo &   2108 \\
\bottomrule
\end{tabular}

This offers us a lot of functionality, but what if we need to sort by
some other metric? For example, what if we wanted to find the longest
names in the DataFrame?

We can do this by specifying the \texttt{key} parameter of
\texttt{.sort\_values}. The \texttt{key} parameter is assigned to a
function of our choice. This function is then applied to each value in
the specified column. \texttt{pandas} will, finally, sort the DataFrame
by the values outputted by the function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Here, a lambda function is applied to find the length of each value, \textasciigrave{}x\textasciigrave{}, in the "Name" column}
\NormalTok{babynames.sort\_values(}\StringTok{"Name"}\NormalTok{, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x.}\BuiltInTok{str}\NormalTok{.}\BuiltInTok{len}\NormalTok{(), ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &             Name &  Count \\
\midrule
313143 &    CA &   M &  1989 &  Franciscojavier &      6 \\
333732 &    CA &   M &  1997 &  Ryanchristopher &      5 \\
330421 &    CA &   M &  1996 &  Franciscojavier &      8 \\
323615 &    CA &   M &  1993 &  Johnchristopher &      5 \\
310235 &    CA &   M &  1988 &  Franciscojavier &     10 \\
\bottomrule
\end{tabular}

\hypertarget{adding-and-removing-columns}{%
\section{Adding and Removing
Columns}\label{adding-and-removing-columns}}

To add a new column to a DataFrame, we use a syntax similar to that used
when accessing an existing column. Specify the name of the new column by
writing \texttt{dataframe{[}"new\_column"{]}}, then assign this to a
Series or Array containing the values that will populate this column.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Add a column named "name\_lengths" that includes the length of each name}
\NormalTok{babynames[}\StringTok{"name\_lengths"}\NormalTok{] }\OperatorTok{=}\NormalTok{ babynames[}\StringTok{"Name"}\NormalTok{].}\BuiltInTok{str}\NormalTok{.}\BuiltInTok{len}\NormalTok{()}
\NormalTok{babynames.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlrr}
\toprule
{} & State & Sex &  Year &      Name &  Count &  name\_lengths \\
\midrule
0 &    CA &   F &  1910 &      Mary &    295 &             4 \\
1 &    CA &   F &  1910 &     Helen &    239 &             5 \\
2 &    CA &   F &  1910 &   Dorothy &    220 &             7 \\
3 &    CA &   F &  1910 &  Margaret &    163 &             8 \\
4 &    CA &   F &  1910 &   Frances &    134 &             7 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sort by the temporary column}
\NormalTok{babynames }\OperatorTok{=}\NormalTok{ babynames.sort\_values(by }\OperatorTok{=} \StringTok{"name\_lengths"}\NormalTok{, ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{babynames.head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlrr}
\toprule
{} & State & Sex &  Year &             Name &  Count &  name\_lengths \\
\midrule
313143 &    CA &   M &  1989 &  Franciscojavier &      6 &            15 \\
333732 &    CA &   M &  1997 &  Ryanchristopher &      5 &            15 \\
330421 &    CA &   M &  1996 &  Franciscojavier &      8 &            15 \\
323615 &    CA &   M &  1993 &  Johnchristopher &      5 &            15 \\
310235 &    CA &   M &  1988 &  Franciscojavier &     10 &            15 \\
\bottomrule
\end{tabular}

In the example above, we made use of an in-built function given to us by
the \texttt{str} accessor for getting the length of names. Then we used
\texttt{name\_length} column to sort the dataframe. What if we had
wanted to generate the values in our new column using a function of our
own making?

We can do this using the Series
\href{https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html}{\texttt{.map}}
method. \texttt{.map} takes in a function as input, and will apply this
function to each value of a Series.

For example, say we wanted to find the number of occurrences of the
sequence ``dr'' or ``ea'' in each name.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First, define a function to count the number of times "dr" or "ea" appear in each name}
\KeywordTok{def}\NormalTok{ dr\_ea\_count(string):}
    \ControlFlowTok{return}\NormalTok{ string.count(}\StringTok{"dr"}\NormalTok{) }\OperatorTok{+}\NormalTok{ string.count(}\StringTok{"ea"}\NormalTok{)}

\CommentTok{\# Then, use \textasciigrave{}map\textasciigrave{} to apply \textasciigrave{}dr\_ea\_count\textasciigrave{} to each name in the "Name" column}
\NormalTok{babynames[}\StringTok{"dr\_ea\_count"}\NormalTok{] }\OperatorTok{=}\NormalTok{ babynames[}\StringTok{"Name"}\NormalTok{].}\BuiltInTok{map}\NormalTok{(dr\_ea\_count)}

\CommentTok{\# Sort the DataFrame by the new "dr\_ea\_count" column so we can see our handiwork}
\NormalTok{babynames.sort\_values(by }\OperatorTok{=} \StringTok{"dr\_ea\_count"}\NormalTok{, ascending }\OperatorTok{=} \VariableTok{False}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlrrr}
\toprule
{} & State & Sex &  Year &      Name &  Count &  name\_lengths &  dr\_ea\_count \\
\midrule
101969 &    CA &   F &  1986 &  Deandrea &      6 &             8 &            3 \\
304390 &    CA &   M &  1985 &  Deandrea &      6 &             8 &            3 \\
131022 &    CA &   F &  1994 &  Leandrea &      5 &             8 &            3 \\
115950 &    CA &   F &  1990 &  Deandrea &      5 &             8 &            3 \\
108723 &    CA &   F &  1988 &  Deandrea &      5 &             8 &            3 \\
\bottomrule
\end{tabular}

If we want to remove a column or row of a DataFrame, we can call the
\href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html}{\texttt{.drop}}
method. Use the \texttt{axis} parameter to specify whether a column or
row should be dropped. Unless otherwise specified, \texttt{pandas} will
assume that we are dropping a row by default.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Drop our "dr\_ea\_count" and "length" columns from the DataFrame}
\NormalTok{babynames }\OperatorTok{=}\NormalTok{ babynames.drop([}\StringTok{"dr\_ea\_count"}\NormalTok{, }\StringTok{"name\_lengths"}\NormalTok{], axis}\OperatorTok{=}\StringTok{"columns"}\NormalTok{)}
\NormalTok{babynames.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &             Name &  Count \\
\midrule
313143 &    CA &   M &  1989 &  Franciscojavier &      6 \\
333732 &    CA &   M &  1997 &  Ryanchristopher &      5 \\
330421 &    CA &   M &  1996 &  Franciscojavier &      8 \\
323615 &    CA &   M &  1993 &  Johnchristopher &      5 \\
310235 &    CA &   M &  1988 &  Franciscojavier &     10 \\
\bottomrule
\end{tabular}

Notice that we reassigned \texttt{babynames} to the result of
\texttt{babynames.drop(...)}. This is a subtle, but important point:
\texttt{pandas} table operations \textbf{do not occur in-place}. Calling
\texttt{dataframe.drop(...)} will output a \emph{copy} of
\texttt{dataframe} with the row/column of interest removed, without
modifying the original \texttt{dataframe} table.

In other words, if we simply call:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This creates a copy of \textasciigrave{}babynames\textasciigrave{} and removes the row with label 3...}
\NormalTok{babynames.drop(}\DecValTok{3}\NormalTok{, axis}\OperatorTok{=}\StringTok{"rows"}\NormalTok{)}

\CommentTok{\# ...but the original \textasciigrave{}babynames\textasciigrave{} is unchanged! }
\CommentTok{\# Notice that the row with label 3 is still present}
\NormalTok{babynames.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrlr}
\toprule
{} & State & Sex &  Year &             Name &  Count \\
\midrule
313143 &    CA &   M &  1989 &  Franciscojavier &      6 \\
333732 &    CA &   M &  1997 &  Ryanchristopher &      5 \\
330421 &    CA &   M &  1996 &  Franciscojavier &      8 \\
323615 &    CA &   M &  1993 &  Johnchristopher &      5 \\
310235 &    CA &   M &  1988 &  Franciscojavier &     10 \\
\bottomrule
\end{tabular}

\hypertarget{aggregating-data-with-groupby}{%
\section{Aggregating Data with
GroupBy}\label{aggregating-data-with-groupby}}

Up until this point, we have been working with individual rows of
DataFrames. As data scientists, we often wish to investigate trends
across a larger \emph{subset} of our data. For example, we may want to
compute some summary statistic (the mean, median, sum, etc.) for a group
of rows in our DataFrame. To do this, we'll use \texttt{pandas}
\texttt{GroupBy} objects.

Let's say we wanted to aggregate all rows in \texttt{babynames} for a
given year.

\texttt{babynames.groupby("Year")}

\texttt{\textless{}pandas.core.groupby.generic.DataFrameGroupBy\ object\ at\ 0x000001FD34F9E640\textgreater{}}

What does this strange output mean? Calling
\href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html}{\texttt{.groupby}}
has generated a \texttt{GroupBy} object. You can imagine this as a set
of ``mini'' sub-DataFrames, where each subframe contains all of the rows
from \texttt{babynames} that correspond to a particular year.

The diagram below shows a simplified view of \texttt{babynames} to help
illustrate this idea.

\begin{figure}

{\centering \includegraphics{pandas_2/images/gb.png}

}

\caption{Creating a GroupBy object}

\end{figure}

We can't work with a \texttt{GroupBy} object directly -- that is why you
saw that strange output earlier, rather than a standard view of a
DataFrame. To actually manipulate values within these ``mini''
DataFrames, we'll need to call an \emph{aggregation method}. This is a
method that tells \texttt{pandas} how to aggregate the values within the
\texttt{GroupBy} object. Once the aggregation is applied,
\texttt{pandas} will return a normal (now grouped) DataFrame.

The first aggregation method we'll consider is \texttt{.agg}. The
\texttt{.agg} method takes in a function as its argument; this function
is then applied to each column of a ``mini'' grouped DataFrame. We end
up with a new DataFrame with one aggregated row per subframe. Let's see
this in action by finding the \texttt{sum} of all counts for each year
in \texttt{babynames} -- this is equivalent to finding the number of
babies born in each year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.groupby(}\StringTok{"Year"}\NormalTok{).agg(}\BuiltInTok{sum}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  Count \\
Year &        \\
\midrule
1910 &   9163 \\
1911 &   9983 \\
1912 &  17946 \\
1913 &  22094 \\
1914 &  26926 \\
\bottomrule
\end{tabular}

We can relate this back to the diagram we used above. Remember that the
diagram uses a simplified version of \texttt{babynames}, which is why we
see smaller values for the summed counts.

\begin{figure}

{\centering \includegraphics{pandas_2/images/agg.png}

}

\caption{Performing an aggregation}

\end{figure}

Calling \texttt{.agg} has condensed each subframe back into a single
row. This gives us our final output: a DataFrame that is now indexed by
\texttt{"Year"}, with a single row for each unique year in the original
\texttt{babynames} DataFrame.

You may be wondering: where did the \texttt{"State"}, \texttt{"Sex"},
and \texttt{"Name"} columns go? Logically, it doesn't make sense to
\texttt{sum} the string data in these columns (how would we add ``Mary''
+ ``Ann''?). Because of this, \texttt{pandas} will simply omit these
columns when it performs the aggregation on the DataFrame. Since this
happens implicitly, without the user specifying that these columns
should be ignored, it's easy to run into troubling situations where
columns are removed without the programmer noticing. It is better coding
practice to select \emph{only} the columns we care about before
performing the aggregation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Same result, but now we explicitly tell Pandas to only consider the "Count" column when summing}
\NormalTok{babynames.groupby(}\StringTok{"Year"}\NormalTok{)[[}\StringTok{"Count"}\NormalTok{]].agg(}\BuiltInTok{sum}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lr}
\toprule
{} &  Count \\
Year &        \\
\midrule
1910 &   9163 \\
1911 &   9983 \\
1912 &  17946 \\
1913 &  22094 \\
1914 &  26926 \\
\bottomrule
\end{tabular}

\hypertarget{parting-note-1}{%
\subsection{Parting note}\label{parting-note-1}}

Manipulating \texttt{DataFrames} is a skill that is not mastered in just
one day. Due to the flexibility of \texttt{pandas}, there are many
different ways to get from a point A to a point B. We recommend trying
multiple different ways to solve the same problem to gain even more
practice and reach that point of mastery sooner.

Next, we will start digging deeper into the mechanics behind grouping
data.

\bookmarksetup{startatroot}

\hypertarget{pandas-iii}{%
\chapter{Pandas III}\label{pandas-iii}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, left=2mm, colback=white, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, coltitle=black, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, toprule=.15mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacityback=0, opacitybacktitle=0.6]

\begin{itemize}
\tightlist
\item
  Perform advanced aggregation using \texttt{.groupby}
\item
  Use the \texttt{pd.pivot\_table} method to contruct a pivot table
\item
  Perform simple merges between DataFrames using \texttt{pd.merge}
\end{itemize}

\end{tcolorbox}

Last time, we introduced the concept of aggregating data -- we
familiarized ourselves with \texttt{GroupBy} objects and used them as
tools to consolidate and summarize a DataFrame. In this lecture, we will
explore some advanced \texttt{.groupby} methods to show just how
powerful of a resource they can be for understanding our data. We will
also introduce other techniques for data aggregation to provide
flexibility in how we manipulate our tables.

\hypertarget{groupby-continued}{%
\section{\texorpdfstring{\texttt{GroupBy},
Continued}{GroupBy, Continued}}\label{groupby-continued}}

As we learned last lecture, a \texttt{groupby} operation involves some
combination of \textbf{splitting a DataFrame into grouped subframes},
\textbf{applying a function}, and \textbf{combining the results}.

For some arbitrary DataFrame \texttt{df} below, the code
\texttt{df.groupby("year").agg(sum)} does the following:

\begin{itemize}
\tightlist
\item
  Organizes all rows with the same year into a subframe for that year.
\item
  Creates a new DataFrame with one row representing each subframe year.
\item
  Combines all integer rows in each subframe using the \texttt{sum}
  function.
\end{itemize}

\hypertarget{aggregation-with-lambda-functions}{%
\subsection{\texorpdfstring{Aggregation with \texttt{lambda}
Functions}{Aggregation with lambda Functions}}\label{aggregation-with-lambda-functions}}

Throughout this note, we'll work with the \texttt{elections} DataFrame.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{elections }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/elections.csv"}\NormalTok{)}
\NormalTok{elections.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 &    win &  56.203927 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 &   loss &  43.796073 \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 &    win &  54.574789 \\
\bottomrule
\end{tabular}

What if we wish to aggregate our DataFrame using a non-standard function
-- for example, a function of our own design? We can do so by combining
\texttt{.agg} with \texttt{lambda} expressions.

Let's first consider a puzzle to jog our memory. We will attempt to find
the \texttt{Candidate} from each \texttt{Party} with the highest
\texttt{\%} of votes.

A naive approach may be to group by the \texttt{Party} column and
aggregate by the maximum.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.groupby(}\StringTok{"Party"}\NormalTok{).agg(}\BuiltInTok{max}\NormalTok{).head(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrlrlr}
\toprule
{} &  Year &           Candidate &  Popular vote & Result &          \% \\
Party                 &       &                     &               &        &            \\
\midrule
American              &  1976 &  Thomas J. Anderson &        873053 &   loss &  21.554001 \\
American Independent  &  1976 &       Lester Maddox &       9901118 &   loss &  13.571218 \\
Anti-Masonic          &  1832 &        William Wirt &        100715 &   loss &   7.821583 \\
Anti-Monopoly         &  1884 &     Benjamin Butler &        134294 &   loss &   1.335838 \\
Citizens              &  1980 &      Barry Commoner &        233052 &   loss &   0.270182 \\
Communist             &  1932 &   William Z. Foster &        103307 &   loss &   0.261069 \\
Constitution          &  2016 &    Michael Peroutka &        203091 &   loss &   0.152398 \\
Constitutional Union  &  1860 &           John Bell &        590901 &   loss &  12.639283 \\
Democratic            &  2020 &      Woodrow Wilson &      81268924 &    win &  61.344703 \\
Democratic-Republican &  1824 &   John Quincy Adams &        151271 &    win &  57.210122 \\
\bottomrule
\end{tabular}

This approach is clearly wrong -- the DataFrame claims that Woodrow
Wilson won the presidency in 2020.

Why is this happening? Here, the \texttt{max} aggregation function is
taken over every column \emph{independently}. Among Democrats,
\texttt{max} is computing:

\begin{itemize}
\tightlist
\item
  The most recent \texttt{Year} a Democratic candidate ran for president
  (2020)
\item
  The \texttt{Candidate} with the alphabetically ``largest'' name
  (``Woodrow Wilson'')
\item
  The \texttt{Result} with the alphabetically ``largest'' outcome
  (``win'')
\end{itemize}

Instead, let's try a different approach. We will:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort the DataFrame so that rows are in descending order of \texttt{\%}
\item
  Group by \texttt{Party} and select the first row of each groupby
  object
\end{enumerate}

While it may seem unintuitive, sorting \texttt{elections} by descending
order of \texttt{\%} is extremely helpful. If we then group by
\texttt{Party}, the first row of each groupby object will contain
information about the \texttt{Candidate} with the highest voter
\texttt{\%}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections\_sorted\_by\_percent }\OperatorTok{=}\NormalTok{ elections.sort\_values(}\StringTok{"\%"}\NormalTok{, ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{elections\_sorted\_by\_percent.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &           Candidate &       Party &  Popular vote & Result &          \% \\
\midrule
114 &  1964 &      Lyndon Johnson &  Democratic &      43127041 &    win &  61.344703 \\
91  &  1936 &  Franklin Roosevelt &  Democratic &      27752648 &    win &  60.978107 \\
120 &  1972 &       Richard Nixon &  Republican &      47168710 &    win &  60.907806 \\
79  &  1920 &      Warren Harding &  Republican &      16144093 &    win &  60.574501 \\
133 &  1984 &       Ronald Reagan &  Republican &      54455472 &    win &  59.023326 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections\_sorted\_by\_percent.groupby(}\StringTok{"Party"}\NormalTok{).agg(}\KeywordTok{lambda}\NormalTok{ x : x.iloc[}\DecValTok{0}\NormalTok{]).head(}\DecValTok{10}\NormalTok{)}

\CommentTok{\# Equivalent to the below code}
\CommentTok{\# elections\_sorted\_by\_percent.groupby("Party").agg(\textquotesingle{}first\textquotesingle{}).head(10)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrlrlr}
\toprule
{} &  Year &          Candidate &  Popular vote & Result &          \% \\
Party                 &       &                    &               &        &            \\
\midrule
American              &  1856 &   Millard Fillmore &        873053 &   loss &  21.554001 \\
American Independent  &  1968 &     George Wallace &       9901118 &   loss &  13.571218 \\
Anti-Masonic          &  1832 &       William Wirt &        100715 &   loss &   7.821583 \\
Anti-Monopoly         &  1884 &    Benjamin Butler &        134294 &   loss &   1.335838 \\
Citizens              &  1980 &     Barry Commoner &        233052 &   loss &   0.270182 \\
Communist             &  1932 &  William Z. Foster &        103307 &   loss &   0.261069 \\
Constitution          &  2008 &      Chuck Baldwin &        199750 &   loss &   0.152398 \\
Constitutional Union  &  1860 &          John Bell &        590901 &   loss &  12.639283 \\
Democratic            &  1964 &     Lyndon Johnson &      43127041 &    win &  61.344703 \\
Democratic-Republican &  1824 &     Andrew Jackson &        151271 &   loss &  57.210122 \\
\bottomrule
\end{tabular}

Notice how our code correctly determines that Lyndon Johnson from the
Democratic Party has the highest voter \texttt{\%}.

More generally, \texttt{lambda} functions are used to design custom
aggregation functions that aren't pre-defined by Python. The input
parameter \texttt{x} to the \texttt{lambda} function is a
\texttt{GroupBy} object. Therefore, it should make sense why
\texttt{lambda\ x\ :\ x.iloc{[}0{]}} selects the first row in each
groupby object.

In fact, there's a few different ways to approach this problem. Each
approach has different tradeoffs in terms of readability, performance,
memory consumption, complexity, etc. We've given a few examples below.

\textbf{Note}: Understanding these alternative solutions is not
required. They are given to demonstrate the vast number of
problem-solving approaches in \texttt{pandas}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Using the idxmax function}
\NormalTok{best\_per\_party }\OperatorTok{=}\NormalTok{ elections.loc[elections.groupby(}\StringTok{\textquotesingle{}Party\textquotesingle{}}\NormalTok{)[}\StringTok{\textquotesingle{}\%\textquotesingle{}}\NormalTok{].idxmax()]}
\NormalTok{best\_per\_party.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &         Candidate &                 Party &  Popular vote & Result &          \% \\
\midrule
22  &  1856 &  Millard Fillmore &              American &        873053 &   loss &  21.554001 \\
115 &  1968 &    George Wallace &  American Independent &       9901118 &   loss &  13.571218 \\
6   &  1832 &      William Wirt &          Anti-Masonic &        100715 &   loss &   7.821583 \\
38  &  1884 &   Benjamin Butler &         Anti-Monopoly &        134294 &   loss &   1.335838 \\
127 &  1980 &    Barry Commoner &              Citizens &        233052 &   loss &   0.270182 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Using the .drop\_duplicates function}
\NormalTok{best\_per\_party2 }\OperatorTok{=}\NormalTok{ elections.sort\_values(}\StringTok{\textquotesingle{}\%\textquotesingle{}}\NormalTok{).drop\_duplicates([}\StringTok{\textquotesingle{}Party\textquotesingle{}}\NormalTok{], keep}\OperatorTok{=}\StringTok{\textquotesingle{}last\textquotesingle{}}\NormalTok{)}
\NormalTok{best\_per\_party2.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &           Candidate &           Party &  Popular vote & Result &         \% \\
\midrule
148 &  1996 &        John Hagelin &     Natural Law &        113670 &   loss &  0.118219 \\
164 &  2008 &       Chuck Baldwin &    Constitution &        199750 &   loss &  0.152398 \\
110 &  1956 &  T. Coleman Andrews &  States' Rights &        107929 &   loss &  0.174883 \\
147 &  1996 &     Howard Phillips &       Taxpayers &        184656 &   loss &  0.192045 \\
136 &  1988 &       Lenora Fulani &    New Alliance &        217221 &   loss &  0.237804 \\
\bottomrule
\end{tabular}

\hypertarget{other-groupby-features}{%
\section{\texorpdfstring{Other \texttt{GroupBy}
Features}{Other GroupBy Features}}\label{other-groupby-features}}

There are many aggregation methods we can use with \texttt{.agg}. Some
useful options are:

\begin{itemize}
\tightlist
\item
  \href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.max.html}{\texttt{.max}}:
  creates a new DataFrame with the maximum value of each group
\item
  \href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.mean.html}{\texttt{.mean}}:
  creates a new DataFrame with the mean value of each group
\item
  \href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.size.html}{\texttt{.size}}:
  creates a new Series with the number of entries in each group
\end{itemize}

In fact, these (and other) aggregation functions are so common that
\texttt{pandas} allows for writing shorthand. Instead of explicitly
stating the use of \texttt{.agg}, we can call the function directly on
the \texttt{GroupBy} object.

For example, the following are equivalent:

\begin{itemize}
\tightlist
\item
  \texttt{elections.groupby("Candidate").agg(mean)}
\item
  \texttt{elections.groupby("Candidate").mean()}
\end{itemize}

\hypertarget{the-groupby.filter-function}{%
\subsection{\texorpdfstring{The \texttt{groupby.filter}
function}{The groupby.filter function}}\label{the-groupby.filter-function}}

Another common use for \texttt{GroupBy} objects is to filter data by
group.

\texttt{groupby.filter} takes an argument \(\text{f}\), where
\(\text{f}\) is a function that:

\begin{itemize}
\tightlist
\item
  Takes a \texttt{GroupBy} object as input
\item
  Returns a single \texttt{True} or \texttt{False} for the entire
  subframe
\end{itemize}

\texttt{GroupBy} objects that correspond to \texttt{True} are returned
in the final result, whereas those with a \texttt{False} value are not.
Importantly, \texttt{groupby.filter} is different from
\texttt{groupby.agg} in that the \emph{entire} subframe is returned in
the final DataFrame, not just a single row.

To illustrate how this happens, consider the following \texttt{.filter}
function applied on some arbitrary data. Say we want to identify
``tight'' election years -- that is, we want to find all rows that
correspond to elections years where all candidates in that year won a
similar portion of the total vote. Specifically, let's find all rows
corresponding to a year where no candidate won more than 45\% of the
total vote.

An equivalent way of framing this goal is to say:

\begin{itemize}
\tightlist
\item
  Find the years where the maximum \texttt{\%} in that year is less than
  45\%
\item
  Return all DataFrame rows that correspond to these years
\end{itemize}

For each year, we need to find the maximum \texttt{\%} among \emph{all}
rows for that year. If this maximum \texttt{\%} is lower than 45\%, we
will tell \texttt{pandas} to keep all rows corresponding to that year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.groupby(}\StringTok{"Year"}\NormalTok{).}\BuiltInTok{filter}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ sf: sf[}\StringTok{"\%"}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{\textless{}} \DecValTok{45}\NormalTok{).head(}\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &             Candidate &                 Party &  Popular vote & Result &          \% \\
\midrule
23 &  1860 &       Abraham Lincoln &            Republican &       1855993 &    win &  39.699408 \\
24 &  1860 &             John Bell &  Constitutional Union &        590901 &   loss &  12.639283 \\
25 &  1860 &  John C. Breckinridge &   Southern Democratic &        848019 &   loss &  18.138998 \\
26 &  1860 &    Stephen A. Douglas &   Northern Democratic &       1380202 &   loss &  29.522311 \\
66 &  1912 &        Eugene V. Debs &             Socialist &        901551 &   loss &   6.004354 \\
67 &  1912 &      Eugene W. Chafin &           Prohibition &        208156 &   loss &   1.386325 \\
68 &  1912 &    Theodore Roosevelt &           Progressive &       4122721 &   loss &  27.457433 \\
69 &  1912 &          William Taft &            Republican &       3486242 &   loss &  23.218466 \\
70 &  1912 &        Woodrow Wilson &            Democratic &       6296284 &    win &  41.933422 \\
\bottomrule
\end{tabular}

What's going on here? In this example, we've defined our filtering
function, \(\text{f}\), to be
\texttt{lambda\ sf:\ sf{[}"\%"{]}.max()\ \textless{}\ 45}. This
filtering function will find the maximum \texttt{"\%"} value among all
entries in the grouped subframe, which we call \texttt{sf}. If the
maximum value is less than 45, then the filter function will return
\texttt{True} and all rows in that grouped subframe will appear in the
final output DataFrame.

Examine the DataFrame above. Notice how, in this preview of the first 9
rows, all entries from the years 1860 and 1912 appear. This means that
in 1860 and 1912, no candidate in that year won more than 45\% of the
total vote.

You may ask: how is the \texttt{groupby.filter} procedure different to
the boolean filtering we've seen previously? Boolean filtering considers
\emph{individual} rows when applying a boolean condition. For example,
the code \texttt{elections{[}elections{[}"\%"{]}\ \textless{}\ 45{]}}
will check the \texttt{"\%"} value of every single row in
\texttt{elections}; if it is less than 45, then that row will be kept in
the output. \texttt{groupby.filter}, in contrast, applies a boolean
condition \emph{across} all rows in a group. If not all rows in that
group satisfy the condition specified by the filter, the entire group
will be discarded in the output.

\hypertarget{aggregating-data-with-pivot-tables}{%
\section{Aggregating Data with Pivot
Tables}\label{aggregating-data-with-pivot-tables}}

We know now that \texttt{.groupby} gives us the ability to group and
aggregate data across our DataFrame. The examples above formed groups
using just one column in the DataFrame. It's possible to group by
multiple columns at once by passing in a list of columns names to
\texttt{.groupby}.

Let's consider the \texttt{babynames} dataset from last lecture. In this
problem, we will find the total number of baby names associated with
each sex for each year. To do this, we'll group by \emph{both} the
\texttt{"Year"} and \texttt{"Sex"} columns.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ urllib.request}
\ImportTok{import}\NormalTok{ os.path}

\CommentTok{\# Download data from the web directly}
\NormalTok{data\_url }\OperatorTok{=} \StringTok{"https://www.ssa.gov/oact/babynames/names.zip"}
\NormalTok{local\_filename }\OperatorTok{=} \StringTok{"data/babynames.zip"}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ os.path.exists(local\_filename): }\CommentTok{\# if the data exists don\textquotesingle{}t download again}
    \ControlFlowTok{with}\NormalTok{ urllib.request.urlopen(data\_url) }\ImportTok{as}\NormalTok{ resp, }\BuiltInTok{open}\NormalTok{(local\_filename, }\StringTok{\textquotesingle{}wb\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{        f.write(resp.read())}

        
\CommentTok{\# Load data without unzipping the file}
\ImportTok{import}\NormalTok{ zipfile}
\NormalTok{babynames }\OperatorTok{=}\NormalTok{ [] }
\ControlFlowTok{with}\NormalTok{ zipfile.ZipFile(local\_filename, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ zf:}
\NormalTok{    data\_files }\OperatorTok{=}\NormalTok{ [f }\ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ zf.filelist }\ControlFlowTok{if}\NormalTok{ f.filename[}\OperatorTok{{-}}\DecValTok{3}\NormalTok{:] }\OperatorTok{==} \StringTok{"txt"}\NormalTok{]}
    \KeywordTok{def}\NormalTok{ extract\_year\_from\_filename(fn):}
        \ControlFlowTok{return} \BuiltInTok{int}\NormalTok{(fn[}\DecValTok{3}\NormalTok{:}\DecValTok{7}\NormalTok{])}
    \ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ data\_files:}
\NormalTok{        year }\OperatorTok{=}\NormalTok{ extract\_year\_from\_filename(f.filename)}
        \ControlFlowTok{with}\NormalTok{ zf.}\BuiltInTok{open}\NormalTok{(f) }\ImportTok{as}\NormalTok{ fp:}
\NormalTok{            df }\OperatorTok{=}\NormalTok{ pd.read\_csv(fp, names}\OperatorTok{=}\NormalTok{[}\StringTok{"Name"}\NormalTok{, }\StringTok{"Sex"}\NormalTok{, }\StringTok{"Count"}\NormalTok{])}
\NormalTok{            df[}\StringTok{"Year"}\NormalTok{] }\OperatorTok{=}\NormalTok{ year}
\NormalTok{            babynames.append(df)}
\NormalTok{babynames }\OperatorTok{=}\NormalTok{ pd.concat(babynames)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames.head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrr}
\toprule
{} &       Name & Sex &  Count &  Year \\
\midrule
0 &       Mary &   F &   7065 &  1880 \\
1 &       Anna &   F &   2604 &  1880 \\
2 &       Emma &   F &   2003 &  1880 \\
3 &  Elizabeth &   F &   1939 &  1880 \\
4 &     Minnie &   F &   1746 &  1880 \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Find the total number of baby names associated with each sex for each year in the data}
\NormalTok{babynames.groupby([}\StringTok{"Year"}\NormalTok{, }\StringTok{"Sex"}\NormalTok{])[[}\StringTok{"Count"}\NormalTok{]].agg(}\BuiltInTok{sum}\NormalTok{).head(}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{llr}
\toprule
     &   &   Count \\
Year & Sex &         \\
\midrule
1880 & F &   90994 \\
     & M &  110490 \\
1881 & F &   91953 \\
     & M &  100737 \\
1882 & F &  107847 \\
     & M &  113686 \\
\bottomrule
\end{tabular}

Notice that both \texttt{"Year"} and \texttt{"Sex"} serve as the index
of the DataFrame (they are both rendered in bold). We've created a
\emph{multindex} where two different index values, the year and sex, are
used to uniquely identify each row.

This isn't the most intuitive way of representing this data -- and,
because multindexes have multiple dimensions in their index, they can
often be difficult to use.

Another strategy to aggregate across two columns is to create a pivot
table. You saw these back in
\href{https://inferentialthinking.com/chapters/08/3/Cross-Classifying_by_More_than_One_Variable.html\#pivot-tables-rearranging-the-output-of-group}{Data
8}. One set of values is used to create the index of the table; another
set is used to define the column names. The values contained in each
cell of the table correspond to the aggregated data for each
index-column pair.

The best way to understand pivot tables is to see one in action. Let's
return to our original goal of summing the total number of names
associated with each combination of year and sex. We'll call the
\texttt{pandas}
\href{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html}{\texttt{.pivot\_table}}
method to create a new table.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The \textasciigrave{}pivot\_table\textasciigrave{} method is used to generate a Pandas pivot table}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{babynames.pivot\_table(index }\OperatorTok{=} \StringTok{"Year"}\NormalTok{, columns }\OperatorTok{=} \StringTok{"Sex"}\NormalTok{, values }\OperatorTok{=} \StringTok{"Count"}\NormalTok{, aggfunc }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrr}
\toprule
Sex &       F &       M \\
Year &         &         \\
\midrule
1880 &   90994 &  110490 \\
1881 &   91953 &  100737 \\
1882 &  107847 &  113686 \\
1883 &  112319 &  104625 \\
1884 &  129019 &  114442 \\
\bottomrule
\end{tabular}

Looks a lot better! Now, our DataFrame is structured with clear
index-column combinations. Each entry in the pivot table represents the
summed count of names for a given combination of \texttt{"Year"} and
\texttt{"Sex"}.

Let's take a closer look at the code implemented above.

\begin{itemize}
\tightlist
\item
  \texttt{index\ =\ "Year"} specifies the column name in the original
  DataFrame that should be used as the index of the pivot table
\item
  \texttt{columns\ =\ "Sex"} specifies the column name in the original
  DataFrame that should be used to generate the columns of the pivot
  table
\item
  \texttt{values\ =\ "Count"} indicates what values from the original
  DataFrame should be used to populate the entry for each index-column
  combination
\item
  \texttt{aggfunc\ =\ np.sum} tells \texttt{pandas} what function to use
  when aggregating the data specified by \texttt{values}. Here, we are
  \texttt{sum}ming the name counts for each pair of \texttt{"Year"} and
  \texttt{"Sex"}
\end{itemize}

We can even include multiple values in the index or columns of our pivot
tables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{babynames\_pivot }\OperatorTok{=}\NormalTok{ babynames.pivot\_table(}
\NormalTok{    index}\OperatorTok{=}\StringTok{"Year"}\NormalTok{,     }\CommentTok{\# the rows (turned into index)}
\NormalTok{    columns}\OperatorTok{=}\StringTok{"Sex"}\NormalTok{,    }\CommentTok{\# the column values}
\NormalTok{    values}\OperatorTok{=}\NormalTok{[}\StringTok{"Count"}\NormalTok{, }\StringTok{"Name"}\NormalTok{], }
\NormalTok{    aggfunc}\OperatorTok{=}\BuiltInTok{max}\NormalTok{,   }\CommentTok{\# group operation}
\NormalTok{)}
\NormalTok{babynames\_pivot.head(}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrrll}
\toprule
{} & \multicolumn{2}{l}{Count} & \multicolumn{2}{l}{Name} \\
Sex &     F &     M &     F &       M \\
Year &       &       &       &         \\
\midrule
1880 &  7065 &  9655 &  Zula &    Zeke \\
1881 &  6919 &  8769 &  Zula &     Zeb \\
1882 &  8148 &  9557 &  Zula &     Zed \\
1883 &  8012 &  8894 &  Zula &    Zeno \\
1884 &  9217 &  9388 &  Zula &  Zollie \\
1885 &  9128 &  8756 &  Zula &  Zollie \\
\bottomrule
\end{tabular}

\hypertarget{joining-tables}{%
\section{Joining Tables}\label{joining-tables}}

When working on data science projects, we're unlikely to have absolutely
all the data we want contained in a single DataFrame -- a real-world
data scientist needs to grapple with data coming from multiple sources.
If we have access to multiple datasets with related information, we can
join two or more tables into a single DataFrame.

To put this into practice, we'll revisit the \texttt{elections} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elections.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 &    win &  56.203927 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 &   loss &  43.796073 \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 &    win &  54.574789 \\
\bottomrule
\end{tabular}

Say we want to understand the 2020 popularity of the names of each
presidential candidate. To do this, we'll need the combined data of
\texttt{babynames} \emph{and} \texttt{elections}.

We'll start by creating a new column containing the first name of each
presidential candidate. This will help us join each name in
\texttt{elections} to the corresponding name data in \texttt{babynames}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This \textasciigrave{}str\textasciigrave{} operation splits each candidate\textquotesingle{}s full name at each }
\CommentTok{\# blank space, then takes just the candidiate\textquotesingle{}s first name}
\NormalTok{elections[}\StringTok{"First Name"}\NormalTok{] }\OperatorTok{=}\NormalTok{ elections[}\StringTok{"Candidate"}\NormalTok{].}\BuiltInTok{str}\NormalTok{.split().}\BuiltInTok{str}\NormalTok{[}\DecValTok{0}\NormalTok{]}
\NormalTok{elections.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlrl}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote & Result &          \% & First Name \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 &     Andrew \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 &    win &  42.789878 &       John \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 &    win &  56.203927 &     Andrew \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 &   loss &  43.796073 &       John \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 &    win &  54.574789 &     Andrew \\
\bottomrule
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Here, we\textquotesingle{}ll only consider \textasciigrave{}babynames\textasciigrave{} data from 2020}
\NormalTok{babynames\_2020 }\OperatorTok{=}\NormalTok{ babynames[babynames[}\StringTok{"Year"}\NormalTok{]}\OperatorTok{==}\DecValTok{2020}\NormalTok{]}
\NormalTok{babynames\_2020.head()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lllrr}
\toprule
{} &       Name & Sex &  Count &  Year \\
\midrule
0 &     Olivia &   F &  17641 &  2020 \\
1 &       Emma &   F &  15656 &  2020 \\
2 &        Ava &   F &  13160 &  2020 \\
3 &  Charlotte &   F &  13065 &  2020 \\
4 &     Sophia &   F &  13036 &  2020 \\
\bottomrule
\end{tabular}

Now, we're ready to join the two tables.
\href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html}{\texttt{pd.merge}}
is the \texttt{pandas} method used to join DataFrames together. The
\texttt{left} and \texttt{right} parameters are used to specify the
DataFrames to be joined. The \texttt{left\_on} and \texttt{right\_on}
parameters are assigned to the string names of the columns to be used
when performing the join. These two \texttt{on} parameters tell
\texttt{pandas} what values should act as pairing keys to determine
which rows to merge across the DataFrames. We'll talk more about this
idea of a pairing key next lecture.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged }\OperatorTok{=}\NormalTok{ pd.merge(left }\OperatorTok{=}\NormalTok{ elections, right }\OperatorTok{=}\NormalTok{ babynames\_2020, }\OperatorTok{\textbackslash{}}
\NormalTok{                  left\_on }\OperatorTok{=} \StringTok{"First Name"}\NormalTok{, right\_on }\OperatorTok{=} \StringTok{"Name"}\NormalTok{)}
\NormalTok{merged.head()}
\CommentTok{\# Notice that pandas automatically specifies \textasciigrave{}Year\_x\textasciigrave{} and \textasciigrave{}Year\_y\textasciigrave{} }
\CommentTok{\# when both merged DataFrames have the same column name to avoid confusion}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlrlllrr}
\toprule
{} &  Year\_x &       Candidate &                  Party &  Popular vote & Result &          \% & First Name &    Name & Sex &  Count &  Year\_y \\
\midrule
0 &    1824 &  Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 &     Andrew &  Andrew &   F &     12 &    2020 \\
1 &    1824 &  Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 &     Andrew &  Andrew &   M &   6036 &    2020 \\
2 &    1828 &  Andrew Jackson &             Democratic &        642806 &    win &  56.203927 &     Andrew &  Andrew &   F &     12 &    2020 \\
3 &    1828 &  Andrew Jackson &             Democratic &        642806 &    win &  56.203927 &     Andrew &  Andrew &   M &   6036 &    2020 \\
4 &    1832 &  Andrew Jackson &             Democratic &        702735 &    win &  54.574789 &     Andrew &  Andrew &   F &     12 &    2020 \\
\bottomrule
\end{tabular}

\bookmarksetup{startatroot}

\hypertarget{data-cleaning-and-eda}{%
\chapter{Data Cleaning and EDA}\label{data-cleaning-and-eda}}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, left=2mm, colback=white, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, rightrule=.15mm, breakable, coltitle=black, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, toprule=.15mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, leftrule=.75mm, opacityback=0, opacitybacktitle=0.6]

\begin{itemize}
\tightlist
\item
  Recognize common file formats
\item
  Categorize data by its variable type
\item
  Build awareness of issues with data faithfulness and develop targeted
  solutions
\end{itemize}

\end{tcolorbox}

In the past few lectures, we've learned that \texttt{pandas} is a
toolkit to restructure, modify, and explore a dataset. What we haven't
yet touched on is \emph{how} to make these data transformation
decisions. When we receive a new set of data from the ``real world,''
how do we know what processing we should do to convert this data into a
usable form?

\textbf{Data cleaning}, also called \textbf{data wrangling}, is the
process of transforming raw data to facilitate subsequent analysis. It
is often used to address issues like:

\begin{itemize}
\tightlist
\item
  Unclear structure or formatting
\item
  Missing or corrupted values
\item
  Unit conversions
\item
  \ldots and so on
\end{itemize}

\textbf{Exploratory Data Analysis (EDA)} is the process of understanding
a new dataset. It is an open-ended, informal analysis that involves
familiarizing ourselves with the variables present in the data,
discovering potential hypotheses, and identifying potential issues with
the data. This last point can often motivate further data cleaning to
address any problems with the dataset's format; because of this, EDA and
data cleaning are often thought of as an ``infinite loop,'' with each
process driving the other.

In this lecture, we will consider the key properties of data to consider
when performing data cleaning and EDA. In doing so, we'll develop a
``checklist'' of sorts for you to consider when approaching a new
dataset. Throughout this process, we'll build a deeper understanding of
this early (but very important!) stage of the data science lifecycle.

\hypertarget{structure}{%
\section{Structure}\label{structure}}

\hypertarget{file-format}{%
\subsection{File Format}\label{file-format}}

In the past two \texttt{pandas} lectures, we briefly touched on the idea
of file format: the way data is encoded in a file for storage.
Specifically, our \texttt{elections} and \texttt{babynames} datasets
were stored and loaded as CSVs:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{pd.read\_csv(}\StringTok{"data/elections.csv"}\NormalTok{).head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{lrllrlr}
\toprule
{} &  Year &          Candidate &                  Party &  Popular vote & Result &          \% \\
\midrule
0 &  1824 &     Andrew Jackson &  Democratic-Republican &        151271 &   loss &  57.210122 \\
1 &  1824 &  John Quincy Adams &  Democratic-Republican &        113142 &    win &  42.789878 \\
2 &  1828 &     Andrew Jackson &             Democratic &        642806 &    win &  56.203927 \\
3 &  1828 &  John Quincy Adams &    National Republican &        500897 &   loss &  43.796073 \\
4 &  1832 &     Andrew Jackson &             Democratic &        702735 &    win &  54.574789 \\
\bottomrule
\end{tabular}

CSVs, which stand for \textbf{Comma-Separated Values}, are a common
tabular data format. To better understand the properties of a CSV, let's
take a look at the first few rows of the raw data file to see what it
looks like before being loaded into a DataFrame.

\begin{verbatim}
Year,Candidate,Party,Popular vote,Result,%

1824,Andrew Jackson,Democratic-Republican,151271,loss,57.21012204

1824,John Quincy Adams,Democratic-Republican,113142,win,42.78987796

1828,Andrew Jackson,Democratic,642806,win,56.20392707
\end{verbatim}

Each row, or \textbf{record}, in the data is delimited by a newline.
Each column, or \textbf{field}, in the data is delimited by a comma
(hence, comma-separated!).

Another common file type is the \textbf{TSV (Tab-Separated Values)}. In
a TSV, records are still delimited by a newline, while fields are
delimited by \texttt{\textbackslash{}t} tab character. A TSV can be
loaded into \texttt{pandas} using \texttt{pd.read\_csv()} with the
\texttt{delimiter} parameter:
\texttt{pd.read\_csv("file\_name.tsv",\ delimiter="\textbackslash{}t")}.
A raw TSV file is shown below.

\begin{verbatim}
Year   Candidate   Party   Popular vote    Result  %

1824    Andrew Jackson  Democratic-Republican   151271  loss    57.21012204

1824    John Quincy Adams   Democratic-Republican   113142  win 42.78987796

1828    Andrew Jackson  Democratic  642806  win 56.20392707
\end{verbatim}

\textbf{JSON (JavaScript Object Notation)} files behave similarly to
Python dictionaries. They can be loaded into \texttt{pandas} using
\texttt{pd.read\_json}. A raw JSON is shown below.

\begin{verbatim}
[

 {

   "Year": 1824,

   "Candidate": "Andrew Jackson",

   "Party": "Democratic-Republican",

   "Popular vote": 151271,

   "Result": "loss",

   "%": 57.21012204

 },
\end{verbatim}

\hypertarget{variable-types}{%
\subsection{Variable Types}\label{variable-types}}

After loading data into a file, it's a good idea to take the time to
understand what pieces of information are encoded in the dataset. In
particular, we want to identify what variable types are present in our
data. Broadly speaking, we can categorize variables into one of two
overarching types.

\textbf{Quantitative variables} describe some numeric quantity or
amount. We can sub-divide quantitative data into:

\begin{itemize}
\tightlist
\item
  \textbf{Continuous quantitative variables}: numeric data that can be
  measured on a continuous scale to arbitrary precision. Continuous
  variables do not have a strict set of possible values -- they can be
  recorded to any number of decimal places. For example, weights, GPA,
  or CO2 concentrations
\item
  \textbf{Discrete quantitative variables}: numeric data that can only
  take on a finite set of possible values. For example, someone's age or
  number of siblings.
\end{itemize}

\textbf{Qualitative variables}, also known as \textbf{categorical
variables}, describe data that isn't measuring some quantity or amount.
The sub-categories of categorical data are:

\begin{itemize}
\tightlist
\item
  \textbf{Ordinal qualitative variables}: categories with ordered
  levels. Specifically, ordinal variables are those where the difference
  between levels has no consistent, quantifiable meaning. For example, a
  Yelp rating or set of income brackets.
\item
  \textbf{Nominal qualitative variables}: categories with no specific
  order. For example, someone's political affiliation or Cal ID number.
\end{itemize}

\begin{figure}

{\centering \includegraphics{eda/images/variable.png}

}

\caption{Classification of variable types}

\end{figure}

\hypertarget{primary-and-foreign-keys}{%
\subsection{Primary and Foreign Keys}\label{primary-and-foreign-keys}}

Last time, we introduced \texttt{.merge} as the \texttt{pandas} method
for joining multiple DataFrames together. In our discussion of joins, we
touched on the idea of using a ``key'' to determine what rows should be
merged from each table. Let's take a moment to examine this idea more
closely.

The \textbf{primary key} is the column or set of columns in a table that
determine the values of the remaining columns. It can be thought of as
the unique identifier for each individual row in the table. For example,
a table of Data 100 students might use each student's Cal ID as the
primary key.

\begin{tabular}{lrll}
\toprule
{} &      Cal ID &   Name &             Major \\
\midrule
0 &  3034619471 &   Oski &      Data Science \\
1 &  3035619472 &  Ollie &  Computer Science \\
2 &  3025619473 &  Orrie &      Data Science \\
3 &  3046789372 &  Ollie &         Economics \\
\bottomrule
\end{tabular}

The \textbf{foreign key} is the column or set of columns in a table that
reference primary keys in other tables. Knowing a dataset's foreign keys
can be useful when assigning the \texttt{left\_on} and
\texttt{right\_on} parameters of \texttt{.merge}. In the table of office
hour tickets below, \texttt{"Cal\ ID"} is a foreign key referencing the
previous table.

\begin{tabular}{lrrl}
\toprule
{} &  OH Request \# &      Cal ID &  Question \\
\midrule
0 &             1 &  3034619471 &   HW 2 Q1 \\
1 &             2 &  3035619472 &   HW 2 Q3 \\
2 &             3 &  3025619473 &  Lab 3 Q4 \\
3 &             4 &  3035619472 &   HW 2 Q7 \\
\bottomrule
\end{tabular}

\hypertarget{granularity-scope-and-temporality}{%
\section{Granularity, Scope, and
Temporality}\label{granularity-scope-and-temporality}}

After understanding the structure of the dataset, the next task is to
determine what exactly the data represents. We'll do so by considering
the data's granularity, scope, and temporality.

The \textbf{granularity} of a dataset is the level of detail included in
the data. To determine the data's granularity, ask: what does each row
in the dataset represent? Fine-grained data contains a high level of
detail, with a single row representing a small individual unit. For
example, each record may represent one person. Coarse-grained data is
encoded such that a single row represents a large individual unit -- for
example, each record may represent a group of people.

The \textbf{scope} of a dataset is the subset of the population covered
by the data. If we were investigating student performance in Data
Science courses, a dataset with narrow scope might encompass all
students enrolled in Data 100; a dataset with expansive scope might
encompass all students in California.

The \textbf{temporality} of a dataset describes the time period over
which the data was collected. To fully understand the temporality of the
data, it may be necessary to standardize timezones or inspect recurring
time-based trends in the data (Do patterns recur in 24-hour patterns?
Over the course of a month? Seasonally?).

\hypertarget{faithfulness}{%
\section{Faithfulness}\label{faithfulness}}

At this stage in our data cleaning and EDA workflow, we've achieved
quite a lot: we've identified how our data is structured, come to terms
with what information it encodes, and gained insight as to how it was
generated. Throughout this process, we should always recall the original
intent of our work in Data Science -- to use data to better understand
and model the real world. To achieve this goal, we need to ensure that
the data we use is faithful to reality; that is, that our data
accurately captures the ``real world.''

Data used in research or industry is often ``messy'' -- there may be
errors or inaccuracies that impact the faithfulness of the dataset.
Signs that data may not be faithful include:

\begin{itemize}
\tightlist
\item
  Unrealistic or ``incorrect'' values, such as negative counts,
  locations that don't exist, or dates set in the future
\item
  Violations of obvious dependencies, like an age that does not match a
  birthday
\item
  Clear signs that data was entered by hand, which can lead to spelling
  errors or fields that are incorrectly shifted
\item
  Signs of data falsification, such as fake email addresses or repeated
  use of the same names
\item
  Duplicated records or fields containing the same information
\end{itemize}

A common issue encountered with real-world datasets is that of missing
data. One strategy to resolve this is to simply drop any records with
missing values from the dataset. This does, however, introduce the risk
of inducing biases -- it is possible that the missing or corrupt records
may be systemically related to some feature of interest in the data.

Another method to address missing data is to perform
\textbf{imputation}: infer the missing values using other data available
in the dataset. There is a wide variety of imputation techniques that
can be implemented; some of the most common are listed below.

\begin{itemize}
\tightlist
\item
  Average imputation: replace missing values with the average value for
  that field
\item
  Hot deck imputation: replace missing values with some random value
\item
  Regression imputation: develop a model to predict missing values
\item
  Multiple imputation: replace missing values with multiple random
  values
\end{itemize}

Regardless of the strategy used to deal with missing data, we should
think carefully about \emph{why} particular records or fields may be
missing -- this can help inform whether or not the absence of these
values is signficant in some meaningful way.



\end{document}
