[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principles and Techniques of Data Science",
    "section": "",
    "text": "Welcome"
  },
  {
    "objectID": "index.html#about-the-course-notes",
    "href": "index.html#about-the-course-notes",
    "title": "Principles and Techniques of Data Science",
    "section": "About the Course Notes",
    "text": "About the Course Notes\nThis text was developed for the Spring 2023 Edition of the UC Berkeley course Data 100: Principles and Techniques of Data Science.\nAs this project is in development during the Spring 2023 semester, the course notes may be in flux. We appreciate your understanding. If you spot any errors or would like to suggest any changes, please email us.   Email: data100.instructors@berkeley.edu"
  },
  {
    "objectID": "pandas_3/pandas_3.html#groupby-continued",
    "href": "pandas_3/pandas_3.html#groupby-continued",
    "title": "4  Pandas III",
    "section": "4.1 GroupBy, Continued",
    "text": "4.1 GroupBy, Continued\nAs we learned last lecture, a groupby operation involves some combination of splitting a DataFrame into grouped subframes, applying a function, and combining the results.\nFor some arbitrary DataFrame df below, the code df.groupby(\"year\").agg(sum) does the following:\n\nOrganizes all rows with the same year into a subframe for that year.\nCreates a new DataFrame with one row representing each subframe year.\nCombines all integer rows in each subframe using the sum function.\n\n\n\n4.1.1 Aggregation with lambda Functions\nThroughout this note, we’ll work with the elections DataFrame.\n\n\nCode\nimport pandas as pd\n\nelections = pd.read_csv(\"data/elections.csv\")\nelections.head(5)\n\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n    \n  \n\n\n\n\nWhat if we wish to aggregate our DataFrame using a non-standard function – for example, a function of our own design? We can do so by combining .agg with lambda expressions.\nLet’s first consider a puzzle to jog our memory. We will attempt to find the Candidate from each Party with the highest % of votes.\nA naive approach may be to group by the Party column and aggregate by the maximum.\n\nelections.groupby(\"Party\").agg(max).head(10)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Popular vote\n      Result\n      %\n    \n    \n      Party\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      American\n      1976\n      Thomas J. Anderson\n      873053\n      loss\n      21.554001\n    \n    \n      American Independent\n      1976\n      Lester Maddox\n      9901118\n      loss\n      13.571218\n    \n    \n      Anti-Masonic\n      1832\n      William Wirt\n      100715\n      loss\n      7.821583\n    \n    \n      Anti-Monopoly\n      1884\n      Benjamin Butler\n      134294\n      loss\n      1.335838\n    \n    \n      Citizens\n      1980\n      Barry Commoner\n      233052\n      loss\n      0.270182\n    \n    \n      Communist\n      1932\n      William Z. Foster\n      103307\n      loss\n      0.261069\n    \n    \n      Constitution\n      2016\n      Michael Peroutka\n      203091\n      loss\n      0.152398\n    \n    \n      Constitutional Union\n      1860\n      John Bell\n      590901\n      loss\n      12.639283\n    \n    \n      Democratic\n      2020\n      Woodrow Wilson\n      81268924\n      win\n      61.344703\n    \n    \n      Democratic-Republican\n      1824\n      John Quincy Adams\n      151271\n      win\n      57.210122\n    \n  \n\n\n\n\nThis approach is clearly wrong – the DataFrame claims that Woodrow Wilson won the presidency in 2020.\nWhy is this happening? Here, the max aggregation function is taken over every column independently. Among Democrats, max is computing:\n\nThe most recent Year a Democratic candidate ran for president (2020)\nThe Candidate with the alphabetically “largest” name (“Woodrow Wilson”)\nThe Result with the alphabetically “largest” outcome (“win”)\n\nInstead, let’s try a different approach. We will:\n\nSort the DataFrame so that rows are in descending order of %\nGroup by Party and select the first row of each groupby object\n\nWhile it may seem unintuitive, sorting elections by descending order of % is extremely helpful. If we then group by Party, the first row of each groupby object will contain information about the Candidate with the highest voter %.\n\nelections_sorted_by_percent = elections.sort_values(\"%\", ascending=False)\nelections_sorted_by_percent.head(5)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      114\n      1964\n      Lyndon Johnson\n      Democratic\n      43127041\n      win\n      61.344703\n    \n    \n      91\n      1936\n      Franklin Roosevelt\n      Democratic\n      27752648\n      win\n      60.978107\n    \n    \n      120\n      1972\n      Richard Nixon\n      Republican\n      47168710\n      win\n      60.907806\n    \n    \n      79\n      1920\n      Warren Harding\n      Republican\n      16144093\n      win\n      60.574501\n    \n    \n      133\n      1984\n      Ronald Reagan\n      Republican\n      54455472\n      win\n      59.023326\n    \n  \n\n\n\n\n\nelections_sorted_by_percent.groupby(\"Party\").agg(lambda x : x.iloc[0]).head(10)\n\n# Equivalent to the below code\n# elections_sorted_by_percent.groupby(\"Party\").agg('first').head(10)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Popular vote\n      Result\n      %\n    \n    \n      Party\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      American\n      1856\n      Millard Fillmore\n      873053\n      loss\n      21.554001\n    \n    \n      American Independent\n      1968\n      George Wallace\n      9901118\n      loss\n      13.571218\n    \n    \n      Anti-Masonic\n      1832\n      William Wirt\n      100715\n      loss\n      7.821583\n    \n    \n      Anti-Monopoly\n      1884\n      Benjamin Butler\n      134294\n      loss\n      1.335838\n    \n    \n      Citizens\n      1980\n      Barry Commoner\n      233052\n      loss\n      0.270182\n    \n    \n      Communist\n      1932\n      William Z. Foster\n      103307\n      loss\n      0.261069\n    \n    \n      Constitution\n      2008\n      Chuck Baldwin\n      199750\n      loss\n      0.152398\n    \n    \n      Constitutional Union\n      1860\n      John Bell\n      590901\n      loss\n      12.639283\n    \n    \n      Democratic\n      1964\n      Lyndon Johnson\n      43127041\n      win\n      61.344703\n    \n    \n      Democratic-Republican\n      1824\n      Andrew Jackson\n      151271\n      loss\n      57.210122\n    \n  \n\n\n\n\nNotice how our code correctly determines that Lyndon Johnson from the Democratic Party has the highest voter %.\nMore generally, lambda functions are used to design custom aggregation functions that aren’t pre-defined by Python. The input parameter x to the lambda function is a GroupBy object. Therefore, it should make sense why lambda x : x.iloc[0] selects the first row in each groupby object.\nIn fact, there’s a few different ways to approach this problem. Each approach has different tradeoffs in terms of readability, performance, memory consumption, complexity, etc. We’ve given a few examples below.\nNote: Understanding these alternative solutions is not required. They are given to demonstrate the vast number of problem-solving approaches in pandas.\n\n# Using the idxmax function\nbest_per_party = elections.loc[elections.groupby('Party')['%'].idxmax()]\nbest_per_party.head(5)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      22\n      1856\n      Millard Fillmore\n      American\n      873053\n      loss\n      21.554001\n    \n    \n      115\n      1968\n      George Wallace\n      American Independent\n      9901118\n      loss\n      13.571218\n    \n    \n      6\n      1832\n      William Wirt\n      Anti-Masonic\n      100715\n      loss\n      7.821583\n    \n    \n      38\n      1884\n      Benjamin Butler\n      Anti-Monopoly\n      134294\n      loss\n      1.335838\n    \n    \n      127\n      1980\n      Barry Commoner\n      Citizens\n      233052\n      loss\n      0.270182\n    \n  \n\n\n\n\n\n# Using the .drop_duplicates function\nbest_per_party2 = elections.sort_values('%').drop_duplicates(['Party'], keep='last')\nbest_per_party2.head(5)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      148\n      1996\n      John Hagelin\n      Natural Law\n      113670\n      loss\n      0.118219\n    \n    \n      164\n      2008\n      Chuck Baldwin\n      Constitution\n      199750\n      loss\n      0.152398\n    \n    \n      110\n      1956\n      T. Coleman Andrews\n      States' Rights\n      107929\n      loss\n      0.174883\n    \n    \n      147\n      1996\n      Howard Phillips\n      Taxpayers\n      184656\n      loss\n      0.192045\n    \n    \n      136\n      1988\n      Lenora Fulani\n      New Alliance\n      217221\n      loss\n      0.237804"
  },
  {
    "objectID": "pandas_3/pandas_3.html#other-groupby-features",
    "href": "pandas_3/pandas_3.html#other-groupby-features",
    "title": "4  Pandas III",
    "section": "4.2 Other GroupBy Features",
    "text": "4.2 Other GroupBy Features\nThere are many aggregation methods we can use with .agg. Some useful options are:\n\n.max: creates a new DataFrame with the maximum value of each group\n.mean: creates a new DataFrame with the mean value of each group\n.size: creates a new Series with the number of entries in each group\n\nIn fact, these (and other) aggregation functions are so common that pandas allows for writing shorthand. Instead of explicitly stating the use of .agg, we can call the function directly on the GroupBy object.\nFor example, the following are equivalent:\n\nelections.groupby(\"Candidate\").agg(mean)\nelections.groupby(\"Candidate\").mean()\n\n\n4.2.1 The groupby.filter function\nAnother common use for GroupBy objects is to filter data by group.\ngroupby.filter takes an argument \\(\\text{f}\\), where \\(\\text{f}\\) is a function that:\n\nTakes a GroupBy object as input\nReturns a single True or False for the entire subframe\n\nGroupBy objects that correspond to True are returned in the final result, whereas those with a False value are not. Importantly, groupby.filter is different from groupby.agg in that the entire subframe is returned in the final DataFrame, not just a single row.\nTo illustrate how this happens, consider the following .filter function applied on some arbitrary data. Say we want to identify “tight” election years – that is, we want to find all rows that correspond to elections years where all candidates in that year won a similar portion of the total vote. Specifically, let’s find all rows corresponding to a year where no candidate won more than 45% of the total vote.\nAn equivalent way of framing this goal is to say:\n\nFind the years where the maximum % in that year is less than 45%\nReturn all DataFrame rows that correspond to these years\n\nFor each year, we need to find the maximum % among all rows for that year. If this maximum % is lower than 45%, we will tell pandas to keep all rows corresponding to that year.\n\nelections.groupby(\"Year\").filter(lambda sf: sf[\"%\"].max() < 45).head(9)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      23\n      1860\n      Abraham Lincoln\n      Republican\n      1855993\n      win\n      39.699408\n    \n    \n      24\n      1860\n      John Bell\n      Constitutional Union\n      590901\n      loss\n      12.639283\n    \n    \n      25\n      1860\n      John C. Breckinridge\n      Southern Democratic\n      848019\n      loss\n      18.138998\n    \n    \n      26\n      1860\n      Stephen A. Douglas\n      Northern Democratic\n      1380202\n      loss\n      29.522311\n    \n    \n      66\n      1912\n      Eugene V. Debs\n      Socialist\n      901551\n      loss\n      6.004354\n    \n    \n      67\n      1912\n      Eugene W. Chafin\n      Prohibition\n      208156\n      loss\n      1.386325\n    \n    \n      68\n      1912\n      Theodore Roosevelt\n      Progressive\n      4122721\n      loss\n      27.457433\n    \n    \n      69\n      1912\n      William Taft\n      Republican\n      3486242\n      loss\n      23.218466\n    \n    \n      70\n      1912\n      Woodrow Wilson\n      Democratic\n      6296284\n      win\n      41.933422\n    \n  \n\n\n\n\nWhat’s going on here? In this example, we’ve defined our filtering function, \\(\\text{f}\\), to be lambda sf: sf[\"%\"].max() < 45. This filtering function will find the maximum \"%\" value among all entries in the grouped subframe, which we call sf. If the maximum value is less than 45, then the filter function will return True and all rows in that grouped subframe will appear in the final output DataFrame.\nExamine the DataFrame above. Notice how, in this preview of the first 9 rows, all entries from the years 1860 and 1912 appear. This means that in 1860 and 1912, no candidate in that year won more than 45% of the total vote.\nYou may ask: how is the groupby.filter procedure different to the boolean filtering we’ve seen previously? Boolean filtering considers individual rows when applying a boolean condition. For example, the code elections[elections[\"%\"] < 45] will check the \"%\" value of every single row in elections; if it is less than 45, then that row will be kept in the output. groupby.filter, in contrast, applies a boolean condition across all rows in a group. If not all rows in that group satisfy the condition specified by the filter, the entire group will be discarded in the output."
  },
  {
    "objectID": "pandas_3/pandas_3.html#aggregating-data-with-pivot-tables",
    "href": "pandas_3/pandas_3.html#aggregating-data-with-pivot-tables",
    "title": "4  Pandas III",
    "section": "4.3 Aggregating Data with Pivot Tables",
    "text": "4.3 Aggregating Data with Pivot Tables\nWe know now that .groupby gives us the ability to group and aggregate data across our DataFrame. The examples above formed groups using just one column in the DataFrame. It’s possible to group by multiple columns at once by passing in a list of columns names to .groupby.\nLet’s consider the babynames dataset from last lecture. In this problem, we will find the total number of baby names associated with each sex for each year. To do this, we’ll group by both the \"Year\" and \"Sex\" columns.\n\n\nCode\nimport urllib.request\nimport os.path\n\n# Download data from the web directly\ndata_url = \"https://www.ssa.gov/oact/babynames/names.zip\"\nlocal_filename = \"data/babynames.zip\"\nif not os.path.exists(local_filename): # if the data exists don't download again\n    with urllib.request.urlopen(data_url) as resp, open(local_filename, 'wb') as f:\n        f.write(resp.read())\n\n        \n# Load data without unzipping the file\nimport zipfile\nbabynames = [] \nwith zipfile.ZipFile(local_filename, \"r\") as zf:\n    data_files = [f for f in zf.filelist if f.filename[-3:] == \"txt\"]\n    def extract_year_from_filename(fn):\n        return int(fn[3:7])\n    for f in data_files:\n        year = extract_year_from_filename(f.filename)\n        with zf.open(f) as fp:\n            df = pd.read_csv(fp, names=[\"Name\", \"Sex\", \"Count\"])\n            df[\"Year\"] = year\n            babynames.append(df)\nbabynames = pd.concat(babynames)\n\n\n\nbabynames.head()\n\n\n\n\n\n  \n    \n      \n      Name\n      Sex\n      Count\n      Year\n    \n  \n  \n    \n      0\n      Mary\n      F\n      7065\n      1880\n    \n    \n      1\n      Anna\n      F\n      2604\n      1880\n    \n    \n      2\n      Emma\n      F\n      2003\n      1880\n    \n    \n      3\n      Elizabeth\n      F\n      1939\n      1880\n    \n    \n      4\n      Minnie\n      F\n      1746\n      1880\n    \n  \n\n\n\n\n\n# Find the total number of baby names associated with each sex for each year in the data\nbabynames.groupby([\"Year\", \"Sex\"])[[\"Count\"]].agg(sum).head(6)\n\n\n\n\n\n  \n    \n      \n      \n      Count\n    \n    \n      Year\n      Sex\n      \n    \n  \n  \n    \n      1880\n      F\n      90994\n    \n    \n      M\n      110490\n    \n    \n      1881\n      F\n      91953\n    \n    \n      M\n      100737\n    \n    \n      1882\n      F\n      107847\n    \n    \n      M\n      113686\n    \n  \n\n\n\n\nNotice that both \"Year\" and \"Sex\" serve as the index of the DataFrame (they are both rendered in bold). We’ve created a multindex where two different index values, the year and sex, are used to uniquely identify each row.\nThis isn’t the most intuitive way of representing this data – and, because multindexes have multiple dimensions in their index, they can often be difficult to use.\nAnother strategy to aggregate across two columns is to create a pivot table. You saw these back in Data 8. One set of values is used to create the index of the table; another set is used to define the column names. The values contained in each cell of the table correspond to the aggregated data for each index-column pair.\nThe best way to understand pivot tables is to see one in action. Let’s return to our original goal of summing the total number of names associated with each combination of year and sex. We’ll call the pandas .pivot_table method to create a new table.\n\n# The `pivot_table` method is used to generate a Pandas pivot table\nimport numpy as np\nbabynames.pivot_table(index = \"Year\", columns = \"Sex\", values = \"Count\", aggfunc = np.sum).head(5)\n\n\n\n\n\n  \n    \n      Sex\n      F\n      M\n    \n    \n      Year\n      \n      \n    \n  \n  \n    \n      1880\n      90994\n      110490\n    \n    \n      1881\n      91953\n      100737\n    \n    \n      1882\n      107847\n      113686\n    \n    \n      1883\n      112319\n      104625\n    \n    \n      1884\n      129019\n      114442\n    \n  \n\n\n\n\nLooks a lot better! Now, our DataFrame is structured with clear index-column combinations. Each entry in the pivot table represents the summed count of names for a given combination of \"Year\" and \"Sex\".\nLet’s take a closer look at the code implemented above.\n\nindex = \"Year\" specifies the column name in the original DataFrame that should be used as the index of the pivot table\ncolumns = \"Sex\" specifies the column name in the original DataFrame that should be used to generate the columns of the pivot table\nvalues = \"Count\" indicates what values from the original DataFrame should be used to populate the entry for each index-column combination\naggfunc = np.sum tells pandas what function to use when aggregating the data specified by values. Here, we are summing the name counts for each pair of \"Year\" and \"Sex\"\n\nWe can even include multiple values in the index or columns of our pivot tables.\n\nbabynames_pivot = babynames.pivot_table(\n    index=\"Year\",     # the rows (turned into index)\n    columns=\"Sex\",    # the column values\n    values=[\"Count\", \"Name\"], \n    aggfunc=max,   # group operation\n)\nbabynames_pivot.head(6)\n\n\n\n\n\n  \n    \n      \n      Count\n      Name\n    \n    \n      Sex\n      F\n      M\n      F\n      M\n    \n    \n      Year\n      \n      \n      \n      \n    \n  \n  \n    \n      1880\n      7065\n      9655\n      Zula\n      Zeke\n    \n    \n      1881\n      6919\n      8769\n      Zula\n      Zeb\n    \n    \n      1882\n      8148\n      9557\n      Zula\n      Zed\n    \n    \n      1883\n      8012\n      8894\n      Zula\n      Zeno\n    \n    \n      1884\n      9217\n      9388\n      Zula\n      Zollie\n    \n    \n      1885\n      9128\n      8756\n      Zula\n      Zollie"
  },
  {
    "objectID": "pandas_3/pandas_3.html#joining-tables",
    "href": "pandas_3/pandas_3.html#joining-tables",
    "title": "4  Pandas III",
    "section": "4.4 Joining Tables",
    "text": "4.4 Joining Tables\nWhen working on data science projects, we’re unlikely to have absolutely all the data we want contained in a single DataFrame – a real-world data scientist needs to grapple with data coming from multiple sources. If we have access to multiple datasets with related information, we can join two or more tables into a single DataFrame.\nTo put this into practice, we’ll revisit the elections dataset.\n\nelections.head(5)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n    \n  \n\n\n\n\nSay we want to understand the 2020 popularity of the names of each presidential candidate. To do this, we’ll need the combined data of babynames and elections.\nWe’ll start by creating a new column containing the first name of each presidential candidate. This will help us join each name in elections to the corresponding name data in babynames.\n\n# This `str` operation splits each candidate's full name at each \n# blank space, then takes just the candidiate's first name\nelections[\"First Name\"] = elections[\"Candidate\"].str.split().str[0]\nelections.head(5)\n\n\n\n\n\n  \n    \n      \n      Year\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n      First Name\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n      Andrew\n    \n    \n      1\n      1824\n      John Quincy Adams\n      Democratic-Republican\n      113142\n      win\n      42.789878\n      John\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n      Andrew\n    \n    \n      3\n      1828\n      John Quincy Adams\n      National Republican\n      500897\n      loss\n      43.796073\n      John\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n      Andrew\n    \n  \n\n\n\n\n\n# Here, we'll only consider `babynames` data from 2020\nbabynames_2020 = babynames[babynames[\"Year\"]==2020]\nbabynames_2020.head()\n\n\n\n\n\n  \n    \n      \n      Name\n      Sex\n      Count\n      Year\n    \n  \n  \n    \n      0\n      Olivia\n      F\n      17641\n      2020\n    \n    \n      1\n      Emma\n      F\n      15656\n      2020\n    \n    \n      2\n      Ava\n      F\n      13160\n      2020\n    \n    \n      3\n      Charlotte\n      F\n      13065\n      2020\n    \n    \n      4\n      Sophia\n      F\n      13036\n      2020\n    \n  \n\n\n\n\nNow, we’re ready to join the two tables. pd.merge is the pandas method used to join DataFrames together. The left and right parameters are used to specify the DataFrames to be joined. The left_on and right_on parameters are assigned to the string names of the columns to be used when performing the join. These two on parameters tell pandas what values should act as pairing keys to determine which rows to merge across the DataFrames. We’ll talk more about this idea of a pairing key next lecture.\n\nmerged = pd.merge(left = elections, right = babynames_2020, \\\n                  left_on = \"First Name\", right_on = \"Name\")\nmerged.head()\n# Notice that pandas automatically specifies `Year_x` and `Year_y` \n# when both merged DataFrames have the same column name to avoid confusion\n\n\n\n\n\n  \n    \n      \n      Year_x\n      Candidate\n      Party\n      Popular vote\n      Result\n      %\n      First Name\n      Name\n      Sex\n      Count\n      Year_y\n    \n  \n  \n    \n      0\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n      Andrew\n      Andrew\n      F\n      12\n      2020\n    \n    \n      1\n      1824\n      Andrew Jackson\n      Democratic-Republican\n      151271\n      loss\n      57.210122\n      Andrew\n      Andrew\n      M\n      6036\n      2020\n    \n    \n      2\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n      Andrew\n      Andrew\n      F\n      12\n      2020\n    \n    \n      3\n      1828\n      Andrew Jackson\n      Democratic\n      642806\n      win\n      56.203927\n      Andrew\n      Andrew\n      M\n      6036\n      2020\n    \n    \n      4\n      1832\n      Andrew Jackson\n      Democratic\n      702735\n      win\n      54.574789\n      Andrew\n      Andrew\n      F\n      12\n      2020"
  }
]