<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.21">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>23&nbsp; Logistic Regression II (Summer 2025) – Principles and Techniques of Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../pca_1/pca_1.html" rel="next">
<link href="../logistic_regression_1/logistic_reg_1.html" rel="prev">
<link href="../data100_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea1d7ac60288e0f1efdbc993fd8432ae.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-48faffd076f6e246ab7435acea77d2f2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../logistic_regression_2/logistic_reg_2.html"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Logistic Regression II (Summer 2025)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../data100_logo.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../data100_logo.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Principles and Techniques of Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/DS-100/course-notes" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_lec/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_1/pandas_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Pandas I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_2/pandas_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_3/pandas_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas III</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda/eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Cleaning and EDA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regex/regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Regular Expressions (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_1/visualization_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visualization I (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_2/visualization_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Visualization II (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling/sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Sampling (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modeling_slr/modeling_slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Modeling &amp; SLR (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../constant_model_loss_transformations/loss_transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Constant Model, Loss, and Transformations (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ols/ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ordinary Least Squares (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gradient_descent/gradient_descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">sklearn and Gradient Descent (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../feature_engineering/feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Gradient Descent Continuation, Feature Engineering (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../case_study_HCE/case_study_HCE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cv_regularization/cv_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_1/probability_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Random Variables (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_2/probability_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Estimators, Bias, and Variance (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference_causality/inference_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Parameter Inference and Bootstrapping (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_I/sql_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">SQL I (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_II/sql_II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">SQL II (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_1/logistic_reg_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Logistic Regression I (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_2/logistic_reg_2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Logistic Regression II (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_1/pca_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">PCA I (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_2/pca_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">PCA II (Summer 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Clustering (Summer 2025)</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#cross-entropy-loss" id="toc-cross-entropy-loss" class="nav-link active" data-scroll-target="#cross-entropy-loss"><span class="header-section-number">23.1</span> Cross-Entropy Loss</a>
  <ul>
  <li><a href="#why-not-mse" id="toc-why-not-mse" class="nav-link" data-scroll-target="#why-not-mse"><span class="header-section-number">23.1.1</span> Why Not MSE?</a></li>
  <li><a href="#motivating-cross-entropy-loss" id="toc-motivating-cross-entropy-loss" class="nav-link" data-scroll-target="#motivating-cross-entropy-loss"><span class="header-section-number">23.1.2</span> Motivating Cross-Entropy Loss</a></li>
  </ul></li>
  <li><a href="#review-decision-boundaries" id="toc-review-decision-boundaries" class="nav-link" data-scroll-target="#review-decision-boundaries"><span class="header-section-number">23.2</span> Review : Decision Boundaries</a></li>
  <li><a href="#linear-separability-and-regularization" id="toc-linear-separability-and-regularization" class="nav-link" data-scroll-target="#linear-separability-and-regularization"><span class="header-section-number">23.3</span> Linear Separability and Regularization</a>
  <ul>
  <li><a href="#regularized-logistic-regression" id="toc-regularized-logistic-regression" class="nav-link" data-scroll-target="#regularized-logistic-regression"><span class="header-section-number">23.3.1</span> Regularized Logistic Regression</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="header-section-number">23.4</span> Performance Metrics</a>
  <ul>
  <li><a href="#types-of-classification" id="toc-types-of-classification" class="nav-link" data-scroll-target="#types-of-classification"><span class="header-section-number">23.4.1</span> Types of Classification</a></li>
  <li><a href="#accuracy-precision-and-recall" id="toc-accuracy-precision-and-recall" class="nav-link" data-scroll-target="#accuracy-precision-and-recall"><span class="header-section-number">23.4.2</span> Accuracy, Precision, and Recall</a></li>
  <li><a href="#example-calculation" id="toc-example-calculation" class="nav-link" data-scroll-target="#example-calculation"><span class="header-section-number">23.4.3</span> Example Calculation</a>
  <ul>
  <li><a href="#model-1" id="toc-model-1" class="nav-link" data-scroll-target="#model-1"><span class="header-section-number">23.4.3.1</span> Model 1</a></li>
  <li><a href="#model-2" id="toc-model-2" class="nav-link" data-scroll-target="#model-2"><span class="header-section-number">23.4.3.2</span> Model 2</a></li>
  </ul></li>
  <li><a href="#precision-vs.-recall" id="toc-precision-vs.-recall" class="nav-link" data-scroll-target="#precision-vs.-recall"><span class="header-section-number">23.4.4</span> Precision vs.&nbsp;Recall</a></li>
  <li><a href="#three-more-metrics" id="toc-three-more-metrics" class="nav-link" data-scroll-target="#three-more-metrics"><span class="header-section-number">23.4.5</span> Three More Metrics</a></li>
  </ul></li>
  <li><a href="#adjusting-the-classification-threshold" id="toc-adjusting-the-classification-threshold" class="nav-link" data-scroll-target="#adjusting-the-classification-threshold"><span class="header-section-number">23.5</span> Adjusting the Classification Threshold</a>
  <ul>
  <li><a href="#precision-recall-curves" id="toc-precision-recall-curves" class="nav-link" data-scroll-target="#precision-recall-curves"><span class="header-section-number">23.5.1</span> Precision-Recall Curves</a></li>
  <li><a href="#f1-score" id="toc-f1-score" class="nav-link" data-scroll-target="#f1-score"><span class="header-section-number">23.5.2</span> F1 Score</a></li>
  <li><a href="#the-roc-curve" id="toc-the-roc-curve" class="nav-link" data-scroll-target="#the-roc-curve"><span class="header-section-number">23.5.3</span> The ROC Curve</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">23.5.4</span> Summary</a></li>
  </ul></li>
  <li><a href="#bonus-maximum-likelihood-estimation" id="toc-bonus-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#bonus-maximum-likelihood-estimation"><span class="header-section-number">23.6</span> [BONUS] Maximum Likelihood Estimation</a>
  <ul>
  <li><a href="#building-intuition-the-coin-flip" id="toc-building-intuition-the-coin-flip" class="nav-link" data-scroll-target="#building-intuition-the-coin-flip"><span class="header-section-number">23.6.1</span> Building Intuition: The Coin Flip</a></li>
  <li><a href="#likelihood-of-data" id="toc-likelihood-of-data" class="nav-link" data-scroll-target="#likelihood-of-data"><span class="header-section-number">23.6.2</span> Likelihood of Data</a></li>
  </ul></li>
  <li><a href="#bonus-gradient-descent-for-logistic-regression" id="toc-bonus-gradient-descent-for-logistic-regression" class="nav-link" data-scroll-target="#bonus-gradient-descent-for-logistic-regression"><span class="header-section-number">23.7</span> [BONUS] Gradient Descent for Logistic Regression</a>
  <ul>
  <li><a href="#gradient-descent-update-rule" id="toc-gradient-descent-update-rule" class="nav-link" data-scroll-target="#gradient-descent-update-rule"><span class="header-section-number">23.7.1</span> Gradient Descent Update Rule</a></li>
  <li><a href="#stochastic-gradient-descent-update-rule" id="toc-stochastic-gradient-descent-update-rule" class="nav-link" data-scroll-target="#stochastic-gradient-descent-update-rule"><span class="header-section-number">23.7.2</span> Stochastic Gradient Descent Update Rule</a></li>
  </ul></li>
  <li><a href="#bonus-auc-of-the-random-predictor" id="toc-bonus-auc-of-the-random-predictor" class="nav-link" data-scroll-target="#bonus-auc-of-the-random-predictor"><span class="header-section-number">23.8</span> [BONUS] AUC of the Random Predictor</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Logistic Regression II (Summer 2025)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Learning Outcomes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li>Apply decision rules to make a classification</li>
<li>Learn when logistic regression works well and when it does not</li>
<li>Introduce new metrics for model performance</li>
</ul>
</div>
</div>
</div>
<p>Today, we will continue studying the Logistic Regression model and discuss decision boundaries that help inform the classification of a particular prediction and learn about linear separability. Starting off from cross-entropy loss, we’ll study a few of its pitfalls, and learn potential remedies. We will also provide an implementation of <code>sklearn</code>’s logistic regression model. Lastly, we’ll return to decision rules and discuss metrics that allow us to determine our model’s performance in different scenarios.</p>
<p>This will introduce us to the process of <strong>thresholding</strong> – a technique used to <em>classify</em> data from our model’s predicted probabilities, or <span class="math inline">\(P(Y=1|x)\)</span>. In doing so, we’ll focus on how these thresholding decisions affect the behavior of our model and learn various evaluation metrics useful for binary classification, and apply them to our study of logistic regression.</p>
<section id="cross-entropy-loss" class="level2" data-number="23.1">
<h2 data-number="23.1" class="anchored" data-anchor-id="cross-entropy-loss"><span class="header-section-number">23.1</span> Cross-Entropy Loss</h2>
<p>To quantify the error of our logistic regression model, we’ll need to define a new loss function.</p>
<section id="why-not-mse" class="level3" data-number="23.1.1">
<h3 data-number="23.1.1" class="anchored" data-anchor-id="why-not-mse"><span class="header-section-number">23.1.1</span> Why Not MSE?</h3>
<p>You may wonder: why not use our familiar mean squared error? It turns out that the MSE is not well suited for logistic regression. To see why, let’s consider a simple, artificially generated <code>toy</code> dataset with just one feature (this will be easier to work with than the more complicated <code>games</code> data).</p>
<div id="3adcc2c8" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.seterr(divide<span class="op">=</span><span class="st">'ignore'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}</code></pre>
</div>
</div>
<div id="d43cfe74" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>toy_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>        <span class="st">"x"</span>: [<span class="op">-</span><span class="dv">4</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>],</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"y"</span>: [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]})</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>toy_df.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>-4.0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>-2.0</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>-0.5</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>1.0</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>3.0</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We’ll construct a basic logistic regression model with only one feature and no intercept term. Our predicted probabilities take the form:</p>
<p><span class="math display">\[p=\hat{P}_\theta(Y=1|x)= \sigma({x^{T}\theta}) = \frac{1}{1+e^{-\theta_1 x}}\]</span></p>
<p>In the cell below, we plot the MSE for our model on the data.</p>
<div id="e64a0590" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.e<span class="op">**</span>(<span class="op">-</span>z))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_on_toy_data(theta):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    p_hat <span class="op">=</span> sigmoid(toy_df[<span class="st">'x'</span>] <span class="op">*</span> theta)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean((toy_df[<span class="st">'y'</span>] <span class="op">-</span> p_hat)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>thetas <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">15</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.plot(thetas, [mse_on_toy_data(theta) <span class="cf">for</span> theta <span class="kw">in</span> thetas])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"MSE on toy classification data"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r'</span><span class="dv">$</span><span class="ch">\t</span><span class="vs">heta_1</span><span class="dv">$</span><span class="vs">'</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MSE'</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="logistic_reg_2_files/figure-html/cell-4-output-1.png" width="589" height="451" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This looks nothing like the parabola we found when plotting the MSE of a linear regression model! In particular, we can identify two flaws with using the MSE for logistic regression:</p>
<ol type="1">
<li>The MSE loss surface is <em>non-convex</em>. There is both a global minimum and a (barely perceptible) local minimum in the loss surface above. This means that there is the risk of gradient descent converging on the local minimum of the loss surface, missing the true optimum parameter <span class="math inline">\(\theta_1\)</span>.
<center>
<img src="images/global_local_min.png" alt="reg" width="400">
</center></li>
<li>Squared loss is <em>bounded</em> for a classification task. MSE never gets very large, because both response and predicted probability are bounded by 1. Recall that each true <span class="math inline">\(y\)</span> has a value of either 0 or 1. This means that even if our model makes the worst possible prediction (e.g.&nbsp;predicting <span class="math inline">\(p=0\)</span> for <span class="math inline">\(y=1\)</span>), the squared loss for an observation will be no greater than 1: <span class="math display">\[(y-p)^2=(1-0)^2=1\]</span> The MSE does not strongly penalize poor predictions.
<center>
<img src="images/squared_loss.png" alt="reg" width="400">
</center></li>
</ol>
</section>
<section id="motivating-cross-entropy-loss" class="level3" data-number="23.1.2">
<h3 data-number="23.1.2" class="anchored" data-anchor-id="motivating-cross-entropy-loss"><span class="header-section-number">23.1.2</span> Motivating Cross-Entropy Loss</h3>
<p>Suffice to say, we don’t want to use the MSE when working with logistic regression. Instead, we’ll consider what kind of behavior we would <em>like</em> to see in a loss function.</p>
<p>Let <span class="math inline">\(y\)</span> be the binary label (it can either be 0 or 1), and <span class="math inline">\(p\)</span> be the model’s predicted probability of the label <span class="math inline">\(y\)</span> being 1.</p>
<ul>
<li>When the true <span class="math inline">\(y\)</span> is 1, we should incur <em>low loss</em> when the model predicts <em>large</em> <span class="math inline">\(p\)</span></li>
<li>When the true <span class="math inline">\(y\)</span> is 0, we should incur <em>high loss</em> when the model predicts <em>large</em> <span class="math inline">\(p\)</span></li>
</ul>
<p>In other words, our loss function should behave differently depending on the value of the true class, <span class="math inline">\(y\)</span>.</p>
<p>The <strong>cross-entropy loss</strong> incorporates this changing behavior. We will use it throughout our work on logistic regression. Below, we write out the cross-entropy loss for a <em>single</em> datapoint (no averages just yet). Again let <span class="math inline">\(y\)</span> be a binary label {0, 1}, and <span class="math inline">\(p\)</span> be the probability of the label being 1.</p>
<p><span class="math display">\[\text{Cross-Entropy Loss} = \begin{cases}
  -\log{(p)}  &amp; \text{if } y=1 \\
  -\log{(1-p)} &amp; \text{if } y=0
\end{cases}\]</span></p>
<p>Why does this (seemingly convoluted) loss function “work”? Let’s break it down.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>When <span class="math inline">\(y=1\)</span></th>
<th>When <span class="math inline">\(y=0\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="images/y=1.png" alt="cross-entropy loss when Y=1" width="300"></td>
<td><img src="images/y=0.png" alt="cross-entropy loss when Y=0" width="300"></td>
</tr>
<tr class="even">
<td>As <span class="math inline">\(p \rightarrow 0\)</span>, loss approches <span class="math inline">\(\infty\)</span></td>
<td>As <span class="math inline">\(p \rightarrow 0\)</span>, loss approches 0</td>
</tr>
<tr class="odd">
<td>As <span class="math inline">\(p \rightarrow 1\)</span>, loss approaches 0</td>
<td>As <span class="math inline">\(p \rightarrow 1\)</span>, loss approaches <span class="math inline">\(\infty\)</span></td>
</tr>
</tbody>
</table>
<!-- :::: {.columns}

::: {.column width="35%"}
When $y=1$
<center><img src="images/y=1.png" alt='cross-entropy loss when Y=1' width='300'></center>

* As $p \rightarrow 0$, loss approches $\infty$
* As $p \rightarrow 1$, loss approaches 0
  
:::

::: {.column width="20%"}
:::

::: {.column width="35%"}
When $y=0$
<center><img src="images/y=0.png" alt='cross-entropy loss when Y=0' width='300'></center>

* As $p \rightarrow 0$, loss approches 0
* As $p \rightarrow 1$, loss approaches $\infty$
  
:::

:::: -->
<p>All good – we are seeing the behavior we want for our logistic regression model.</p>
<p>The piecewise function we outlined above is difficult to optimize: we don’t want to constantly “check” which form of the loss function we should be using at each step of choosing the optimal model parameters. We can re-express cross-entropy loss in a more convenient way:</p>
<p><span class="math display">\[\text{Cross-Entropy Loss} = -\left(y\log{(p)}+(1-y)\log{(1-p)}\right)\]</span></p>
<p>By setting <span class="math inline">\(y\)</span> to 0 or 1, we see that this new form of cross-entropy loss gives us the same behavior as the original formulation. Another way to think about this is that in either scenario (y being equal to 0 or 1), only one of the cross-entropy loss terms is activated, which gives us a convenient way to combine the two independent loss functions.</p>
<div class="columns">
<div class="column" style="width:35%;">
<p>When <span class="math inline">\(y=1\)</span>:</p>
<p><span class="math display">\[\begin{align}
\text{CE} &amp;= -\left((1)\log{(p)}+(1-1)\log{(1-p)}\right)\\
&amp;= -\log{(p)}
\end{align}\]</span></p>
</div><div class="column" style="width:20%;">

</div><div class="column" style="width:35%;">
<p>When <span class="math inline">\(y=0\)</span>:</p>
<p><span class="math display">\[\begin{align}
\text{CE} &amp;= -\left((0)\log{(p)}+(1-0)\log{(1-p)}\right)\\
&amp;= -\log{(1-p)}
\end{align}\]</span></p>
</div>
</div>
<p>The empirical risk of the logistic regression model is then the mean cross-entropy loss across all datapoints in the dataset. When fitting the model, we want to determine the model parameter <span class="math inline">\(\theta\)</span> that leads to the lowest mean cross-entropy loss possible. For logistic regression, the empirical risk over a sample of size n is:</p>
<p><span class="math display">\[
\begin{align}
R(\theta) &amp;= - \frac{1}{n} \sum_{i=1}^n \left(y_i\log{(p_i)}+(1-y_i)\log{(1-p_i)}\right) \\
&amp;= - \frac{1}{n} \sum_{i=1}^n \left(y_i\log{\sigma(\mathbb{X}_i^{\top}\theta)}+(1-y_i)\log{(1-\sigma(\mathbb{X}_i^{\top}\theta))}\right)
\end{align}
\]</span></p>
<p>The optimization problem is therefore to find the estimate <span class="math inline">\(\hat{\theta}\)</span> that minimizes <span class="math inline">\(R(\theta)\)</span>:</p>
<p><span class="math display">\[
\hat{\theta} = \underset{\theta}{\arg\min} - \frac{1}{n} \sum_{i=1}^n \left(y_i\log{(\sigma(\mathbb{X}_i^{\top}\theta))}+(1-y_i)\log{(1-\sigma(\mathbb{X}_i^{\top}\theta))}\right)
\]</span></p>
<p>Plotting the cross-entropy loss surface for our <code>toy</code> dataset gives us a more encouraging result – our loss function is now convex. This means we can optimize it using gradient descent. Computing the gradient of the logistic model is fairly challenging, so we’ll let <code>sklearn</code> take care of this for us. You won’t need to compute the gradient of the logistic model in Data 100.</p>
<div id="0cb2d18b" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy(y, p_hat):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span> y <span class="op">*</span> np.log(p_hat) <span class="op">-</span> (<span class="dv">1</span> <span class="op">-</span> y) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> p_hat)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_cross_entropy_on_toy_data(theta):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    p_hat <span class="op">=</span> sigmoid(toy_df[<span class="st">'x'</span>] <span class="op">*</span> theta)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(cross_entropy(toy_df[<span class="st">'y'</span>], p_hat))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.plot(thetas, [mean_cross_entropy_on_toy_data(theta) <span class="cf">for</span> theta <span class="kw">in</span> thetas], color <span class="op">=</span> <span class="st">'green'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r'Mean Cross-Entropy Loss</span><span class="kw">(</span><span class="dv">$</span><span class="ch">\t</span><span class="vs">heta</span><span class="dv">$</span><span class="kw">)</span><span class="vs">'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r'</span><span class="dv">$</span><span class="ch">\t</span><span class="vs">heta</span><span class="dv">$</span><span class="vs">'</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="logistic_reg_2_files/figure-html/cell-5-output-1.png" width="587" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="review-decision-boundaries" class="level2" data-number="23.2">
<h2 data-number="23.2" class="anchored" data-anchor-id="review-decision-boundaries"><span class="header-section-number">23.2</span> Review : Decision Boundaries</h2>
<p>Let’s start with a recap of decision boundaries that we covered at the end of the previous lecture. In logistic regression, we model the <em>probability</em> that a datapoint belongs to Class 1.</p>
<center>
<img src="images/log_reg_summary.png" alt="tpr_fpr" width="800">
</center>
<p><br> In the last lecture, we developed the logistic regression model to predict that probability, but we never actually made any <em>classifications</em> for whether our prediction <span class="math inline">\(y\)</span> belongs in Class 0 or Class 1.</p>
<p><span class="math display">\[ p = \hat{P}_\theta(Y=1 | x) = \frac{1}{1 + e^{-x^{\top}\theta}}\]</span></p>
<p>A <strong>decision rule</strong> tells us how to interpret the output of the model to make a decision on how to classify a datapoint. We commonly make decision rules by specifying a <strong>threshold</strong>, <span class="math inline">\(T\)</span>. If the predicted probability is greater than or equal to <span class="math inline">\(T\)</span>, predict Class 1. Otherwise, predict Class 0.</p>
<p><span class="math display">\[\hat y = \text{classify}(x) = \begin{cases}
        \text{Class 1}, &amp; p \ge T\\
        \text{Class 0}, &amp; p &lt; T
    \end{cases}\]</span></p>
<p>The threshold is often set to <span class="math inline">\(T = 0.5\)</span>, but <em>not always</em>. We’ll discuss why we might want to use other thresholds <span class="math inline">\(T \neq 0.5\)</span> later in this lecture.</p>
<p>Using our decision rule, we can define a <strong>decision boundary</strong> as the “line” that splits the data into classes based on its features. For logistic regression, since we are working in <span class="math inline">\(p\)</span> dimensions, the decision boundary is a <strong>hyperplane</strong> – a linear combination of the features in <span class="math inline">\(p\)</span>-dimensions – and we can recover it from the final logistic regression model. For example, if we have a model with 2 features (2D), we have <span class="math inline">\(\theta = [\theta_0, \theta_1, \theta_2]\)</span> including the intercept term, and we can solve for the decision boundary like so:</p>
<p><span class="math display">\[
\begin{align}
T &amp;= \frac{1}{1 + e^{-(\theta_0 + \theta_1 * \text{feature1} +  \theta_2 * \text{feature2})}} \\
1 + e^{-(\theta_0 + \theta_1 \cdot \text{feature1} +  \theta_2  \cdot  \text{feature2})} &amp;= \frac{1}{T} \\
e^{-(\theta_0 + \theta_1  \cdot  \text{feature1} +  \theta_2  \cdot  \text{feature2})} &amp;= \frac{1}{T} - 1 \\
\theta_0 + \theta_1  \cdot  \text{feature1} +  \theta_2  \cdot  \text{feature2} &amp;= -\log(\frac{1}{T} - 1)
\end{align}
\]</span></p>
<p>For a model with 2 features, the decision boundary is a line in terms of its features. Let’s prove this by again looking at the basketball example from the previous lecture where our two features are <code>GOAL_DIFF</code> and <code>AST</code>. Rewriting the previous equation in terms of these features, we get the following:</p>
<p><span class="math display">\[\theta_0 + \theta_1  \cdot  \text{GOAL\_DIFF} +  \theta_2  \cdot  \text{AST} = -\log(\frac{1}{T} - 1)\]</span></p>
<p>Now if we assume that the threshold T = 0.5, then <span class="math inline">\(\log(\frac{1}{0.5} - 1) = \log(1) = 0\)</span>, so substituting this in and rearranging terms, we get the following:</p>
<p><span class="math display">\[
\begin{align}
0 &amp;= \theta_0 + \theta_1  \cdot  \text{GOAL\_DIFF} +  \theta_2  \cdot  \text{AST} \\
\text{AST} &amp;= \frac{\theta_0 + \theta_1  \cdot  \text{GOAL\_DIFF}}{-\theta_2}
\end{align}
\]</span></p>
<p>This is the equation of a line of form <span class="math inline">\(y=mx+b\)</span> relating <code>AST</code> to <code>GOAL_DIFF</code>, so we’ve just proved that the decision boundary is a <strong>hyperplane</strong> that can split points into two classes! To make it easier to visualize, we’ve included an example of a 1-dimensional and a 2-dimensional decision boundary below. Notice how the decision boundary predicted by our logistic regression model perfectly separates the points into two classes. Here the color is the <em>predicted</em> class, rather than the true class.</p>
<center>
<img src="images/decision_boundary.png" alt="varying_threshold" width="800">
</center>
<p>In real life, however, that is often not the case, and we often see some overlap between points of different classes across the decision boundary. The <em>true</em> classes of the 2D data are shown below:</p>
<center>
<img src="images/decision_boundary_true.png" alt="varying_threshold" width="400">
</center>
<p>As you can see, the decision boundary predicted by our logistic regression does not perfectly separate the two classes. There’s a “muddled” region near the decision boundary where our classifier predicts the wrong class. What would the data have to look like for the classifier to make perfect predictions?</p>
</section>
<section id="linear-separability-and-regularization" class="level2" data-number="23.3">
<h2 data-number="23.3" class="anchored" data-anchor-id="linear-separability-and-regularization"><span class="header-section-number">23.3</span> Linear Separability and Regularization</h2>
<p>A classification dataset is said to be <strong>linearly separable</strong> if there exists a hyperplane <strong>among input features <span class="math inline">\(x\)</span></strong> that separates the two classes <span class="math inline">\(y\)</span>.</p>
<p>Linear separability in 1D can be found with a rugplot of a single feature where a point perfectly separates the classes (Remember that in 1D, our decision boundary is just a point). For example, notice how the plot on the bottom left is linearly separable along the vertical line <span class="math inline">\(x=0\)</span>. However, no such line perfectly separates the two classes on the bottom right.</p>
<center>
<img src="images/linear_separability_1D.png" alt="linear_separability_1D" width="800">
</center>
<p>This same definition holds in higher dimensions. If there are two features, the separating hyperplane must exist in two dimensions (any line of the form <span class="math inline">\(y=mx+b\)</span>). We can visualize this using a scatter plot.</p>
<center>
<img src="images/linear_separability_2D.png" alt="linear_separability_1D" width="800">
</center>
<p>This sounds great! When the dataset is linearly separable, a <strong>logistic regression classifier can perfectly assign datapoints into classes</strong>. Can it achieve <strong>0 cross-entropy loss</strong>?</p>
<p><span class="math display">\[-(y \log(p) + (1 - y) \log(1 - p))\]</span></p>
<p>Cross-entropy loss is 0 if <span class="math inline">\(p = 1\)</span> when <span class="math inline">\(y = 1\)</span>, and <span class="math inline">\(p = 0\)</span> when <span class="math inline">\(y = 0\)</span>. Consider a simple model with one feature and no intercept.</p>
<p><span class="math display">\[P_{\theta}(Y = 1|x) = \sigma(\theta x) = \frac{1}{1 + e^{-\theta x}}\]</span></p>
<p>What <span class="math inline">\(\theta\)</span> will achieve 0 loss if we train on the datapoint <span class="math inline">\(x = 1, y = 1\)</span>? We would want <span class="math inline">\(p = 1\)</span> which occurs when <span class="math inline">\(\theta \rightarrow \infty\)</span>.</p>
<p>However, (unexpected) complications may arise. When data is linearly separable, the <strong>optimal model parameters diverge to <span class="math inline">\(\pm \infty\)</span></strong>. <em>The sigmoid can never output exactly 0 or 1</em>, so no finite optimal <span class="math inline">\(\theta\)</span> exists. This can be a problem when using gradient descent to fit the model. Consider a simple, linearly separable “toy” dataset with two datapoints.</p>
<center>
<img src="images/toy_linear_separable_dataset.png" alt="toy_linear_separability" width="500">
</center>
<p>Let’s also visualize the mean cross entropy loss along with the direction of the gradient (how this loss surface is calculated is out of scope).</p>
<center>
<img src="images/mean_cross_entropy_loss_plot.png" alt="mean_cross_entropy_loss_plot" width="450">
</center>
<p>It’s nearly impossible to see, but the plateau to the right is slightly tilted. Because gradient descent follows the tilted loss surface downwards, it never converges. Loss keeps approaching 0 as <span class="math inline">\(\theta\)</span> increases.</p>
<p>The diverging weights cause the model to be <strong>overconfident</strong>. Say we add a new point <span class="math inline">\((x, y) = (-0.5, 1)\)</span>. Following the behavior above, our model will incorrectly predict <span class="math inline">\(p=0\)</span>, and thus, <span class="math inline">\(\hat y = 0\)</span>.</p>
<center>
<img src="images/toy_linear_separable_dataset_2.png" alt="toy_linear_separability" width="450">
</center>
<p><br> The loss incurred by this misclassified point is infinite.</p>
<p><span class="math display">\[-(y\text{ log}(p) + (1-y)\text{ log}(1-p))=1 * \text{log}(0)\]</span></p>
<p>Thus, diverging weights (<span class="math inline">\(|\theta| \rightarrow \infty\)</span>) occur with <strong>linearly separable</strong> data. “Overconfidence”, as shown here, is a particularly dangerous version of overfitting.</p>
<section id="regularized-logistic-regression" class="level3" data-number="23.3.1">
<h3 data-number="23.3.1" class="anchored" data-anchor-id="regularized-logistic-regression"><span class="header-section-number">23.3.1</span> Regularized Logistic Regression</h3>
<p>To avoid large weights and infinite loss (particularly on linearly separable data), we use <strong>regularization</strong>. The same principles apply as with linear regression - make sure to standardize your features first.</p>
<p>For example, <span class="math inline">\(L2\)</span> (Ridge) Logistic Regression takes on the form:</p>
<p><span class="math display">\[\underset{\theta}{\arg\min} -\frac{1}{n} \sum_{i=1}^{n} (y_i \text{log}(\sigma(X_i^T\theta)) + (1-y_i)\text{log}(1-\sigma(X_i^T\theta))) + \lambda \sum_{j=1}^{d} \theta_j^2\]</span></p>
<p>Now, let us compare the loss functions of un-regularized and regularized logistic regression.</p>
<center>
<img src="images/unreg_loss_infinite_argmin.png" alt="unreg_loss" width="450">
</center>
<center>
<img src="images/reg_loss_finite_argmin.png" alt="reg_loss" width="450">
</center>
<p>As we can see, <span class="math inline">\(L2\)</span> regularization helps us prevent diverging weights and deters against “overconfidence.”</p>
<p><code>sklearn</code>’s logistic regression defaults to <span class="math inline">\(L2\)</span> regularization and <code>C=1.0</code>; <code>C</code> is the inverse of <span class="math inline">\(\lambda\)</span>: <span class="math display">\[C = \frac{1}{\lambda}\]</span> Setting <code>C</code> to a large value, for example, <code>C=300.0</code>, results in minimal regularization.</p>
<pre><code># sklearn defaults
model = LogisticRegression(penalty = 'l2', C = 1.0, ...)
model.fit()</code></pre>
<p>Note that in Data 100, we only use <code>sklearn</code> to fit logistic regression models. There is no closed-form solution to the optimal theta vector, and the gradient is a little messy (see the bonus section below for details).</p>
<p>From here, the <code>.predict</code> function returns the predicted class <span class="math inline">\(\hat y\)</span> of the point. In the simple binary case where the threshold is 0.5,</p>
<p><span class="math display">\[\hat y = \begin{cases}
        1, &amp; P(Y=1|x) \ge 0.5\\
        0, &amp; \text{otherwise }
    \end{cases}\]</span></p>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="23.4">
<h2 data-number="23.4" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">23.4</span> Performance Metrics</h2>
<p>You might be thinking, if we’ve already introduced cross-entropy loss, why do we need additional ways of assessing how well our models perform? In linear regression, we made numerical predictions and used a loss function to determine how “good” these predictions were. In logistic regression, our ultimate goal is to <strong><em>classify</em> data</strong> – we are much more concerned with whether or not each datapoint was assigned the correct class using the decision rule. As such, we are interested in the <strong><em>quality</em> of classifications decisions for a choice of threshold</strong>, not the predicted probabilities.</p>
<p>The most basic evaluation metric is <strong>accuracy</strong>, that is, the proportion of correctly classified points.</p>
<p><span class="math display">\[\text{accuracy} = \frac{\# \text{ of points classified correctly}}{\# \text{ of total points}}\]</span></p>
<p>Translated to code:</p>
<pre><code>def accuracy(X, Y):
    return np.mean(model.predict(X) == Y)
    
model.score(X, y) # built-in accuracy function</code></pre>
<p>You can find the <code>sklearn</code> documentation <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score">here</a>.</p>
<p>However, accuracy is not always a great metric for classification. To understand why, let’s consider a classification problem with 100 emails where only 5 are truly spam, and the remaining 95 are truly ham. We’ll investigate two models where accuracy is a poor metric.</p>
<ul>
<li><strong>Model 1</strong>: Our first model classifies every email as non-spam. The model’s accuracy is high (<span class="math inline">\(\frac{95}{100} = 0.95\)</span>), but it doesn’t detect any spam emails. Despite the high accuracy, this is a bad model.</li>
<li><strong>Model 2</strong>: The second model classifies every email as spam. The accuracy is low (<span class="math inline">\(\frac{5}{100} = 0.05\)</span>), but the model correctly labels every spam email. Unfortunately, it also misclassifies every non-spam email.</li>
</ul>
<p>As this example illustrates, accuracy is not always a good metric for classification, particularly when your data could exhibit <strong>class imbalance</strong> (e.g., very few 1’s compared to 0’s).</p>
<section id="types-of-classification" class="level3" data-number="23.4.1">
<h3 data-number="23.4.1" class="anchored" data-anchor-id="types-of-classification"><span class="header-section-number">23.4.1</span> Types of Classification</h3>
<p>There are 4 different different classifications that our model might make:</p>
<ol type="1">
<li><strong>True positive</strong>: correctly classify a positive point as being positive (<span class="math inline">\(y=1\)</span> and <span class="math inline">\(\hat{y}=1\)</span>)</li>
<li><strong>True negative</strong>: correctly classify a negative point as being negative (<span class="math inline">\(y=0\)</span> and <span class="math inline">\(\hat{y}=0\)</span>)</li>
<li><strong>False positive</strong>: incorrectly classify a negative point as being positive (<span class="math inline">\(y=0\)</span> and <span class="math inline">\(\hat{y}=1\)</span>)</li>
<li><strong>False negative</strong>: incorrectly classify a positive point as being negative (<span class="math inline">\(y=1\)</span> and <span class="math inline">\(\hat{y}=0\)</span>)</li>
</ol>
<p>These classifications can be concisely summarized in a <strong>confusion matrix</strong>.</p>
<center>
<img src="images/confusion_matrix.png" alt="confusion_matrix" width="450">
</center>
<p>An easy way to remember this terminology is as follows:</p>
<ol type="1">
<li>Look at the second word in the phrase. <em>Positive</em> means a prediction of 1. <em>Negative</em> means a prediction of 0.</li>
<li>Look at the first word in the phrase. <em>True</em> means our prediction was correct. <em>False</em> means it was incorrect.</li>
</ol>
<p>We can now write the accuracy calculation as <span class="math display">\[\text{accuracy} = \frac{TP + TN}{n}\]</span></p>
<p>In <code>sklearn</code>, we use the following syntax to plot a confusion matrix:</p>
<pre><code>from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_true, Y_pred)</code></pre>
<center>
<img src="images/confusion_matrix_sklearn.png" alt="confusion_matrix" width="300">
</center>
</section>
<section id="accuracy-precision-and-recall" class="level3" data-number="23.4.2">
<h3 data-number="23.4.2" class="anchored" data-anchor-id="accuracy-precision-and-recall"><span class="header-section-number">23.4.2</span> Accuracy, Precision, and Recall</h3>
<p>The purpose of our discussion of the confusion matrix was to motivate better performance metrics for classification problems with class imbalance - namely, precision and recall.</p>
<p><strong>Precision</strong> is defined as</p>
<p><span class="math display">\[\text{precision} = \frac{\text{TP}}{\text{TP + FP}}\]</span></p>
<p>Precision answers the question: “Of all observations that were predicted to be <span class="math inline">\(1\)</span>, what proportion was actually <span class="math inline">\(1\)</span>?” It measures how <strong>precise</strong> the classifier is <em>when the predictions are positive</em>, and it penalizes false positives.</p>
<p><strong>Recall</strong> (or <strong>sensitivity</strong>) is defined as</p>
<p><span class="math display">\[\text{recall} = \frac{\text{TP}}{\text{TP + FN}}\]</span></p>
<p>Recall aims to answer: “Of all observations that were actually <span class="math inline">\(1\)</span>, what proportion was predicted to be <span class="math inline">\(1\)</span>?” It measures how <strong>sensitive</strong> our classifier is to <em>actual positive observations</em>, and it penalizes false negatives.</p>
<p>Here’s a helpful graphic that summarizes our discussion above.</p>
<center>
<img src="images/precision_recall_graphic.png" alt="confusion_matrix" width="700">
</center>
</section>
<section id="example-calculation" class="level3" data-number="23.4.3">
<h3 data-number="23.4.3" class="anchored" data-anchor-id="example-calculation"><span class="header-section-number">23.4.3</span> Example Calculation</h3>
<p>In this section, we will calculate the accuracy, precision, and recall performance metrics for our earlier spam classification example. As a reminder, we had 100 emails, 5 of which were truly spam and 95 of which were ham. We designed two models:</p>
<ul>
<li>Model 1: Predict that every email is <em>non-spam</em></li>
<li>Model 2: Predict that every email is <em>spam</em></li>
</ul>
<section id="model-1" class="level4" data-number="23.4.3.1">
<h4 data-number="23.4.3.1" class="anchored" data-anchor-id="model-1"><span class="header-section-number">23.4.3.1</span> Model 1</h4>
<p>First, let’s begin by creating the confusion matrix.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>True Negative: 95</td>
<td>False Positive: 0</td>
</tr>
<tr class="even">
<td>1</td>
<td>False Negative: 5</td>
<td>True Positive: 0</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\text{accuracy} = \frac{95}{100} = 0.95\]</span> <span class="math display">\[\text{precision} = \frac{0}{0 + 0} = \text{undefined}\]</span> <span class="math display">\[\text{recall} = \frac{0}{0 + 5} = 0\]</span></p>
<p>Notice how our precision is undefined because we never predicted class <span class="math inline">\(1\)</span>. Our recall is 0 for the same reason – the numerator is 0 (we had no positive predictions).</p>
</section>
<section id="model-2" class="level4" data-number="23.4.3.2">
<h4 data-number="23.4.3.2" class="anchored" data-anchor-id="model-2"><span class="header-section-number">23.4.3.2</span> Model 2</h4>
<p>The confusion matrix for Model 2 is:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>True Negative: 0</td>
<td>False Positive: 95</td>
</tr>
<tr class="even">
<td>1</td>
<td>False Negative: 0</td>
<td>True Positive: 5</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\text{accuracy} = \frac{5}{100} = 0.05\]</span> <span class="math display">\[\text{precision} = \frac{5}{5 + 95} = 0.05\]</span> <span class="math display">\[\text{recall} = \frac{5}{5 + 0} = 1\]</span></p>
<p>Our precision is low because we have many false positives, and our recall is perfect - we correctly classified all spam emails (we never predicted class <span class="math inline">\(0\)</span>).</p>
</section>
</section>
<section id="precision-vs.-recall" class="level3" data-number="23.4.4">
<h3 data-number="23.4.4" class="anchored" data-anchor-id="precision-vs.-recall"><span class="header-section-number">23.4.4</span> Precision vs.&nbsp;Recall</h3>
<p>Precision (<span class="math inline">\(\frac{\text{TP}}{\text{TP} + \textbf{ FP}}\)</span>) penalizes false positives, while recall (<span class="math inline">\(\frac{\text{TP}}{\text{TP} + \textbf{ FN}}\)</span>) penalizes false negatives. In fact, precision and recall are <em>inversely related</em>. This is evident in our second model – we observed a high recall and low precision. Usually, there is a tradeoff in these two (most models can either minimize the number of FP or FN; and in rare cases, both).</p>
<p>The specific performance metric(s) to prioritize depends on the context. In many medical settings, there might be a much higher cost to missing positive cases. For instance, in our breast cancer example, it is more costly to misclassify malignant tumors (false negatives) than it is to incorrectly classify a benign tumor as malignant (false positives). In the case of the latter, pathologists can conduct further studies to verify malignant tumors. As such, we should minimize the number of false negatives. This is equivalent to maximizing recall.</p>
</section>
<section id="three-more-metrics" class="level3" data-number="23.4.5">
<h3 data-number="23.4.5" class="anchored" data-anchor-id="three-more-metrics"><span class="header-section-number">23.4.5</span> Three More Metrics</h3>
<p>The <strong>True Positive Rate (TPR)</strong> is defined as</p>
<p><span class="math display">\[\text{true positive rate} = \frac{\text{TP}}{\text{TP + FN}}\]</span></p>
<p>You’ll notice this is equivalent to <em>recall</em>. In the context of our spam email classifier, it answers the question: “What proportion of spam did I mark correctly?”. We’d like this to be close to <span class="math inline">\(1\)</span>.</p>
<p>The <strong>True Negative Rate (TNR)</strong> is defined as</p>
<p><span class="math display">\[\text{true negative rate} = \frac{\text{TN}}{\text{TN + FP}}\]</span></p>
<p>Another word for TNR is <em>specificity</em>. This answers the question: “What proportion of ham did I mark correctly?”. We’d like this to be close to <span class="math inline">\(1\)</span>.</p>
<p>The <strong>False Positive Rate (FPR)</strong> is defined as</p>
<p><span class="math display">\[\text{false positive rate} = \frac{\text{FP}}{\text{FP + TN}}\]</span></p>
<p>FPR is equal to <em>1 - specificity</em>, or <em>1 - TNR</em>. This answers the question: “What proportion of regular email did I mark as spam?”. We’d like this to be close to <span class="math inline">\(0\)</span>.</p>
<p>As we increase threshold <span class="math inline">\(T\)</span>, both TPR and FPR decrease. We’ve plotted this relationship below for some model on a <code>toy</code> dataset.</p>
<center>
<img src="images/tpr_fpr.png" alt="tpr_fpr" width="800">
</center>
</section>
</section>
<section id="adjusting-the-classification-threshold" class="level2" data-number="23.5">
<h2 data-number="23.5" class="anchored" data-anchor-id="adjusting-the-classification-threshold"><span class="header-section-number">23.5</span> Adjusting the Classification Threshold</h2>
<p>One way to minimize the number of FP vs.&nbsp;FN (equivalently, maximizing precision vs.&nbsp;recall) is by adjusting the classification threshold <span class="math inline">\(T\)</span>.</p>
<p><span class="math display">\[\hat y = \begin{cases}
        \text{Class 1}, &amp; p \ge T\\
        \text{Class 0}, &amp; p &lt; T
    \end{cases}\]</span></p>
<p>The default threshold in <code>sklearn</code> is <span class="math inline">\(T = 0.5\)</span>. As we increase the threshold <span class="math inline">\(T\)</span>, we “raise the standard” of how confident our classifier needs to be to predict 1 (i.e., “positive”).</p>
<center>
<img src="images/varying_threshold.png" alt="varying_threshold" width="700">
</center>
<p>As you may notice, the choice of threshold <span class="math inline">\(T\)</span> impacts our classifier’s performance.</p>
<ul>
<li>High <span class="math inline">\(T\)</span>: Most predictions are <span class="math inline">\(0\)</span>.
<ul>
<li>Lots of false negatives</li>
<li>Fewer false positives</li>
</ul></li>
<li>Low <span class="math inline">\(T\)</span>: Most predictions are <span class="math inline">\(1\)</span>.
<ul>
<li>Lots of false positives</li>
<li>Fewer false negatives</li>
</ul></li>
</ul>
<p>In fact, we can choose a threshold <span class="math inline">\(T\)</span> based on our desired number, or proportion, of false positives and false negatives. We can do so using a few different tools. We’ll touch on three of the most important ones in Data 100.</p>
<ol type="1">
<li>Precision-Recall Curve (PR Curve)</li>
<li>F1 Score</li>
<li>“Receiver Operating Characteristic” Curve (ROC Curve)</li>
</ol>
<section id="precision-recall-curves" class="level3" data-number="23.5.1">
<h3 data-number="23.5.1" class="anchored" data-anchor-id="precision-recall-curves"><span class="header-section-number">23.5.1</span> Precision-Recall Curves</h3>
<p>A <strong>Precision-Recall Curve (PR Curve)</strong> is a curve that displays the relationship between precision and recall for various threshold values. In this curve, we test out many different possible thresholds and for each one we compute the precision and recall of the classifier.</p>
<p>Let’s first consider how precision and recall change as a function of the threshold <span class="math inline">\(T\)</span>. We know this quite well from earlier – precision will generally increase, and recall will decrease.</p>
<center>
<img src="images/precision-recall-thresh.png" alt="precision-recall-thresh" width="650">
</center>
<p>Displayed below is the PR Curve for the same <code>toy</code> dataset. Notice how threshold values increase as we move to the left.</p>
<center>
<img src="images/pr_curve_thresholds.png" alt="pr_curve_thresholds" width="600">
</center>
<p>Once again, the perfect classifier will resemble the orange curve, this time, facing the opposite direction.</p>
<center>
<img src="images/pr_curve_perfect.png" alt="pr_curve_perfect" width="600">
</center>
<p>We want our PR curve to be as close to the “top right” of this graph as possible. We can use the <strong>area under curve (or AUC)</strong> to determine “closeness”, with the perfect classifier exhibiting an AUC = 1 (and the worst with an AUC = 0.5).</p>
</section>
<section id="f1-score" class="level3" data-number="23.5.2">
<h3 data-number="23.5.2" class="anchored" data-anchor-id="f1-score"><span class="header-section-number">23.5.2</span> F1 Score</h3>
<p>Another way to <strong><u>balance</u> precision and recall</strong> is to maximize the <strong><span class="math inline">\(F_1\)</span> Score</strong>:</p>
<p><span class="math display">\[ F_1\ \text{Score} = \frac{2}{\frac{1}{\text{Precision}} + \frac{1}{\text{Recall}}} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision}+\text{Recall}}\]</span></p>
<p>The <span class="math inline">\(F_1\)</span> score is the <strong>harmonic mean of precision and recall</strong>, and it is often used when there is a <strong>large class imbalance</strong>. The score optimizes for the <strong>true-positive case</strong> and <strong>balances precision and recall</strong>, so if we want to optimize for <strong>true-negatives</strong> or favor either precision or recall, it may be better to pick a different metric.</p>
<p>We can begin by calculating the <span class="math inline">\(F_1\)</span> score for different thresholds, and plotting the results below:</p>
<center>
<img src="images/f1_score.png" alt="f1_score" width="500">
</center>
<p>From this, we want to pick the threshold that <strong>maximizes the <span class="math inline">\(F_1\)</span> score</strong> and <strong>report the <span class="math inline">\(F_1\)</span> score</strong> as a metric describing the classifier. We can also plot this point on a PR curve to see how the <span class="math inline">\(F_1\)</span> score determined a point with balance between precision and recall.</p>
<center>
<img src="images/f1_score_plot.png" alt="f1_score_plot" width="400">
</center>
</section>
<section id="the-roc-curve" class="level3" data-number="23.5.3">
<h3 data-number="23.5.3" class="anchored" data-anchor-id="the-roc-curve"><span class="header-section-number">23.5.3</span> The ROC Curve</h3>
<p>The “Receiver Operating Characteristic” Curve (<strong>ROC Curve</strong>) is another method that plots the tradeoff between FPR and TPR. Notice how the far-left of the curve corresponds to higher threshold <span class="math inline">\(T\)</span> values. At lower thresholds, the FPR and TPR are both high as there are many positive predictions while at higher thresholds the FPR and TPR are both low as there are fewer positive predictions.</p>
<center>
<img src="images/roc_curve.png" alt="roc_curve" width="600">
</center>
<p>The “perfect” classifier is the one that has a TPR of 1, and FPR of 0. This is achieved at the top-left of the plot below. More generally, it’s ROC curve resembles the curve in orange.</p>
<center>
<img src="images/roc_curve_perfect.png" alt="roc_curve_perfect" width="600">
</center>
<p>We want our model to be as close to this orange curve as possible. How do we quantify “closeness”?</p>
<p>We can compute the <strong>area under curve (AUC)</strong> of the ROC curve. Notice how the perfect classifier has an AUC = 1. The closer our model’s AUC is to 1, the better it is.</p>
<p>On the other hand, a terrible model will have an AUC closer to 0.5. A predictor that <strong>predicts randomly</strong> has an AUC of 0.5. This indicates the classifier is not able to distinguish between positive and negative classes, and thus, randomly predicts one of the two. The proof for this is out of scope and is in the Bonus section.</p>
<center>
<img src="images/roc_curve_worst_predictor.png" alt="roc_curve_worst_predictor" width="700">
</center>
<p>Real-world classifiers have an AUC between 0.5 and 1.</p>
</section>
<section id="summary" class="level3" data-number="23.5.4">
<h3 data-number="23.5.4" class="anchored" data-anchor-id="summary"><span class="header-section-number">23.5.4</span> Summary</h3>
<ol type="1">
<li>When classes are <strong>relatively balanced</strong> or performance on <strong>both classes is equally important</strong>:
<ul>
<li>Pick a threshold to <strong>maximize accuracy</strong> (often close to 0.5)</li>
<li><strong>Accuracy</strong> or <strong>area under the ROC</strong> are appropriate metrics to report.</li>
</ul></li>
<li>When classes are <strong>imbalanced</strong> and performance on the <strong>positive class is more important</strong>:
<ul>
<li>Pick a threshold to <strong>maximize <span class="math inline">\(F_1\)</span> score</strong></li>
<li><strong><span class="math inline">\(F_1\)</span> score or area under the Precision-Recall Curve</strong> are appropriate metrics to report</li>
</ul></li>
</ol>
<p>Note that both the Accuracy and <span class="math inline">\(F_1\)</span> score are <strong>threshold dependent</strong> while area under the curve metrics are not.</p>
<p>Overall, be warned that working with class imbalance <em>can be challenging</em> because</p>
<ul>
<li>Many <strong>modeling techniques don’t work well</strong> with highly imbalance data.</li>
<li><strong>Results can be misleading</strong> (e.g., 95% accuracy from always guessing not spam)</li>
</ul>
</section>
</section>
<section id="bonus-maximum-likelihood-estimation" class="level2" data-number="23.6">
<h2 data-number="23.6" class="anchored" data-anchor-id="bonus-maximum-likelihood-estimation"><span class="header-section-number">23.6</span> [BONUS] Maximum Likelihood Estimation</h2>
<p>It may have seemed like we pulled cross-entropy loss out of thin air. How did we know that taking the negative logarithms of our probabilities would work so well? It turns out that cross-entropy loss is justified by probability theory.</p>
<p>The following section is out of scope, but is certainly an interesting read!</p>
<section id="building-intuition-the-coin-flip" class="level3" data-number="23.6.1">
<h3 data-number="23.6.1" class="anchored" data-anchor-id="building-intuition-the-coin-flip"><span class="header-section-number">23.6.1</span> Building Intuition: The Coin Flip</h3>
<p>To build some intuition for logistic regression, let’s look at an introductory example to classification: the coin flip. Suppose we observe some outcomes of a coin flip (1 = Heads, 0 = Tails).</p>
<div id="9ff0791f" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>flips <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>flips</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>[0, 0, 1, 1, 1, 1, 0, 0, 0, 0]</code></pre>
</div>
</div>
<p>A reasonable model is to assume all flips are IID (independent and identically distributed). In other words, each flip has the same probability of returning a 1 (or heads). Let’s define a parameter <span class="math inline">\(\theta\)</span>, the probability that the next flip is a heads. We will use this parameter to inform our decision for <span class="math inline">\(\hat y\)</span> (predicting either 0 or 1) of the next flip. If <span class="math inline">\(\theta \ge 0.5, \hat y = 1, \text{else } \hat y = 0\)</span>.</p>
<p>You may be inclined to say <span class="math inline">\(0.5\)</span> is the best choice for <span class="math inline">\(\theta\)</span>. However, notice that we made no assumption about the coin itself. The coin may be biased, so we should make our decision based only on the data. We know that exactly <span class="math inline">\(\frac{4}{10}\)</span> of the flips were heads, so we might guess <span class="math inline">\(\hat \theta = 0.4\)</span>. In the next section, we will mathematically prove why this is the best possible estimate.</p>
</section>
<section id="likelihood-of-data" class="level3" data-number="23.6.2">
<h3 data-number="23.6.2" class="anchored" data-anchor-id="likelihood-of-data"><span class="header-section-number">23.6.2</span> Likelihood of Data</h3>
<p>Let’s call the result of the coin flip a random variable <span class="math inline">\(Y\)</span>. This is a Bernoulli random variable with two outcomes. <span class="math inline">\(Y\)</span> has the following distribution:</p>
<p><span class="math display">\[P(Y = y) = \begin{cases}
        p, \text{if }  y=1\\
        1 - p, \text{if }  y=0
    \end{cases} \]</span></p>
<p><span class="math inline">\(p\)</span> is unknown to us. But we can find the <span class="math inline">\(p\)</span> that makes the data we observed the most <em>likely</em>.</p>
<p>The probability of observing 4 heads and 6 tails follows the binomial distribution.</p>
<p><span class="math display">\[\binom{10}{4} (p)^4 (1-p)^6\]</span></p>
<p>We define the <strong>likelihood</strong> of obtaining our observed data as a quantity <em>proportional</em> to the probability above. To find it, simply multiply the probabilities of obtaining each coin flip.</p>
<p><span class="math display">\[(p)^{4} (1-p)^6\]</span></p>
<p>The technique known as <strong>maximum likelihood estimation</strong> finds the <span class="math inline">\(p\)</span> that maximizes the above likelihood. You can find this maximum by taking the derivative of the likelihood, but we’ll provide a more intuitive graphical solution.</p>
<div id="dea7390b" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>thetas <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.plot(thetas, (thetas<span class="op">**</span><span class="dv">4</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>thetas)<span class="op">**</span><span class="dv">6</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"</span><span class="dv">$</span><span class="ch">\t</span><span class="vs">heta</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Likelihood"</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="logistic_reg_2_files/figure-html/cell-7-output-1.png" width="614" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>More generally, the likelihood for some Bernoulli(<span class="math inline">\(p\)</span>) random variable <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[P(Y = y) = \begin{cases}
        1, \text{with probability }  p\\
        0, \text{with probability }  1 - p
    \end{cases} \]</span></p>
<p>Equivalently, this can be written in a compact way:</p>
<p><span class="math display">\[P(Y=y) = p^y(1-p)^{1-y}\]</span></p>
<ul>
<li>When <span class="math inline">\(y = 1\)</span>, this reads <span class="math inline">\(P(Y=y) = p\)</span></li>
<li>When <span class="math inline">\(y = 0\)</span>, this reads <span class="math inline">\(P(Y=y) = (1-p)\)</span></li>
</ul>
<p>In our example, a Bernoulli random variable is analogous to a single data point (e.g., one instance of a basketball team winning or losing a game). All together, our <code>games</code> data consists of many IID Bernoulli(<span class="math inline">\(p\)</span>) random variables. To find the likelihood of independent events in succession, simply multiply their likelihoods.</p>
<p><span class="math display">\[\prod_{i=1}^{n} p^{y_i} (1-p)^{1-y_i}\]</span></p>
<p>As with the coin example, we want to find the parameter <span class="math inline">\(p\)</span> that maximizes this likelihood. Earlier, we gave an intuitive graphical solution, but let’s take the derivative of the likelihood to find this maximum.</p>
<p>At a first glance, this derivative will be complicated! We will have to use the product rule, followed by the chain rule. Instead, we can make an observation that simplifies the problem.</p>
<p>Finding the <span class="math inline">\(p\)</span> that maximizes <span class="math display">\[\prod_{i=1}^{n} p^{y_i} (1-p)^{1-y_i}\]</span> is equivalent to the <span class="math inline">\(p\)</span> that maximizes <span class="math display">\[\text{log}(\prod_{i=1}^{n} p^{y_i} (1-p)^{1-y_i})\]</span></p>
<p>This is because <span class="math inline">\(\text{log}\)</span> is a strictly <em>increasing</em> function. It won’t change the maximum or minimum of the function it was applied to. From <span class="math inline">\(\text{log}\)</span> properties, <span class="math inline">\(\text{log}(a*b)\)</span> = <span class="math inline">\(\text{log}(a) + \text{log}(b)\)</span>. We can apply this to our equation above to get:</p>
<p><span class="math display">\[\underset{p}{\text{argmax}} \sum_{i=1}^{n} \text{log}(p^{y_i} (1-p)^{1-y_i})\]</span></p>
<p><span class="math display">\[= \underset{p}{\text{argmax}} \sum_{i=1}^{n} (\text{log}(p^{y_i}) + \text{log}((1-p)^{1-y_i}))\]</span></p>
<p><span class="math display">\[= \underset{p}{\text{argmax}} \sum_{i=1}^{n} (y_i\text{log}(p) + (1-y_i)\text{log}(1-p))\]</span></p>
<p>We can add a constant factor of <span class="math inline">\(\frac{1}{n}\)</span> out front. It won’t affect the <span class="math inline">\(p\)</span> that maximizes our likelihood.</p>
<p><span class="math display">\[=\underset{p}{\text{argmax}}  \frac{1}{n} \sum_{i=1}^{n} y_i\text{log}(p) + (1-y_i)\text{log}(1-p)\]</span></p>
<p>One last “trick” we can do is change this to a minimization problem by negating the result. This works because we are dealing with a <em>concave</em> function, which can be made <em>convex</em>.</p>
<p><span class="math display">\[= \underset{p}{\text{argmin}} -\frac{1}{n} \sum_{i=1}^{n} y_i\text{log}(p) + (1-y_i)\text{log}(1-p)\]</span></p>
<p>Now let’s say that we have data that are independent with different probability <span class="math inline">\(p_i\)</span>. Then, we would want to find the <span class="math inline">\(p_1, p_2, \dots, p_n\)</span> that maximize <span class="math display">\[\prod_{i=1}^{n} p_i^{y_i} (1-p_i)^{1-y_i}\]</span></p>
<p>Setting up and simplifying the optimization problems as we did above, we ultimately want to find:</p>
<p><span class="math display">\[= \underset{p}{\text{argmin}} -\frac{1}{n} \sum_{i=1}^{n} y_i\text{log}(p_i) + (1-y_i)\text{log}(1-p_i)\]</span></p>
<p>For logistic regression, <span class="math inline">\(p_i = \sigma(x^{\top}\theta)\)</span>. Plugging that in, we get:</p>
<p><span class="math display">\[= \underset{p}{\text{argmin}} -\frac{1}{n} \sum_{i=1}^{n} y_i\text{log}(\sigma(x^{\top}\theta)) + (1-y_i)\text{log}(1-\sigma(x^{\top}\theta))\]</span></p>
<p>This is exactly our average cross-entropy loss minimization problem from before!</p>
<p>Why did we do all this complicated math? We have shown that <em>minimizing</em> cross-entropy loss is equivalent to <em>maximizing</em> the likelihood of the training data.</p>
<ul>
<li>By minimizing cross-entropy loss, we are choosing the model parameters that are “most likely” for the data we observed.</li>
</ul>
<p>Note that this is under the assumption that all data is drawn independently from the same logistic regression model with parameter <span class="math inline">\(\theta\)</span>. In fact, many of the model + loss combinations we’ve seen can be motivated using MLE (e.g., OLS, Ridge Regression, etc.). In probability and ML classes, you’ll get the chance to explore MLE further.</p>
</section>
</section>
<section id="bonus-gradient-descent-for-logistic-regression" class="level2" data-number="23.7">
<h2 data-number="23.7" class="anchored" data-anchor-id="bonus-gradient-descent-for-logistic-regression"><span class="header-section-number">23.7</span> [BONUS] Gradient Descent for Logistic Regression</h2>
<p>Let’s define the following terms: <span class="math display">\[
\begin{align}
t_i &amp;= \phi(x_i)^T \theta \\
p_i &amp;= \sigma(t_i) \\
t_i &amp;= \log(\frac{p_i}{1 - p_i}) \\
1 - \sigma(t_i) &amp;= \sigma(-t_i) \\
\frac{d}{dt}  \sigma(t) &amp;=  \sigma(t) \sigma(-t)
\end{align}
\]</span></p>
<p>Now, we can simplify the cross-entropy loss <span class="math display">\[
\begin{align}
y_i \log(p_i) + (1 - y_i) \log(1 - p_i) &amp;= y_i \log(\frac{p_i}{1 - p_i}) + \log(1 - p_i) \\
&amp;= y_i \phi(x_i)^T + \log(\sigma(-\phi(x_i)^T \theta))
\end{align}
\]</span></p>
<p>Hence, the optimal <span class="math inline">\(\hat{\theta}\)</span> is <span class="math display">\[\text{argmin}_{\theta} - \frac{1}{n} \sum_{i=1}^n (y_i \phi(x_i)^T + \log(\sigma(-\phi(x_i)^T \theta)))\]</span></p>
<p>We want to minimize <span class="math display">\[L(\theta) = - \frac{1}{n} \sum_{i=1}^n (y_i \phi(x_i)^T + \log(\sigma(-\phi(x_i)^T \theta)))\]</span></p>
<p>So we take the derivative <span class="math display">\[
\begin{align}
\triangledown_{\theta} L(\theta) &amp;= - \frac{1}{n} \sum_{i=1}^n \triangledown_{\theta} y_i \phi(x_i)^T + \triangledown_{\theta} \log(\sigma(-\phi(x_i)^T \theta)) \\
&amp;= - \frac{1}{n} \sum_{i=1}^n y_i \phi(x_i) + \triangledown_{\theta} \log(\sigma(-\phi(x_i)^T \theta)) \\
&amp;= - \frac{1}{n} \sum_{i=1}^n y_i \phi(x_i) + \frac{1}{\sigma(-\phi(x_i)^T \theta)} \triangledown_{\theta} \sigma(-\phi(x_i)^T \theta) \\
&amp;= - \frac{1}{n} \sum_{i=1}^n y_i \phi(x_i) + \frac{\sigma(-\phi(x_i)^T \theta)}{\sigma(-\phi(x_i)^T \theta)} \sigma(\phi(x_i)^T \theta)\triangledown_{\theta} \sigma(-\phi(x_i)^T \theta) \\
&amp;= - \frac{1}{n} \sum_{i=1}^n (y_i - \sigma(\phi(x_i)^T \theta)\phi(x_i))
\end{align}
\]</span></p>
<p>Setting the derivative equal to 0 and solving for <span class="math inline">\(\hat{\theta}\)</span>, we find that there’s no general analytic solution. Therefore, we must solve using numeric methods.</p>
<section id="gradient-descent-update-rule" class="level3" data-number="23.7.1">
<h3 data-number="23.7.1" class="anchored" data-anchor-id="gradient-descent-update-rule"><span class="header-section-number">23.7.1</span> Gradient Descent Update Rule</h3>
<p><span class="math display">\[\theta^{(0)} \leftarrow \text{initial vector (random, zeros, ...)} \]</span></p>
<p>For <span class="math inline">\(\tau\)</span> from 0 to convergence: <span class="math display">\[ \theta^{(\tau + 1)} \leftarrow \theta^{(\tau)} - \rho(\tau)\left( \frac{1}{n} \sum_{i=1}^n \triangledown_{\theta} L_i(\theta) \mid_{\theta = \theta^{(\tau)}}\right) \]</span></p>
</section>
<section id="stochastic-gradient-descent-update-rule" class="level3" data-number="23.7.2">
<h3 data-number="23.7.2" class="anchored" data-anchor-id="stochastic-gradient-descent-update-rule"><span class="header-section-number">23.7.2</span> Stochastic Gradient Descent Update Rule</h3>
<p><span class="math display">\[\theta^{(0)} \leftarrow \text{initial vector (random, zeros, ...)} \]</span></p>
<p>For <span class="math inline">\(\tau\)</span> from 0 to convergence, let <span class="math inline">\(B\)</span> ~ <span class="math inline">\(\text{Random subset of indices}\)</span>. <span class="math display">\[ \theta^{(\tau + 1)} \leftarrow \theta^{(\tau)} - \rho(\tau)\left( \frac{1}{|B|} \sum_{i \in B} \triangledown_{\theta} L_i(\theta) \mid_{\theta = \theta^{(\tau)}}\right) \]</span></p>
</section>
</section>
<section id="bonus-auc-of-the-random-predictor" class="level2" data-number="23.8">
<h2 data-number="23.8" class="anchored" data-anchor-id="bonus-auc-of-the-random-predictor"><span class="header-section-number">23.8</span> [BONUS] AUC of the Random Predictor</h2>
<p>Recall that the best possible AUC = 1. On the other hand, a terrible model will have an AUC closer to 0.5. A <strong>random predictor</strong> randomly predicts <span class="math inline">\(P(Y = 1 | x)\)</span> to be uniformly between 0 and 1. This indicates the classifier is not able to distinguish between positive and negative classes, and thus, randomly predicts one of the two.</p>
<center>
<img src="images/roc_curve_worst_predictor.png" alt="roc_curve_worst_predictor" width="700">
</center>
<p>We can illustrate this by comparing different thresholds and seeing their points on the ROC curve.</p>
<center>
<img src="images/roc_curve_worse_predictor_differing_T.png" alt="roc_curve_worse_predictor_differing_T" width="700">
</center>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../logistic_regression_1/logistic_reg_1.html" class="pagination-link" aria-label="Logistic Regression I (Summer 2025)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Logistic Regression I (Summer 2025)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../pca_1/pca_1.html" class="pagination-link" aria-label="PCA I (Summer 2025)">
        <span class="nav-page-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">PCA I (Summer 2025)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>