<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>16&nbsp; Cross Validation and Regularization (from Spring 2025) – Principles and Techniques of Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../probability_1/probability_1.html" rel="next">
<link href="../case_study_HCE/case_study_HCE.html" rel="prev">
<link href="../data100_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-94a17236e36dd7124376e363a2cd9c3d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../cv_regularization/cv_reg.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization (from Spring 2025)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../data100_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Principles and Techniques of Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/DS-100/course-notes" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_lec/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_1/pandas_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Pandas I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_2/pandas_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_3/pandas_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas III</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda/eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Cleaning and EDA (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regex/regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Regular Expressions (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_1/visualization_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visualization I (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_2/visualization_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Visualization II (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling/sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Sampling (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../modeling_slr/modeling_slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Modeling &amp; SLR (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../constant_model_loss_transformations/loss_transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Constant Model, Loss, and Transformations (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ols/ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ordinary Least Squares (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gradient_descent/gradient_descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">sklearn and Gradient Descent (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../feature_engineering/feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Gradient Descent Continuation, Feature Engineering (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../case_study_HCE/case_study_HCE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cv_regularization/cv_reg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_1/probability_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Random Variables (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_2/probability_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Estimators, Bias, and Variance (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inference_causality/inference_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Parameter Inference and Bootstrapping (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_I/sql_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">SQL I (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_II/sql_II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">SQL II (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_1/logistic_reg_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Logistic Regression I (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_2/logistic_reg_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Logistic Regression II (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_1/pca_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">PCA I (from Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_2/pca_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">PCA II (Spring 2025)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Clustering (from Spring 2025)</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link active" data-scroll-target="#cross-validation"><span class="header-section-number">16.1</span> Cross-validation</a>
  <ul>
  <li><a href="#training-test-and-validation-sets" id="toc-training-test-and-validation-sets" class="nav-link" data-scroll-target="#training-test-and-validation-sets"><span class="header-section-number">16.1.1</span> Training, Test, and Validation Sets</a>
  <ul>
  <li><a href="#test-sets" id="toc-test-sets" class="nav-link" data-scroll-target="#test-sets"><span class="header-section-number">16.1.1.1</span> Test Sets</a></li>
  <li><a href="#validation-sets" id="toc-validation-sets" class="nav-link" data-scroll-target="#validation-sets"><span class="header-section-number">16.1.1.2</span> Validation Sets</a></li>
  </ul></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation"><span class="header-section-number">16.1.2</span> K-Fold Cross-Validation</a></li>
  <li><a href="#model-selection-workflow" id="toc-model-selection-workflow" class="nav-link" data-scroll-target="#model-selection-workflow"><span class="header-section-number">16.1.3</span> Model Selection Workflow</a></li>
  <li><a href="#hyperparameters" id="toc-hyperparameters" class="nav-link" data-scroll-target="#hyperparameters"><span class="header-section-number">16.1.4</span> Hyperparameters</a></li>
  </ul></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization"><span class="header-section-number">16.2</span> Regularization</a>
  <ul>
  <li><a href="#constraining-model-parameters" id="toc-constraining-model-parameters" class="nav-link" data-scroll-target="#constraining-model-parameters"><span class="header-section-number">16.2.1</span> Constraining Model Parameters</a></li>
  <li><a href="#l1-lasso-regularization" id="toc-l1-lasso-regularization" class="nav-link" data-scroll-target="#l1-lasso-regularization"><span class="header-section-number">16.2.2</span> L1 (LASSO) Regularization</a></li>
  <li><a href="#scaling-features-for-regularization" id="toc-scaling-features-for-regularization" class="nav-link" data-scroll-target="#scaling-features-for-regularization"><span class="header-section-number">16.2.3</span> Scaling Features for Regularization</a></li>
  <li><a href="#l2-ridge-regularization" id="toc-l2-ridge-regularization" class="nav-link" data-scroll-target="#l2-ridge-regularization"><span class="header-section-number">16.2.4</span> L2 (Ridge) Regularization</a></li>
  </ul></li>
  <li><a href="#regression-summary" id="toc-regression-summary" class="nav-link" data-scroll-target="#regression-summary"><span class="header-section-number">16.3</span> Regression Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization (from Spring 2025)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Outcomes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li>Recognize the need for validation and test sets to preview model performance on unseen data</li>
<li>Apply cross-validation to select model hyperparameters</li>
<li>Understand the conceptual basis for L1 and L2 regularization</li>
</ul>
</div>
</div>
</div>
<p>At the end of the Feature Engineering lecture (Lecture 14), we arrived at the issue of fine-tuning model complexity. We identified that a model that’s too complex can lead to overfitting while a model that’s too simple can lead to underfitting. This brings us to a natural question: how do we control model complexity to avoid under- and overfitting?</p>
<p>To answer this question, we will need to address two things: first, we need to understand <em>when</em> our model begins to overfit by assessing its performance on unseen data. We can achieve this through <strong>cross-validation</strong>. Secondly, we need to introduce a technique to adjust the complexity of our models ourselves – to do so, we will apply <strong>regularization</strong>.</p>
<section id="cross-validation" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="cross-validation"><span class="header-section-number">16.1</span> Cross-validation</h2>
<section id="training-test-and-validation-sets" class="level3" data-number="16.1.1">
<h3 data-number="16.1.1" class="anchored" data-anchor-id="training-test-and-validation-sets"><span class="header-section-number">16.1.1</span> Training, Test, and Validation Sets</h3>
<center>
<img src="images/simple_under_overfit.png" alt="train-test-split" width="400">
</center>
<p><br></p>
<p>From lecture 14, we learned that <em>increasing</em> model complexity <em>decreased</em> our model’s training error but <em>increased</em> its variance. This makes intuitive sense: adding more features causes our model to fit more closely to data it encountered during training, but it generalizes worse to new data that hasn’t been seen before. For this reason, a low training error is not always representative of our model’s underlying performance – we need to also assess how well it performs on unseen data to ensure that it is not overfitting.</p>
<p>Truly, the only way to know when our model overfits is by evaluating it on unseen data. Unfortunately, that means we need to wait for more data. This may be very expensive and time-consuming.</p>
<p>How should we proceed? In this section, we will build up a viable solution to this problem.</p>
<section id="test-sets" class="level4" data-number="16.1.1.1">
<h4 data-number="16.1.1.1" class="anchored" data-anchor-id="test-sets"><span class="header-section-number">16.1.1.1</span> Test Sets</h4>
<p>The simplest approach to avoid overfitting is to keep some of our data “secret” from ourselves. We can set aside a random portion of our full dataset to use <em>only</em> for testing purposes. The datapoints in this <strong>test set</strong> will <em>not</em> be used to fit the model. Instead, we will:</p>
<ul>
<li>Use the remaining portion of our dataset – now called the <strong>training set</strong> – to run ordinary least squares, gradient descent, or some other technique to train our model,</li>
<li>Take the fitted model and use it to make predictions on datapoints in the test set. The model’s performance on the test set (expressed as the MSE, RMSE, etc.) is now indicative of how well it can make predictions on <em>unseen</em> data</li>
</ul>
<p>Importantly, the optimal model parameters were found by <em>only</em> considering the data in the training set. After the model has been fitted to the training data, we do not change any parameters before making predictions on the test set. Importantly, we only ever make predictions on the test set <strong>once</strong> after all model design has been completely finalized. We treat the test set performance as the final test of how well a model does. To reiterate, the test set is only ever touched once: to compute the performance of the model after all fine-tuning has been completed.</p>
<p>The process of sub-dividing our dataset into training and test sets is known as a <strong>train-test split</strong>. Typically, between 10% and 20% of the data is allocated to the test set.</p>
<center>
<img src="images/train-test-split.png" alt="train-test-split" width="500">
</center>
<p><br></p>
<p>In <code>sklearn</code>, the <code>train_test_split</code> function (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">documentation</a>) of the <code>model_selection</code> module allows us to automatically generate train-test splits.</p>
<p>We will work with the <code>vehicles</code> dataset from previous lectures. As before, we will attempt to predict the <code>mpg</code> of a vehicle from transformations of its <code>hp</code>. In the cell below, we allocate 20% of the full dataset to testing, and the remaining 80% to training.</p>
<div id="4cb7a8f8" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset and construct the design matrix</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>vehicles <span class="op">=</span> sns.load_dataset(<span class="st">"mpg"</span>).rename(columns<span class="op">=</span>{<span class="st">"horsepower"</span>:<span class="st">"hp"</span>}).dropna()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vehicles[[<span class="st">"hp"</span>]]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"hp^2"</span>] <span class="op">=</span> vehicles[<span class="st">"hp"</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"hp^3"</span>] <span class="op">=</span> vehicles[<span class="st">"hp"</span>]<span class="op">**</span><span class="dv">3</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"hp^4"</span>] <span class="op">=</span> vehicles[<span class="st">"hp"</span>]<span class="op">**</span><span class="dv">4</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> vehicles[<span class="st">"mpg"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="3bf226f2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># `test_size` specifies the proportion of the full dataset that should be allocated to testing</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># `random_state` makes our results reproducible for educational purposes</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, Y_train, Y_test <span class="op">=</span> train_test_split(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        X, </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        Y, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">220</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Size of full dataset: </span><span class="sc">{</span>X<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> points"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Size of training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> points"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Size of test set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> points"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Size of full dataset: 392 points
Size of training set: 313 points
Size of test set: 79 points</code></pre>
</div>
</div>
<p>After performing our train-test split, we fit a model to the training set and assess its performance on the test set.</p>
<div id="b1101dd0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.linear_model <span class="im">as</span> lm</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> lm.LinearRegression()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit to the training set</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, Y_train)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate errors</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>train_error <span class="op">=</span> mean_squared_error(Y_train, model.predict(X_train))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>test_error <span class="op">=</span> mean_squared_error(Y_test, model.predict(X_test))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training error: </span><span class="sc">{</span>train_error<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test error: </span><span class="sc">{</span>test_error<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training error: 17.858516841012094
Test error: 23.192405629326508</code></pre>
</div>
</div>
</section>
<section id="validation-sets" class="level4" data-number="16.1.1.2">
<h4 data-number="16.1.1.2" class="anchored" data-anchor-id="validation-sets"><span class="header-section-number">16.1.1.2</span> Validation Sets</h4>
<p>Now, what if we were dissatisfied with our test set performance? With our current framework, we’d be stuck. As outlined previously, assessing model performance on the test set is the <em>final</em> stage of the model design process; we can’t go back and adjust our model based on the new discovery that it is overfitting. If we did, then we would be <em>factoring in information from the test set</em> to design our model. The test error would no longer be a true representation of the model’s performance on <em>unseen</em> data!</p>
<p>Our solution is to introduce a <strong>validation set</strong>. A validation set is a random portion of the <em>training set</em> that is set aside for assessing model performance while the model is <em>still being developed</em>. The process for using a validation set is:</p>
<ol type="1">
<li>Perform a train-test split.</li>
<li>Set the test set aside; we will not touch it until the very end of the model design process.</li>
<li>Set aside a portion of the training set to be used for validation.</li>
<li>Fit the model parameters to the datapoints contained in the remaining portion of the training set.</li>
<li>Assess the model’s performance on the validation set. Adjust the model as needed, re-fit it to the remaining portion of the training set, then re-evaluate it on the validation set. Repeat as necessary until you are satisfied.</li>
<li>After <em>all</em> model development is complete, assess the model’s performance on the test set. This is the final test of how well the model performs on unseen data. No further modifications should be made to the model.</li>
</ol>
<p>The process of creating a validation set is called a <strong>validation split</strong>.</p>
<center>
<img src="images/validation-split.png" alt="validation-split" width="600">
</center>
<p><br></p>
<p>Note that the validation error behaves quite differently from the training error explored previously. As the model becomes more complex, it makes better predictions on the training data; the variance of the model typically increases as model complexity increases. Validation error, on the other hand, decreases <em>then increases</em> as we increase model complexity. This reflects the transition from under- to overfitting: at low model complexity, the model underfits because it is not complex enough to capture the main trends in the data; at high model complexity, the model overfits because it “memorizes” the training data too closely.</p>
<p>We can update our understanding of the relationships between error, complexity, and model variance:</p>
<center>
<img src="images/training_validation_curve.png" alt="training_validation_curve" width="500">
</center>
<p><br></p>
<p>Our goal is to train a model with complexity near the orange dotted line – this is where our model minimizes the validation error. Note that this relationship is a simplification of the real-world, but it’s a good enough approximation for the purposes of Data 100.</p>
</section>
</section>
<section id="k-fold-cross-validation" class="level3" data-number="16.1.2">
<h3 data-number="16.1.2" class="anchored" data-anchor-id="k-fold-cross-validation"><span class="header-section-number">16.1.2</span> K-Fold Cross-Validation</h3>
<p>Introducing a validation set gave us one “extra” chance to assess model performance on another set of unseen data. We are able to finetune the model design based on its performance on this <em>one</em> set of validation data.</p>
<p>But what if, by random chance, our validation set just happened to contain many outliers? It is possible that the validation datapoints we set aside do not actually represent other unseen data that the model might encounter. Ideally, we would like to validate our model’s performance on several different unseen datasets. This would give us greater confidence in our understanding of how the model behaves on new data.</p>
<p>Let’s think back to our validation framework. Earlier, we set aside <span class="math inline">\(x\)</span>% of our training data (say, 20%) to use for validation.</p>
<center>
<img src="images/validation_set.png" alt="validation_set" width="220">
</center>
<p>In the example above, we set aside the first 20% of training datapoints for the validation set. This was an arbitrary choice. We could have set aside <em>any</em> 20% portion of the training data for validation. In fact, there are 5 non-overlapping “chunks” of training points that we could have designated as the validation set.</p>
<center>
<img src="images/possible_validation_sets.png" alt="possible_validation_sets" width="750">
</center>
<p>The common term for one of these chunks is a <strong>fold</strong>. In the example above, we had 5 folds, each containing 20% of the training data. This gives us a new perspective: we really have <em>5</em> validation sets “hidden” in our training set.</p>
<p>In <strong>cross-validation</strong>, we perform validation splits for each fold in the training set. For a dataset with <span class="math inline">\(K\)</span> folds, we:</p>
<ol type="1">
<li>Pick one fold to be the validation fold</li>
<li>Train model of data from every fold <em>other</em> than the validation fold</li>
<li>Compute the model’s error on the validation fold and record it</li>
<li>Repeat for all <span class="math inline">\(K\)</span> folds</li>
</ol>
The <strong>cross-validation error</strong> is then the <em>average</em> error across all <span class="math inline">\(K\)</span> validation folds. In the example below, the cross-validation error is the mean of validation errors #1 to #5.
<center>
<img src="images/cross_validation.png" alt="cross_validation" width="800">
</center>
</section>
<section id="model-selection-workflow" class="level3" data-number="16.1.3">
<h3 data-number="16.1.3" class="anchored" data-anchor-id="model-selection-workflow"><span class="header-section-number">16.1.3</span> Model Selection Workflow</h3>
<p>At this stage, we have refined our model selection workflow. We begin by performing a train-test split to set aside a test set for the final evaluation of model performance. Then, we alternate between adjusting our design matrix and computing the cross-validation error to finetune the model’s design. In the example below, we illustrate the use of 4-fold cross-validation to help inform model design.</p>
<center>
<img src="images/model_selection.png" alt="model_selection" width="800">
</center>
</section>
<section id="hyperparameters" class="level3" data-number="16.1.4">
<h3 data-number="16.1.4" class="anchored" data-anchor-id="hyperparameters"><span class="header-section-number">16.1.4</span> Hyperparameters</h3>
<p>An important use of cross-validation is for <strong>hyperparameter</strong> selection. A hyperparameter is some value in a model that is chosen <em>before</em> the model is fit to any data. This means that it is distinct from the <em>model parameters</em>, <span class="math inline">\(\theta_i\)</span>, because its value is selected <em>before</em> the training process begins. We cannot use our usual techniques – calculus, ordinary least squares, or gradient descent – to choose its value. Instead, we must decide it ourselves.</p>
<p>Some examples of hyperparameters in Data 100 are:</p>
<ul>
<li>The degree of our polynomial model (recall that we selected the degree before creating our design matrix and calling <code>.fit</code>)</li>
<li>The learning rate, <span class="math inline">\(\alpha\)</span>, in gradient descent</li>
<li>The regularization penalty, <span class="math inline">\(\lambda\)</span> (to be introduced later this lecture)</li>
</ul>
<p>To select a hyperparameter value via cross-validation, we first list out several “guesses” for what the best hyperparameter may be. For each guess, we then run cross-validation to compute the cross-validation error incurred by the model when using that choice of hyperparameter value. We then select the value of the hyperparameter that resulted in the lowest cross-validation error.</p>
<p>For example, we may wish to use cross-validation to decide what value we should use for <span class="math inline">\(\alpha\)</span>, which controls the step size of each gradient descent update. To do so, we list out some possible guesses for the best <span class="math inline">\(\alpha\)</span>, like 0.1, 1, and 10. For each possible value, we decide to apply 3-fold cross-validation to see what error the model has when we use that value of <span class="math inline">\(\alpha\)</span> to train it.</p>
<center>
<img src="images/hyperparameter_tuning.png" alt="hyperparameter_tuning" width="600">
</center>
</section>
</section>
<section id="regularization" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="regularization"><span class="header-section-number">16.2</span> Regularization</h2>
<p>We’ve now addressed the first of our two goals for today: creating a framework to assess model performance on unseen data. Now, we’ll discuss our second objective: developing a technique to adjust model complexity. This will allow us to directly tackle the issues of under- and overfitting.</p>
<p>Earlier, we adjusted the complexity of our polynomial model by tuning a hyperparameter – the degree of the polynomial. We tested out several different polynomial degrees, computed the validation error for each, and selected the value that minimized the validation error. Tweaking the “complexity” was simple; it was only a matter of adjusting the polynomial degree.</p>
<p>In most machine learning problems, complexity is defined differently from what we have seen so far. Today, we’ll explore two different definitions of complexity: the <em>squared</em> and <em>absolute</em> magnitude of <span class="math inline">\(\theta_i\)</span> coefficients.</p>
<section id="constraining-model-parameters" class="level3" data-number="16.2.1">
<h3 data-number="16.2.1" class="anchored" data-anchor-id="constraining-model-parameters"><span class="header-section-number">16.2.1</span> Constraining Model Parameters</h3>
<p>Think back to our work using gradient descent to descend down a loss surface. You may find it helpful to refer back to the Gradient Descent note to refresh your memory. Our aim was to find the combination of model parameters that the smallest, minimum loss. We visualized this using a contour map by plotting possible parameter values on the horizontal and vertical axes, which allows us to take a bird’s eye view above the loss surface. Notice that the contour map has <span class="math inline">\(p=2\)</span> parameters for ease of visualization. We want to find the model parameters corresponding to the lowest point on the loss surface.</p>
<center>
<img src="images/unconstrained.png" alt="unconstrained" width="450">
</center>
<p>Let’s review our current modeling framework.</p>
<p><span class="math display">\[\hat{\mathbb{Y}} = \theta_0 + \theta_1 \phi_1 + \theta_2 \phi_2 + \ldots + \theta_p \phi_p\]</span></p>
<p>Recall that we represent our features with <span class="math inline">\(\phi_i\)</span> to reflect the fact that we have performed feature engineering.</p>
<p>Previously, we restricted model complexity by limiting the total number of features present in the model. We only included a limited number of polynomial features at a time; all other polynomials were excluded from the model.</p>
<p>What if, instead of fully removing particular features, we kept all features and used each one only a “little bit”? If we put a limit on how <em>much</em> each feature can contribute to the predictions, we can still control the model’s complexity without the need to manually determine how many features should be removed.</p>
<p>What do we mean by a “little bit”? Consider the case where some parameter <span class="math inline">\(\theta_i\)</span> is close to or equal to 0. Then, feature <span class="math inline">\(\phi_i\)</span> barely impacts the prediction – the feature is weighted by such a small value that its presence doesn’t significantly change the value of <span class="math inline">\(\hat{\mathbb{Y}}\)</span>. If we restrict how large each parameter <span class="math inline">\(\theta_i\)</span> can be, we restrict how much feature <span class="math inline">\(\phi_i\)</span> contributes to the model. This has the effect of <em>reducing</em> model complexity.</p>
<p>In <strong>regularization</strong>, we restrict model complexity by <em>putting a limit</em> on the magnitudes of the model parameters <span class="math inline">\(\theta_i\)</span>.</p>
<p>What do these limits look like? Suppose we specify that the sum of all absolute parameter values can be no greater than some number <span class="math inline">\(Q\)</span>. In other words:</p>
<p><span class="math display">\[\sum_{i=1}^p |\theta_i| \leq Q\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the total number of parameters in the model. You can think of this as us giving our model a “budget” for how it distributes the magnitudes of each parameter. If the model assigns a large value to some <span class="math inline">\(\theta_i\)</span>, it may have to assign a small value to some other <span class="math inline">\(\theta_j\)</span>. This has the effect of increasing feature <span class="math inline">\(\phi_i\)</span>’s influence on the predictions while decreasing the influence of feature <span class="math inline">\(\phi_j\)</span>. The model will need to be strategic about how the parameter weights are distributed – ideally, more “important” features will receive greater weighting.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notice that the intercept term, <span class="math inline">\(\theta_0\)</span>, is excluded from this constraint. <strong>We typically do not regularize the intercept term</strong>.</p>
</div>
</div>
<p>Now, let’s think back to gradient descent and visualize the loss surface as a contour map. As a refresher, a loss surface means that each point represents the model’s loss for a particular combination of <span class="math inline">\(\theta_1\)</span>, <span class="math inline">\(\theta_2\)</span>. Let’s say our goal is to find the combination of parameters that gives us the lowest loss.</p>
<center>
<img src="images/constrained_gd.png" alt="constrained_gd" width="450">
</center>
<p><br> With no constraint, the optimal <span class="math inline">\(\hat{\theta}\)</span> is in the center. We denote this as <span class="math inline">\(\hat{\theta}_\text{No Reg}\)</span>.</p>
<p>Applying this constraint limits what combinations of model parameters are valid. We can now only consider parameter combinations with a total absolute sum less than or equal to our number <span class="math inline">\(Q\)</span>. For our 2D example, the constraint <span class="math inline">\(\sum_{i=1}^p |\theta_i| \leq Q\)</span> can be rewritten as <span class="math inline">\(|\theta_1| + |\theta_2| \leq Q\)</span>. This means that we can only assign our <em>regularized</em> parameter vector <span class="math inline">\(\hat{\theta}_{\text{Reg}}\)</span> to positions in the green diamond below.</p>
<center>
<img src="images/diamondreg.png" alt="diamondreg" width="450">
</center>
<p><br> We can no longer select the parameter vector that <em>truly</em> minimizes the loss surface, <span class="math inline">\(\hat{\theta}_{\text{No Reg}}\)</span>, because this combination of parameters does not lie within our allowed region. Instead, we select whatever allowable combination brings us <em>closest</em> to the true minimum loss, which is depicted by the red point below.</p>
<center>
<img src="images/diamond.png" alt="diamond" width="450">
</center>
<p><br> Notice that, under regularization, our optimized <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> values are much smaller than they were without regularization (indeed, <span class="math inline">\(\theta_1\)</span> has decreased to 0). The model has <em>decreased in complexity</em> because we have limited how much our features contribute to the model. In fact, by setting its parameter to 0, we have effectively removed the influence of feature <span class="math inline">\(\phi_1\)</span> from the model altogether.</p>
<p>If we change the value of <span class="math inline">\(Q\)</span>, we change the region of allowed parameter combinations. The model will still choose the combination of parameters that produces the lowest loss – the closest point in the constrained region to the true minimizer, <span class="math inline">\(\hat{\theta}_{\text{No Reg}}\)</span>.</p>
<p>When <span class="math inline">\(Q\)</span> is small, we severely restrict the size of our parameters. <span class="math inline">\(\theta_i\)</span>s are small in value, and features <span class="math inline">\(\phi_i\)</span> only contribute a little to the model. The allowed region of model parameters contracts, and the model becomes much simpler:</p>
<center>
<img src="images/diamondpoint.png" alt="diamondpoint" width="450">
</center>
<p><br></p>
<p>When <span class="math inline">\(Q\)</span> is large, we do not restrict our parameter sizes by much. <span class="math inline">\(\theta_i\)</span>s are large in value, and features <span class="math inline">\(\phi_i\)</span> contribute more to the model. The allowed region of model parameters expands, and the model becomes more complex:</p>
<center>
<img src="images/largerq.png" alt="largerq" width="450">
</center>
<p><br></p>
<p>Consider the extreme case of when <span class="math inline">\(Q\)</span> is extremely large. In this situation, our restriction has essentially no effect, and the allowed region includes the OLS solution!</p>
<center>
<img src="images/verylarge.png" alt="verylarge" width="450">
</center>
<p><br></p>
<p>Now what if <span class="math inline">\(Q\)</span> was extremely small? Most parameters are then set to (essentially) 0.</p>
<ul>
<li>If the model has no intercept term: <span class="math inline">\(\hat{\mathbb{Y}} = (0)\phi_1 + (0)\phi_2 + \ldots = 0\)</span>.</li>
<li>If the model has an intercept term: <span class="math inline">\(\hat{\mathbb{Y}} = \theta_0 + (0)\phi_1 + (0)\phi_2 + \ldots = \theta_0\)</span>. Remember that the intercept term is excluded from the constraint - this is so we avoid the situation where we always predict 0.</li>
</ul>
<p>Let’s summarize what we have seen.</p>
<center>
<img src="images/summary.png" alt="summary" width="700">
</center>
</section>
<section id="l1-lasso-regularization" class="level3" data-number="16.2.2">
<h3 data-number="16.2.2" class="anchored" data-anchor-id="l1-lasso-regularization"><span class="header-section-number">16.2.2</span> L1 (LASSO) Regularization</h3>
<p>How do we actually apply our constraint <span class="math inline">\(\sum_{i=1}^p |\theta_i| \leq Q\)</span>? We will do so by modifying the <em>objective function</em> that we seek to minimize when fitting a model.</p>
<p>Recall our ordinary least squares objective function: our goal was to find parameters that minimize the model’s mean squared error:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 \phi_{i, 1} + \theta_2 \phi_{i, 2} + \ldots + \theta_p \phi_{i, p}))^2\]</span></p>
<p>To apply our constraint, we need to rephrase our minimization goal as:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 \phi_{i, 1} + \theta_2 \phi_{i, 2} + \ldots + \theta_p \phi_{i, p}))^2\:\text{such that} \sum_{i=1}^p |\theta_i| \leq Q\]</span></p>
<p>Unfortunately, we can’t directly use this formulation as our objective function – it’s not easy to mathematically optimize over a constraint. Instead, we will apply the magic of the <a href="https://en.wikipedia.org/wiki/Duality_(optimization)">Lagrangian Duality</a>. The details of this are out of scope (take EECS 127 if you’re interested in learning more), but the end result is very useful. It turns out that minimizing the following <em>augmented</em> objective function is <em>equivalent</em> to our minimization goal above.</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 \phi_{i, 1} + \theta_2 \phi_{i, 2} + \ldots + \theta_p \phi_{i, p}))^2 + \lambda \sum_{i=1}^p \vert \theta_i \vert\]</span> <span class="math display">\[ = \frac{1}{n}||\mathbb{Y} - \mathbb{X}\theta||_2^2 + \lambda \sum_{i=1}^p |\theta_i|\]</span> <span class="math display">\[ = \frac{1}{n}||\mathbb{Y} - \mathbb{X}\theta||_2^2 + \lambda || \theta ||_1\]</span></p>
<p>The last two expressions include the MSE expressed using vector notation, and the last expression writes <span class="math inline">\(\sum_{i=1}^p |\theta_i|\)</span> as it’s <strong>L1 norm</strong> equivalent form, <span class="math inline">\(|| \theta ||_1\)</span>.</p>
<p>Notice that we’ve replaced the constraint with a second term in our objective function. We’re now minimizing a function with an additional regularization term that <em>penalizes large coefficients</em>. In order to minimize this new objective function, we’ll end up balancing two components:</p>
<ol type="1">
<li>Keeping the model’s error on the training data low, represented by the term <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 x_{i, 1} + \theta_2 x_{i, 2} + \ldots + \theta_p x_{i, p}))^2\)</span></li>
<li>Keeping the magnitudes of model parameters low, represented by the term <span class="math inline">\(\lambda \sum_{i=1}^p |\theta_i|\)</span></li>
</ol>
<p>The <span class="math inline">\(\lambda\)</span> controls the degree of regularization. Roughly speaking, <span class="math inline">\(\lambda\)</span> is related to our <span class="math inline">\(Q\)</span> constraint from before by the rule <span class="math inline">\(\lambda \approx \frac{1}{Q}\)</span>. To understand why, let’s consider two extreme examples. Recall that our goal is to minimize the cost function: <span class="math inline">\(\frac{1}{n}||\mathbb{Y} - \mathbb{X}\theta||_2^2 + \lambda || \theta ||_1\)</span>.</p>
<ul>
<li><p>Assume <span class="math inline">\(\lambda \rightarrow \infty\)</span>. Then, <span class="math inline">\(\lambda || \theta ||_1\)</span> dominates the cost function. In order to neutralize the <span class="math inline">\(\infty\)</span> and minimize this term, we set <span class="math inline">\(\theta_j = 0\)</span> for all <span class="math inline">\(j \ge 1\)</span>. This is a very constrained model that is mathematically equivalent to the constant model <!--, which also arises when $Q$ approaches $0$. --></p></li>
<li><p>Assume <span class="math inline">\(\lambda \rightarrow 0\)</span>. Then, <span class="math inline">\(\lambda || \theta ||_1=0\)</span>. Minimizing the cost function is equivalent to minimizing <span class="math inline">\(\frac{1}{n} || Y - X\theta ||_2^2\)</span>, our usual MSE loss function. The act of minimizing MSE loss is just our familiar OLS, and the optimal solution is the global minimum <span class="math inline">\(\hat{\theta} = \hat\theta_{No Reg.}\)</span>. <!-- We showed that the global optimum is achieved when the L2 norm ball radius $Q \rightarrow \infty$. --></p></li>
</ul>
<p>We call <span class="math inline">\(\lambda\)</span> the <strong>regularization penalty hyperparameter</strong>; it needs to be determined <em>prior</em> to training the model, so we must find the best value via cross-validation.</p>
<p>The process of finding the optimal <span class="math inline">\(\hat{\theta}\)</span> to minimize our new objective function is called <strong>L1 regularization</strong>. It is also sometimes known by the acronym “LASSO”, which stands for “Least Absolute Shrinkage and Selection Operator.”</p>
<p>Unlike ordinary least squares, which can be solved via the closed-form solution <span class="math inline">\(\hat{\theta}_{OLS} = (\mathbb{X}^{\top}\mathbb{X})^{-1}\mathbb{X}^{\top}\mathbb{Y}\)</span>, <strong>there is no closed-form solution for the optimal parameter vector under L1 regularization</strong>. Instead, we use the <code>Lasso</code> model class of <code>sklearn</code>.</p>
<div id="a8bcd357" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.linear_model <span class="im">as</span> lm</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The alpha parameter represents our lambda term</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>lasso_model <span class="op">=</span> lm.Lasso(alpha<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>lasso_model.fit(X_train, Y_train)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>lasso_model.coef_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>array([-2.54932056e-01, -9.48597165e-04,  8.91976284e-06, -1.22872290e-08])</code></pre>
</div>
</div>
<p>Notice that all model coefficients are very small in magnitude. In fact, some of them are so small that they are essentially 0. An important characteristic of L1 regularization is that many model parameters are set to 0. In other words, LASSO effectively <strong>selects only a subset</strong> of the features. The reason for this comes back to our loss surface and allowed “diamond” regions from earlier – we can often get closer to the lowest loss contour at a corner of the diamond than along an edge.</p>
<p>When a model parameter is set to 0 or close to 0, its corresponding feature is essentially removed from the model. We say that L1 regularization performs <strong>feature selection</strong> because, by setting the parameters of unimportant features to 0, LASSO “selects” which features are more useful for modeling. L1 regularization indicates that the features with non-zero parameters are more informative for modeling than those with parameters set to zero.</p>
</section>
<section id="scaling-features-for-regularization" class="level3" data-number="16.2.3">
<h3 data-number="16.2.3" class="anchored" data-anchor-id="scaling-features-for-regularization"><span class="header-section-number">16.2.3</span> Scaling Features for Regularization</h3>
<p>The regularization procedure we just performed had one subtle issue. To see what it is, let’s take a look at the design matrix for our <code>lasso_model</code>.</p>
<div id="7752a94d" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X_train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">hp</th>
<th data-quarto-table-cell-role="th">hp^2</th>
<th data-quarto-table-cell-role="th">hp^3</th>
<th data-quarto-table-cell-role="th">hp^4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">259</td>
<td>85.0</td>
<td>7225.0</td>
<td>614125.0</td>
<td>52200625.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">129</td>
<td>67.0</td>
<td>4489.0</td>
<td>300763.0</td>
<td>20151121.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">207</td>
<td>102.0</td>
<td>10404.0</td>
<td>1061208.0</td>
<td>108243216.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">302</td>
<td>70.0</td>
<td>4900.0</td>
<td>343000.0</td>
<td>24010000.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">71</td>
<td>97.0</td>
<td>9409.0</td>
<td>912673.0</td>
<td>88529281.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Our features – <code>hp</code>, <code>hp^2</code>, <code>hp^3</code>, and <code>hp^4</code> – are on drastically different numeric scales! The values contained in <code>hp^4</code> are orders of magnitude larger than those contained in <code>hp</code>. This can be a problem because the value of <code>hp^4</code> will naturally contribute more to each predicted <span class="math inline">\(\hat{y}\)</span> because it is so much greater than the values of the other features. For <code>hp</code> to have much of an impact at all on the prediction, it must be scaled by a large model parameter.</p>
<p>By inspecting the fitted parameters of our model, we see that this is the case – the parameter for <code>hp</code> is much larger in magnitude than the parameter for <code>hp^4</code>.</p>
<div id="ffc544ce" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">"Feature"</span>:X_train.columns, <span class="st">"Parameter"</span>:lasso_model.coef_})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Feature</th>
<th data-quarto-table-cell-role="th">Parameter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>hp</td>
<td>-2.549321e-01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>hp^2</td>
<td>-9.485972e-04</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>hp^3</td>
<td>8.919763e-06</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>hp^4</td>
<td>-1.228723e-08</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Recall that by applying regularization, we give our a model a “budget” for how it can allocate the values of model parameters. For <code>hp</code> to have much of an impact on each prediction, LASSO is forced to “spend” more of this budget on the parameter for <code>hp</code>.</p>
<p>We can avoid this issue by <strong>scaling</strong> the data before regularizing. This is a process where we convert all features to the same numeric scale. A common way to scale data is to perform <strong>standardization</strong> such that all features have mean 0 and standard deviation 1; essentially, we replace everything with its Z-score.</p>
<p><span class="math display">\[z_k = \frac{x_k - \mu_k}{\sigma_k}\]</span></p>
</section>
<section id="l2-ridge-regularization" class="level3" data-number="16.2.4">
<h3 data-number="16.2.4" class="anchored" data-anchor-id="l2-ridge-regularization"><span class="header-section-number">16.2.4</span> L2 (Ridge) Regularization</h3>
<p>In all of our work above, we considered the constraint <span class="math inline">\(\sum_{i=1}^p |\theta_i| \leq Q\)</span> to limit the complexity of the model. What if we had applied a different constraint?</p>
<p>In <strong>L2 regularization</strong>, also known as <strong>ridge regression</strong>, we constrain the model such that the sum of the <em>squared</em> parameters must be less than some number <span class="math inline">\(Q\)</span>. This constraint takes the form:</p>
<p><span class="math display">\[\sum_{i=1}^p \theta_i^2 \leq Q\]</span></p>
<p>As before, <strong>we typically do not regularize the intercept term</strong>.</p>
<p>In our 2D example, the constraint becomes <span class="math inline">\(\theta_1^2 + \theta_2^2 \leq Q\)</span>. Can you see how this is similar to the equation for a circle, <span class="math inline">\(x^2 + y^2 = r^2\)</span>? The allowed region of parameters for a given value of <span class="math inline">\(Q\)</span> is now shaped like a ball.</p>
<center>
<img src="images/green_constrained_gd_sol.png" alt="green_constrained_gd_sol" width="400">
</center>
<p>If we modify our objective function like before, we find that our new goal is to minimize the function: <span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 \phi_{i, 1} + \theta_2 \phi_{i, 2} + \ldots + \theta_p \phi_{i, p}))^2\:\text{such that} \sum_{i=1}^p \theta_i^2 \leq Q\]</span></p>
<p>Notice that all we have done is change the constraint on the model parameters. The first term in the expression, the MSE, has not changed.</p>
<p>Using Lagrangian Duality (again, out of scope for Data 100), we can re-express our objective function as: <span class="math display">\[\frac{1}{n} \sum_{i=1}^n (y_i - (\theta_0 + \theta_1 \phi_{i, 1} + \theta_2 \phi_{i, 2} + \ldots + \theta_p \phi_{i, p}))^2 + \lambda \sum_{i=1}^p \theta_i^2\]</span> <span class="math display">\[= \frac{1}{n}||\mathbb{Y} - \mathbb{X}\theta||_2^2 + \lambda \sum_{i=1}^p \theta_i^2\]</span> <span class="math display">\[= \frac{1}{n}||\mathbb{Y} - \mathbb{X}\theta||_2^2 + \lambda || \theta ||_2^2\]</span></p>
<p>The last two expressions include the MSE expressed using vector notation, and the last expression writes <span class="math inline">\(\sum_{i=1}^p \theta_i^2\)</span> as it’s <strong>L2 norm</strong> equivalent form, <span class="math inline">\(|| \theta ||_2^2\)</span>.</p>
<p>When applying L2 regularization, our goal is to minimize this updated objective function.</p>
<p>Unlike L1 regularization, L2 regularization <em>does</em> have a closed-form solution for the best parameter vector when regularization is applied:</p>
<p><span class="math display">\[\hat\theta_{\text{ridge}} = (\mathbb{X}^{\top}\mathbb{X} + n\lambda I)^{-1}\mathbb{X}^{\top}\mathbb{Y}\]</span></p>
<p>This solution exists <strong>even if <span class="math inline">\(\mathbb{X}\)</span> is not full column rank</strong>. This is a major reason why L2 regularization is often used – it can produce a solution even when there is collinearity in the features. We will discuss the concept of collinearity in a future lecture, but we will not derive this result in Data 100, as it involves a fair bit of matrix calculus.</p>
<p>In <code>sklearn</code>, we perform L2 regularization using the <code>Ridge</code> class. It runs gradient descent to minimize the L2 objective function. Notice that we scale the data before regularizing.</p>
<div id="0852122e" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="op">=</span> lm.Ridge(alpha<span class="op">=</span><span class="dv">1</span>) <span class="co"># alpha represents the hyperparameter lambda</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>ridge_model.fit(X_train, Y_train)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>ridge_model.coef_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([ 5.89130560e-02, -6.42445916e-03,  4.44468157e-05, -8.83981945e-08])</code></pre>
</div>
</div>
</section>
</section>
<section id="regression-summary" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="regression-summary"><span class="header-section-number">16.3</span> Regression Summary</h2>
<p>Our regression models are summarized below. Note the objective function is what the gradient descent optimizer minimizes.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 14%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 32%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Model</th>
<th>Loss</th>
<th>Regularization</th>
<th>Objective Function</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OLS</td>
<td><span class="math inline">\(\hat{\mathbb{Y}} = \mathbb{X}\theta\)</span></td>
<td>MSE</td>
<td>None</td>
<td><span class="math inline">\(\frac{1}{n} \|\mathbb{Y}-\mathbb{X} \theta\|^2_2\)</span></td>
<td><span class="math inline">\(\hat{\theta}_{OLS} = (\mathbb{X}^{\top}\mathbb{X})^{-1}\mathbb{X}^{\top}\mathbb{Y}\)</span> if <span class="math inline">\(\mathbb{X}\)</span> is full-column rank</td>
</tr>
<tr class="even">
<td>Ridge</td>
<td><span class="math inline">\(\hat{\mathbb{Y}} = \mathbb{X} \theta\)</span></td>
<td>MSE</td>
<td>L2</td>
<td><span class="math inline">\(\frac{1}{n} \|\mathbb{Y}-\mathbb{X}\theta\|^2_2 + \lambda \sum_{i=1}^p \theta_i^2\)</span></td>
<td><span class="math inline">\(\hat{\theta}_{ridge} = (\mathbb{X}^{\top}\mathbb{X} + n \lambda I)^{-1}\mathbb{X}^{\top}\mathbb{Y}\)</span></td>
</tr>
<tr class="odd">
<td>LASSO</td>
<td><span class="math inline">\(\hat{\mathbb{Y}} = \mathbb{X} \theta\)</span></td>
<td>MSE</td>
<td>L1</td>
<td><span class="math inline">\(\frac{1}{n} \|\mathbb{Y}-\mathbb{X}\theta\|^2_2 + \lambda \sum_{i=1}^p \vert \theta_i \vert\)</span></td>
<td>No closed form solution</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../case_study_HCE/case_study_HCE.html" class="pagination-link" aria-label="Case Study in Human Contexts and Ethics (from Spring 2025)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics (from Spring 2025)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../probability_1/probability_1.html" class="pagination-link" aria-label="Random Variables (from Spring 2025)">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Random Variables (from Spring 2025)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>