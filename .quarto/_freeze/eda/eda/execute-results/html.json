{
  "hash": "d4f7e5c0905c0a9916cd4661da9d459e",
  "result": {
    "markdown": "---\ntitle: Data Cleaning and EDA\nexecute:\n  echo: true\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    toc: true\n    toc-title: Data Cleaning and EDA\n    page-layout: full\n    theme:\n      - cosmo\n      - cerulean\n    callout-icon: false\n---\n\n::: {.callout-note collapse=\"false\"}\n## Learning Outcomes\n* Recognize common file formats\n* Categorize data by its variable type\n* Build awareness of issues with data faithfulness and develop targeted solutions\n:::\n\nIn the past few lectures, we've learned that `pandas` is a toolkit to restructure, modify, and explore a dataset. What we haven't yet touched on is *how* to make these data transformation decisions. When we receive a new set of data from the \"real world,\" how do we know what processing we should do to convert this data into a usable form?\n\n**Data cleaning**, also called **data wrangling**, is the process of transforming raw data to facilitate subsequent analysis. It is often used to address issues like:\n\n* Unclear structure or formatting\n* Missing or corrupted values\n* Unit conversions\n* ...and so on\n\n**Exploratory Data Analysis (EDA)** is the process of understanding a new dataset. It is an open-ended, informal analysis that involves familiarizing ourselves with the variables present in the data, discovering potential hypotheses, and identifying possible issues with the data. This last point can often motivate further data cleaning to address any problems with the dataset's format; because of this, EDA and data cleaning are often thought of as an \"infinite loop,\" with each process driving the other.\n\nIn this lecture, we will consider the key properties of data to consider when performing data cleaning and EDA. In doing so, we'll develop a \"checklist\" of sorts for you to consider when approaching a new dataset. Throughout this process, we'll build a deeper understanding of this early (but very important!) stage of the data science lifecycle.\n\n## Structure\n\n### File Formats\nThere are many file types for storing structured data: TSV, JSON, XML, ASCII, SAS, etc. We'll only cover CSV, TSV, and JSON in lecture, but you'll likely encounter other formats as you work with different datasets. Reading documentation is your best bet for understanding how to process the multitude of different file types. \n\n#### CSV\nCSVs, which stand for **Comma-Separated Values**, are a common tabular data format. \nIn the past two `pandas` lectures, we briefly touched on the idea of file format: the way data is encoded in a file for storage. Specifically, our `elections` and `babynames` datasets were stored and loaded as CSVs:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"false\"}\nimport pandas as pd\npd.read_csv(\"data/elections.csv\").head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Candidate</th>\n      <th>Party</th>\n      <th>Popular vote</th>\n      <th>Result</th>\n      <th>%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1824</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic-Republican</td>\n      <td>151271</td>\n      <td>loss</td>\n      <td>57.210122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1824</td>\n      <td>John Quincy Adams</td>\n      <td>Democratic-Republican</td>\n      <td>113142</td>\n      <td>win</td>\n      <td>42.789878</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1828</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic</td>\n      <td>642806</td>\n      <td>win</td>\n      <td>56.203927</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1828</td>\n      <td>John Quincy Adams</td>\n      <td>National Republican</td>\n      <td>500897</td>\n      <td>loss</td>\n      <td>43.796073</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1832</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic</td>\n      <td>702735</td>\n      <td>win</td>\n      <td>54.574789</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo better understand the properties of a CSV, let's take a look at the first few rows of the raw data file to see what it looks like before being loaded into a `DataFrame`. We'll use the `repr()` function to return the raw string with its special characters: \n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"false\"}\nwith open(\"data/elections.csv\", \"r\") as table:\n    i = 0\n    for row in table:\n        print(repr(row))\n        i += 1\n        if i > 3:\n            break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'Year,Candidate,Party,Popular vote,Result,%\\n'\n'1824,Andrew Jackson,Democratic-Republican,151271,loss,57.21012204\\n'\n'1824,John Quincy Adams,Democratic-Republican,113142,win,42.78987796\\n'\n'1828,Andrew Jackson,Democratic,642806,win,56.20392707\\n'\n```\n:::\n:::\n\n\nEach row, or **record**, in the data is delimited by a newline `\\n`. Each column, or **field**, in the data is delimited by a comma `,` (hence, comma-separated!). \n\n#### TSV\n\nAnother common file type is **TSV (Tab-Separated Values)**. In a TSV, records are still delimited by a newline `\\n`, while fields are delimited by `\\t` tab character. \n\nLet's check out the first few rows of the raw TSV file. Again, we'll use the `repr()` function so that `print` shows the special characters.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"false\"}\nwith open(\"data/elections.txt\", \"r\") as table:\n    i = 0\n    for row in table:\n        print(repr(row))\n        i += 1\n        if i > 3:\n            break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'\\ufeffYear\\tCandidate\\tParty\\tPopular vote\\tResult\\t%\\n'\n'1824\\tAndrew Jackson\\tDemocratic-Republican\\t151271\\tloss\\t57.21012204\\n'\n'1824\\tJohn Quincy Adams\\tDemocratic-Republican\\t113142\\twin\\t42.78987796\\n'\n'1828\\tAndrew Jackson\\tDemocratic\\t642806\\twin\\t56.20392707\\n'\n```\n:::\n:::\n\n\nTSVs can be loaded into `pandas` using `pd.read_csv`. We'll need to specify the **delimiter** with parameter` sep='\\t'` [(documentation)](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"false\"}\npd.read_csv(\"data/elections.txt\", sep='\\t').head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Candidate</th>\n      <th>Party</th>\n      <th>Popular vote</th>\n      <th>Result</th>\n      <th>%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1824</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic-Republican</td>\n      <td>151271</td>\n      <td>loss</td>\n      <td>57.210122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1824</td>\n      <td>John Quincy Adams</td>\n      <td>Democratic-Republican</td>\n      <td>113142</td>\n      <td>win</td>\n      <td>42.789878</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1828</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic</td>\n      <td>642806</td>\n      <td>win</td>\n      <td>56.203927</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAn issue with CSVs and TSVs comes up whenever there are commas or tabs within the records. How does `pandas` differentiate between a comma delimiter vs. a comma within the field itself, for example `8,900`? To remedy this, check out the [`quotechar` parameter](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). \n\n#### JSON\n**JSON (JavaScript Object Notation)** files behave similarly to Python dictionaries. A raw JSON is shown below.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-fold=\"false\"}\nwith open(\"data/elections.json\", \"r\") as table:\n    i = 0\n    for row in table:\n        print(row)\n        i += 1\n        if i > 8:\n            break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[\n\n {\n\n   \"Year\": 1824,\n\n   \"Candidate\": \"Andrew Jackson\",\n\n   \"Party\": \"Democratic-Republican\",\n\n   \"Popular vote\": 151271,\n\n   \"Result\": \"loss\",\n\n   \"%\": 57.21012204\n\n },\n\n```\n:::\n:::\n\n\nJSON files can be loaded into `pandas` using `pd.read_json`. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code code-fold=\"false\"}\npd.read_json('data/elections.json').head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Candidate</th>\n      <th>Party</th>\n      <th>Popular vote</th>\n      <th>Result</th>\n      <th>%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1824</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic-Republican</td>\n      <td>151271</td>\n      <td>loss</td>\n      <td>57.210122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1824</td>\n      <td>John Quincy Adams</td>\n      <td>Democratic-Republican</td>\n      <td>113142</td>\n      <td>win</td>\n      <td>42.789878</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1828</td>\n      <td>Andrew Jackson</td>\n      <td>Democratic</td>\n      <td>642806</td>\n      <td>win</td>\n      <td>56.203927</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n##### EDA with JSON: Berkeley COVID-19 Data\nThe City of Berkeley Open Data [website](https://data.cityofberkeley.info/Health/COVID-19-Confirmed-Cases/xn6j-b766) has a dataset with COVID-19 Confirmed Cases among Berkeley residents by date. Let's download the file and save it as a JSON (note the source URL file type is also a JSON). In the interest of reproducible data science, we will download the data programatically. We have defined some helper functions in the [`ds100_utils.py`](https://ds100.org/fa23/resources/assets/lectures/lec05/lec05-eda.html) file that we can reuse these helper functions in many different notebooks.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code code-fold=\"false\"}\nfrom ds100_utils import fetch_and_cache\n\ncovid_file = fetch_and_cache(\n    \"https://data.cityofberkeley.info/api/views/xn6j-b766/rows.json?accessType=DOWNLOAD\",\n    \"confirmed-cases.json\",\n    force=False)\ncovid_file          # a file path wrapper object\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing cached version that was downloaded (UTC): Fri Aug 25 09:57:25 2023\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nPosixPath('data/confirmed-cases.json')\n```\n:::\n:::\n\n\n###### File Size\nLet's start our analysis by getting a rough estimate of the size of the dataset to inform the tools we use to view the data. For relatively small datasets, we can use a text editor or spreadsheet. For larger datasets, more programmatic exploration or distributed computing tools may be more fitting. Here we will use `Python` tools to probe the file.\n\nSince there seem to be text files, let's investigate the number of lines, which often corresponds to the number of records\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-fold=\"false\"}\nimport os\n\nprint(covid_file, \"is\", os.path.getsize(covid_file) / 1e6, \"MB\")\n\nwith open(covid_file, \"r\") as f:\n    print(covid_file, \"is\", sum(1 for l in f), \"lines.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndata/confirmed-cases.json is 0.116367 MB\ndata/confirmed-cases.json is 1110 lines.\n```\n:::\n:::\n\n\n###### Unix Commands\nAs part of the EDA workflow, Unix commands can come in very handy. In fact, there's an entire book called [\"Data Science at the Command Line\"](https://datascienceatthecommandline.com/) that explores this idea in depth! \nIn Jupyter/IPython, you can prefix lines with `!` to execute arbitrary Unix commands, and within those lines, you can refer to `Python` variables and expressions with the syntax `{expr}`.\n\nHere, we use the ls command to list files, using the `-lh` flags, which request \"long format with information in human-readable form\". We also use the `wc` command for \"word count\", but with the `-l` flag, which asks for line counts instead of words.\n\nThese two give us the same information as the code above, albeit in a slightly different form:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-fold=\"false\"}\n!ls -lh {covid_file}\n!wc -l {covid_file}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-rw-r--r--  1 lillianweng  staff   114K Aug 25 09:57 data/confirmed-cases.json\r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n    1109 data/confirmed-cases.json\r\n```\n:::\n:::\n\n\n###### File Contents\nLet's explore the data format using `Python`> \n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-fold=\"false\"}\nwith open(covid_file, \"r\") as f:\n    for i, row in enumerate(f):\n        print(repr(row)) # print raw strings\n        if i >= 4: break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'{\\n'\n'  \"meta\" : {\\n'\n'    \"view\" : {\\n'\n'      \"id\" : \"xn6j-b766\",\\n'\n'      \"name\" : \"COVID-19 Confirmed Cases\",\\n'\n```\n:::\n:::\n\n\nWe can use the `head` Unix command (which is where `pandas`' `head` method comes from!) to see the first few lines of the file:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code code-fold=\"false\"}\n!head -5 {covid_file}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\r\n  \"meta\" : {\r\n    \"view\" : {\r\n      \"id\" : \"xn6j-b766\",\r\n      \"name\" : \"COVID-19 Confirmed Cases\",\r\n```\n:::\n:::\n\n\nIn order to load the JSON file into `pandas`, Let's first do some EDA with `Python`'s `json` package to understand the particular structure of this JSON file so that we can decide what (if anything) to load into `pandas`. `Python` has relatively good support for JSON data since it closely matches the internal python object model. In the following cell we import the entire JSON datafile into a python dictionary using the `json` package.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-fold=\"false\"}\nimport json\n\nwith open(covid_file, \"rb\") as f:\n    covid_json = json.load(f)\n```\n:::\n\n\nThe `covid_json` variable is now a dictionary encoding the data in the file:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code code-fold=\"false\"}\ntype(covid_json)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\ndict\n```\n:::\n:::\n\n\nWe can examine what keys are in the top level json object by listing out the keys. \n\n::: {.cell execution_count=14}\n``` {.python .cell-code code-fold=\"false\"}\ncovid_json.keys()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\ndict_keys(['meta', 'data'])\n```\n:::\n:::\n\n\n**Observation**: The JSON dictionary contains a `meta` key which likely refers to meta data (data about the data).  Meta data often maintained with the data and can be a good source of additional information.\n\n\nWe can investigate the meta data further by examining the keys associated with the metadata.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code code-fold=\"false\"}\ncovid_json['meta'].keys()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\ndict_keys(['view'])\n```\n:::\n:::\n\n\nThe `meta` key contains another dictionary called `view`.  This likely refers to meta-data about a particular \"view\" of some underlying database.  We will learn more about views when we study SQL later in the class.    \n\n::: {.cell execution_count=16}\n``` {.python .cell-code code-fold=\"false\"}\ncovid_json['meta']['view'].keys()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\ndict_keys(['id', 'name', 'assetType', 'attribution', 'averageRating', 'category', 'createdAt', 'description', 'displayType', 'downloadCount', 'hideFromCatalog', 'hideFromDataJson', 'newBackend', 'numberOfComments', 'oid', 'provenance', 'publicationAppendEnabled', 'publicationDate', 'publicationGroup', 'publicationStage', 'rowsUpdatedAt', 'rowsUpdatedBy', 'tableId', 'totalTimesRated', 'viewCount', 'viewLastModified', 'viewType', 'approvals', 'columns', 'grants', 'metadata', 'owner', 'query', 'rights', 'tableAuthor', 'tags', 'flags'])\n```\n:::\n:::\n\n\nNotice that this a nested/recursive data structure.  As we dig deeper we reveal more and more keys and the corresponding data:\n\n```\nmeta\n|-> data\n    | ... (haven't explored yet)\n|-> view\n    | -> id\n    | -> name\n    | -> attribution \n    ...\n    | -> description\n    ...\n    | -> columns\n    ...\n```\n\n\nThere is a key called description in the view sub dictionary.  This likely contains a description of the data:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code code-fold=\"false\"}\nprint(covid_json['meta']['view']['description'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCounts of confirmed COVID-19 cases among Berkeley residents by date.\n```\n:::\n:::\n\n\n###### Examining the Data Field for Records\n\nWe can look at a few entries in the `data` field. This is what we'll load into `pandas`.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code code-fold=\"false\"}\nfor i in range(3):\n    print(f\"{i:03} | {covid_json['data'][i]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n000 | ['row-kzbg.v7my-c3y2', '00000000-0000-0000-0405-CB14DE51DAA7', 0, 1643733903, None, 1643733903, None, '{ }', '2020-02-28T00:00:00', '1', '1']\n001 | ['row-jkyx_9u4r-h2yw', '00000000-0000-0000-F806-86D0DBE0E17F', 0, 1643733903, None, 1643733903, None, '{ }', '2020-02-29T00:00:00', '0', '1']\n002 | ['row-qifg_4aug-y3ym', '00000000-0000-0000-2DCE-4D1872F9B216', 0, 1643733903, None, 1643733903, None, '{ }', '2020-03-01T00:00:00', '0', '1']\n```\n:::\n:::\n\n\nObservations:\n* These look like equal-length records, so maybe `data` is a table!\n* But what do each of values in the record mean? Where can we find column headers?\n\nFor that, we'l need the `columns` key in the metadata dictionary. This returns a list: \n\n::: {.cell execution_count=19}\n``` {.python .cell-code code-fold=\"false\"}\ntype(covid_json['meta']['view']['columns'])\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\nlist\n```\n:::\n:::\n\n\n###### Summary of exploring the JSON file\n\n1. The above **metadata** tells us a lot about the columns in the data including column names, potential data anomalies, and a basic statistic. \n1. Because of its non-tabular structure, JSON makes it easier (than CSV) to create **self-documenting data**, meaning that information about the data is stored in the same file as the data.\n1. Self documenting data can be helpful since it maintains its own description and these descriptions are more likely to be updated as data changes. \n\n###### Loading COVID Data into `pandas`\nFinally, le'ts load the data (not the metadata) into a `pandas` `DatFrame`. In the following block of code we:\n\n1. Translate the JSON records into a dataframe:\n\n    * fields: `covid_json['meta']['view']['columns']`\n    * records: `covid_json['data']`\n    \n1. Remove columns that have no metadata description.  This would be a bad idea in general but here we remove these columns since the above analysis suggests that they are unlikely to contain useful information.\n1. Examine the `tail` of the table.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code code-fold=\"false\"}\n# Load the data from JSON and assign column titles\ncovid = pd.DataFrame(\n    covid_json['data'],\n    columns=[c['name'] for c in covid_json['meta']['view']['columns']])\n\ncovid.tail()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sid</th>\n      <th>id</th>\n      <th>position</th>\n      <th>created_at</th>\n      <th>created_meta</th>\n      <th>updated_at</th>\n      <th>updated_meta</th>\n      <th>meta</th>\n      <th>Date</th>\n      <th>New Cases</th>\n      <th>Cumulative Cases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>699</th>\n      <td>row-49b6_x8zv.gyum</td>\n      <td>00000000-0000-0000-A18C-9174A6D05774</td>\n      <td>0</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>{ }</td>\n      <td>2022-01-27T00:00:00</td>\n      <td>106</td>\n      <td>10694</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <td>row-gs55-p5em.y4v9</td>\n      <td>00000000-0000-0000-F41D-5724AEABB4D6</td>\n      <td>0</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>{ }</td>\n      <td>2022-01-28T00:00:00</td>\n      <td>223</td>\n      <td>10917</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>row-3pyj.tf95-qu67</td>\n      <td>00000000-0000-0000-BEE3-B0188D2518BD</td>\n      <td>0</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>{ }</td>\n      <td>2022-01-29T00:00:00</td>\n      <td>139</td>\n      <td>11056</td>\n    </tr>\n    <tr>\n      <th>702</th>\n      <td>row-cgnd.8syv.jvjn</td>\n      <td>00000000-0000-0000-C318-63CF75F7F740</td>\n      <td>0</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>{ }</td>\n      <td>2022-01-30T00:00:00</td>\n      <td>33</td>\n      <td>11089</td>\n    </tr>\n    <tr>\n      <th>703</th>\n      <td>row-qywv_24x6-237y</td>\n      <td>00000000-0000-0000-FE92-9789FED3AA20</td>\n      <td>0</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>1643733903</td>\n      <td>None</td>\n      <td>{ }</td>\n      <td>2022-01-31T00:00:00</td>\n      <td>42</td>\n      <td>11131</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Variable Types\n\nAfter loading data into a file, it's a good idea to take the time to understand what pieces of information are encoded in the dataset. In particular, we want to identify what variable types are present in our data. Broadly speaking, we can categorize variables into one of two overarching types. \n\n**Quantitative variables** describe some numeric quantity or amount. We can divide quantitative data further into:\n\n* **Continuous quantitative variables**: numeric data that can be measured on a continuous scale to arbitrary precision. Continuous variables do not have a strict set of possible values – they can be recorded to any number of decimal places. For example, weights, GPA, or CO<sub>2</sub> concentrations.\n* **Discrete quantitative variables**: numeric data that can only take on a finite set of possible values. For example, someone's age or the number of siblings they have.\n\n**Qualitative variables**, also known as **categorical variables**, describe data that isn't measuring some quantity or amount. The sub-categories of categorical data are:\n\n* **Ordinal qualitative variables**: categories with ordered levels. Specifically, ordinal variables are those where the difference between levels has no consistent, quantifiable meaning. Some examples include levels of education (high school, undergrad, grad, etc.), income bracket (low, medium, high), or Yelp rating. \n* **Nominal qualitative variables**: categories with no specific order. For example, someone's political affiliation or Cal ID number.\n\n![Classification of variable types](images/variable.png)\n\nNote that many variables don't sit neatly in just one of these categories. Qualitative variables could have numeric levels, and conversely, quantitative variables could be stored as strings. \n\n### Primary and Foreign Keys\n\nLast time, we introduced `.merge` as the `pandas` method for joining multiple `DataFrames` together. In our discussion of joins, we touched on the idea of using a \"key\" to determine what rows should be merged from each table. Let's take a moment to examine this idea more closely.\n\nThe **primary key** is the column or set of columns in a table that *uniquely* determine the values of the remaining columns. It can be thought of as the unique identifier for each individual row in the table. For example, a table of Data 100 students might use each student's Cal ID as the primary key. \n\n::: {.cell execution_count=21}\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cal ID</th>\n      <th>Name</th>\n      <th>Major</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3034619471</td>\n      <td>Oski</td>\n      <td>Data Science</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3035619472</td>\n      <td>Ollie</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3025619473</td>\n      <td>Orrie</td>\n      <td>Data Science</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3046789372</td>\n      <td>Ollie</td>\n      <td>Economics</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe **foreign key** is the column or set of columns in a table that reference primary keys in other tables. Knowing a dataset's foreign keys can be useful when assigning the `left_on` and `right_on` parameters of `.merge`. In the table of office hour tickets below, `\"Cal ID\"` is a foreign key referencing the previous table.\n\n::: {.cell execution_count=22}\n\n::: {.cell-output .cell-output-display execution_count=22}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OH Request</th>\n      <th>Cal ID</th>\n      <th>Question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3034619471</td>\n      <td>HW 2 Q1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3035619472</td>\n      <td>HW 2 Q3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3025619473</td>\n      <td>Lab 3 Q4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3035619472</td>\n      <td>HW 2 Q7</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Granularity, Scope, and Temporality\n\nAfter understanding the structure of the dataset, the next task is to determine what exactly the data represents. We'll do so by considering the data's granularity, scope, and temporality.\n\n### Granularity\nThe **granularity** of a dataset is what a single row represents. You can also think of it as the level of detail included in the data. To determine the data's granularity, ask: what does each row in the dataset represent? Fine-grained data contains a high level of detail, with a single row representing a small individual unit. For example, each record may represent one person. Coarse-grained data is encoded such that a single row represents a large individual unit – for example, each record may represent a group of people.\n\n### Scope\nThe **scope** of a dataset is the subset of the population covered by the data. If we were investigating student performance in Data Science courses, a dataset with a narrow scope might encompass all students enrolled in Data 100; a dataset with an expansive scope might encompass all students in California. \n\n### Temporality\nThe **temporality** of a dataset describes the periodicity over which the data was collected as well as when the data was most recently collected or updated. \n\nTime and date fields of a dataset could represent a few things:\n\n1. when the \"event\" happened\n2. when the data was collected, or when it was entered into the system\n3. when the data was copied into the database \n\nTo fully understand the temporality of the data, it also may be necessary to standardize time zones or inspect recurring time-based trends in the data (do patterns recur in 24-hour periods? Over the course of a month? Seasonally?). The convention for standardizing time is the Coordinated Universal Time (UTC), an international time standard measured at 0 degrees latitude that stays consistent throughout the year (no daylight savings). We can represent Berkeley's time zone, Pacific Standard Time (PST), as UTC-7 (with daylight savings). \n\n#### Temporality with `pandas`' `dt` accessors \nLet's briefly look at how we can use `pandas`' `dt` accessors to work with dates/times in a dataset using the dataset you'll see in Lab 3: the Berkeley PD Calls for Service dataset.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code code-fold=\"true\"}\ncalls = pd.read_csv(\"data/Berkeley_PD_-_Calls_for_Service.csv\")\ncalls.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CASENO</th>\n      <th>OFFENSE</th>\n      <th>EVENTDT</th>\n      <th>EVENTTM</th>\n      <th>CVLEGEND</th>\n      <th>CVDOW</th>\n      <th>InDbDate</th>\n      <th>Block_Location</th>\n      <th>BLKADDR</th>\n      <th>City</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21014296</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>04/01/2021 12:00:00 AM</td>\n      <td>10:58</td>\n      <td>LARCENY</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>Berkeley, CA\\n(37.869058, -122.270455)</td>\n      <td>NaN</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21014391</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>04/01/2021 12:00:00 AM</td>\n      <td>10:38</td>\n      <td>LARCENY</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>Berkeley, CA\\n(37.869058, -122.270455)</td>\n      <td>NaN</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21090494</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>04/19/2021 12:00:00 AM</td>\n      <td>12:15</td>\n      <td>LARCENY</td>\n      <td>1</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2100 BLOCK HASTE ST\\nBerkeley, CA\\n(37.864908,...</td>\n      <td>2100 BLOCK HASTE ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21090204</td>\n      <td>THEFT FELONY (OVER $950)</td>\n      <td>02/13/2021 12:00:00 AM</td>\n      <td>17:00</td>\n      <td>LARCENY</td>\n      <td>6</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2600 BLOCK WARRING ST\\nBerkeley, CA\\n(37.86393...</td>\n      <td>2600 BLOCK WARRING ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21090179</td>\n      <td>BURGLARY AUTO</td>\n      <td>02/08/2021 12:00:00 AM</td>\n      <td>6:20</td>\n      <td>BURGLARY - VEHICLE</td>\n      <td>1</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2700 BLOCK GARBER ST\\nBerkeley, CA\\n(37.86066,...</td>\n      <td>2700 BLOCK GARBER ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLooks like there are three columns with dates/times: `EVENTDT`, `EVENTTM`, and `InDbDate`. \n\nMost likely, `EVENTDT` stands for the date when the event took place, `EVENTTM` stands for the time of day the event took place (in 24-hr format), and `InDbDate` is the date this call is recorded onto the database.\n\nIf we check the data type of these columns, we will see they are stored as strings. We can convert them to `datetime` objects using pandas `to_datetime` function.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code code-fold=\"false\"}\ncalls[\"EVENTDT\"] = pd.to_datetime(calls[\"EVENTDT\"])\ncalls.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CASENO</th>\n      <th>OFFENSE</th>\n      <th>EVENTDT</th>\n      <th>EVENTTM</th>\n      <th>CVLEGEND</th>\n      <th>CVDOW</th>\n      <th>InDbDate</th>\n      <th>Block_Location</th>\n      <th>BLKADDR</th>\n      <th>City</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21014296</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>2021-04-01</td>\n      <td>10:58</td>\n      <td>LARCENY</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>Berkeley, CA\\n(37.869058, -122.270455)</td>\n      <td>NaN</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21014391</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>2021-04-01</td>\n      <td>10:38</td>\n      <td>LARCENY</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>Berkeley, CA\\n(37.869058, -122.270455)</td>\n      <td>NaN</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21090494</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>2021-04-19</td>\n      <td>12:15</td>\n      <td>LARCENY</td>\n      <td>1</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2100 BLOCK HASTE ST\\nBerkeley, CA\\n(37.864908,...</td>\n      <td>2100 BLOCK HASTE ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21090204</td>\n      <td>THEFT FELONY (OVER $950)</td>\n      <td>2021-02-13</td>\n      <td>17:00</td>\n      <td>LARCENY</td>\n      <td>6</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2600 BLOCK WARRING ST\\nBerkeley, CA\\n(37.86393...</td>\n      <td>2600 BLOCK WARRING ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21090179</td>\n      <td>BURGLARY AUTO</td>\n      <td>2021-02-08</td>\n      <td>6:20</td>\n      <td>BURGLARY - VEHICLE</td>\n      <td>1</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2700 BLOCK GARBER ST\\nBerkeley, CA\\n(37.86066,...</td>\n      <td>2700 BLOCK GARBER ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow, we can use the `dt` accessor on this column.\n\nWe can get the month: \n\n::: {.cell execution_count=25}\n``` {.python .cell-code code-fold=\"false\"}\ncalls[\"EVENTDT\"].dt.month.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\n0    4\n1    4\n2    4\n3    2\n4    2\nName: EVENTDT, dtype: int64\n```\n:::\n:::\n\n\nWhich day of the week the date is on:\n\n::: {.cell execution_count=26}\n``` {.python .cell-code code-fold=\"false\"}\ncalls[\"EVENTDT\"].dt.dayofweek.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n0    3\n1    3\n2    0\n3    5\n4    0\nName: EVENTDT, dtype: int64\n```\n:::\n:::\n\n\nCheck the mimimum values to see if there are any suspicious-looking, 70s dates:\n\n::: {.cell execution_count=27}\n``` {.python .cell-code code-fold=\"false\"}\ncalls.sort_values(\"EVENTDT\").head()\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CASENO</th>\n      <th>OFFENSE</th>\n      <th>EVENTDT</th>\n      <th>EVENTTM</th>\n      <th>CVLEGEND</th>\n      <th>CVDOW</th>\n      <th>InDbDate</th>\n      <th>Block_Location</th>\n      <th>BLKADDR</th>\n      <th>City</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2513</th>\n      <td>20057398</td>\n      <td>BURGLARY COMMERCIAL</td>\n      <td>2020-12-17</td>\n      <td>16:05</td>\n      <td>BURGLARY - COMMERCIAL</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>600 BLOCK GILMAN ST\\nBerkeley, CA\\n(37.878405,...</td>\n      <td>600 BLOCK GILMAN ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>20057207</td>\n      <td>ASSAULT/BATTERY MISD.</td>\n      <td>2020-12-17</td>\n      <td>16:50</td>\n      <td>ASSAULT</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>2100 BLOCK SHATTUCK AVE\\nBerkeley, CA\\n(37.871...</td>\n      <td>2100 BLOCK SHATTUCK AVE</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>20092214</td>\n      <td>THEFT FROM AUTO</td>\n      <td>2020-12-17</td>\n      <td>18:30</td>\n      <td>LARCENY - FROM VEHICLE</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>800 BLOCK SHATTUCK AVE\\nBerkeley, CA\\n(37.8918...</td>\n      <td>800 BLOCK SHATTUCK AVE</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>20057324</td>\n      <td>THEFT MISD. (UNDER $950)</td>\n      <td>2020-12-17</td>\n      <td>15:44</td>\n      <td>LARCENY</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>1800 BLOCK 4TH ST\\nBerkeley, CA\\n(37.869888, -...</td>\n      <td>1800 BLOCK 4TH ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>993</th>\n      <td>20057573</td>\n      <td>BURGLARY RESIDENTIAL</td>\n      <td>2020-12-17</td>\n      <td>22:15</td>\n      <td>BURGLARY - RESIDENTIAL</td>\n      <td>4</td>\n      <td>06/15/2021 12:00:00 AM</td>\n      <td>1700 BLOCK STUART ST\\nBerkeley, CA\\n(37.857495...</td>\n      <td>1700 BLOCK STUART ST</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nDoesn't look like it! We are good!\n\n\nWe can also do many things with the `dt` accessor like switching time zones and converting time back to UNIX/POSIX time. Check out the documentation on [`.dt` accessor](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors) and [time series/date functionality](https://pandas.pydata.org/docs/user_guide/timeseries.html#).\n\n## Faithfulness\n\nAt this stage in our data cleaning and EDA workflow, we've achieved quite a lot: we've identified how our data is structured, come to terms with what information it encodes, and gained insight as to how it was generated. Throughout this process, we should always recall the original intent of our work in Data Science – to use data to better understand and model the real world. To achieve this goal, we need to ensure that the data we use is faithful to reality; that is, that our data accurately captures the \"real world.\"\n\nData used in research or industry is often \"messy\" – there may be errors or inaccuracies that impact the faithfulness of the dataset. Signs that data may not be faithful include:\n\n* Unrealistic or \"incorrect\" values, such as negative counts, locations that don't exist, or dates set in the future\n* Violations of obvious dependencies, like an age that does not match a birthday\n* Clear signs that data was entered by hand, which can lead to spelling errors or fields that are incorrectly shifted\n* Signs of data falsification, such as fake email addresses or repeated use of the same names\n* Duplicated records or fields containing the same information\n* Truncated data, e.g. Microsoft Excel would limit the number of rows to 655536 and the number of columns to 255\n\nWe often solve some of these more common issues in the following ways: \n\n* Spelling errors: apply corrections or drop records that aren't in a dictionary\n* Time zone inconsistencies: convert to a common time zone (e.g. UTC) \n* Duplicated records or fields: identify and eliminate duplicates (using primary keys)\n* Unspecified or inconsistent units: infer the units and check that values are in reasonable ranges in the data\n\n### Missing Values\nAnother common issue encountered with real-world datasets is that of missing data. One strategy to resolve this is to simply drop any records with missing values from the dataset. This does, however, introduce the risk of inducing biases – it is possible that the missing or corrupt records may be systemically related to some feature of interest in the data. Another solution is to keep the data as `NaN` values. \n\nA third method to address missing data is to perform **imputation**: infer the missing values using other data available in the dataset. There is a wide variety of imputation techniques that can be implemented; some of the most common are listed below.\n\n* Average imputation: replace missing values with the average value for that field\n* Hot deck imputation: replace missing values with some random value\n* Regression imputation: develop a model to predict missing values\n* Multiple imputation: replace missing values with multiple random values\n\nRegardless of the strategy used to deal with missing data, we should think carefully about *why* particular records or fields may be missing – this can help inform whether or not the absence of these values is significant or meaningful.\n\n# EDA Demo: Tuberculosis in the United States\n\nNow, let's walk through the data-cleaning and EDA workflow to see what can we learn about the presence of Tuberculosis in the United States!\n\nWe will examine the data included in the [original CDC article](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down) published in 2021.\n\n\n## CSVs and Field Names\nSuppose Table 1 was saved as a CSV file located in `data/cdc_tuberculosis.csv`.\n\nWe can then explore the CSV (which is a text file, and does not contain binary-encoded data) in many ways:\n1. Using a text editor like emacs, vim, VSCode, etc.\n2. Opening the CSV directly in DataHub (read-only), Excel, Google Sheets, etc.\n3. The `Python` file object\n4. `pandas`, using `pd.read_csv()`\n\nTo try out options 1 and 2, you can view or download the Tuberculosis from the [lecture demo notebook](https://data100.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Ffa23-student&urlpath=lab%2Ftree%2Ffa23-student%2Flecture%2Flec05%2Flec04-eda.ipynb&branch=main) under the `data` folder in the left hand menu. Notice how the CSV file is a type of **rectangular data (i.e., tabular data) stored as comma-separated values**.\n\nNext, let's try out option 3 using the `Python` file object. We'll look at the first four lines:\n\n::: {.cell execution_count=28}\n``` {.python .cell-code code-fold=\"true\"}\nwith open(\"data/cdc_tuberculosis.csv\", \"r\") as f:\n    i = 0\n    for row in f:\n        print(row)\n        i += 1\n        if i > 3:\n            break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n,No. of TB cases,,,TB incidence,,\n\nU.S. jurisdiction,2019,2020,2021,2019,2020,2021\n\nTotal,\"8,900\",\"7,173\",\"7,860\",2.71,2.16,2.37\n\nAlabama,87,72,92,1.77,1.43,1.83\n\n```\n:::\n:::\n\n\nWhoa, why are there blank lines interspaced between the lines of the CSV?\n\nYou may recall that all line breaks in text files are encoded as the special newline character `\\n`. Python's `print()` prints each string (including the newline), and an additional newline on top of that.\n\nIf you're curious, we can use the `repr()` function to return the raw string with all special characters:\n\n::: {.cell execution_count=29}\n``` {.python .cell-code code-fold=\"true\"}\nwith open(\"data/cdc_tuberculosis.csv\", \"r\") as f:\n    i = 0\n    for row in f:\n        print(repr(row)) # print raw strings\n        i += 1\n        if i > 3:\n            break\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n',No. of TB cases,,,TB incidence,,\\n'\n'U.S. jurisdiction,2019,2020,2021,2019,2020,2021\\n'\n'Total,\"8,900\",\"7,173\",\"7,860\",2.71,2.16,2.37\\n'\n'Alabama,87,72,92,1.77,1.43,1.83\\n'\n```\n:::\n:::\n\n\nFinally, let's try option 4 and use the tried-and-true Data 100 approach: `pandas`.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code code-fold=\"false\"}\ntb_df = pd.read_csv(\"data/cdc_tuberculosis.csv\")\ntb_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>No. of TB cases</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>TB incidence</th>\n      <th>Unnamed: 5</th>\n      <th>Unnamed: 6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U.S. jurisdiction</td>\n      <td>2019</td>\n      <td>2020</td>\n      <td>2021</td>\n      <td>2019.00</td>\n      <td>2020.00</td>\n      <td>2021.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Total</td>\n      <td>8,900</td>\n      <td>7,173</td>\n      <td>7,860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou may notice some strange things about this table: what's up with the \"Unnamed\" column names and the first row? \n\nCongratulations — you're ready to wrangle your data. Because of how things are stored, we'll need to clean the data a bit to name our columns better.\n\nA reasonable first step is to identify the row with the right header. The `pd.read_csv()` function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)) has the convenient `header` parameter that we can set to use the elements in row 1 as the appropriate columns:\n\n::: {.cell execution_count=31}\n``` {.python .cell-code code-fold=\"false\"}\ntb_df = pd.read_csv(\"data/cdc_tuberculosis.csv\", header=1) # row index\ntb_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2019.1</th>\n      <th>2020.1</th>\n      <th>2021.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Total</td>\n      <td>8,900</td>\n      <td>7,173</td>\n      <td>7,860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWait...but now we can't differentiate betwen the \"Number of TB cases\" and \"TB incidence\" year columns. `pandas` has tried to make our lives easier by automatically adding \".1\" to the latter columns, but this doesn't help us, as humans, understand the data.\n\nWe can do this manually with `df.rename()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename)):\n\n::: {.cell execution_count=32}\n``` {.python .cell-code code-fold=\"false\"}\nrename_dict = {'2019': 'TB cases 2019',\n               '2020': 'TB cases 2020',\n               '2021': 'TB cases 2021',\n               '2019.1': 'TB incidence 2019',\n               '2020.1': 'TB incidence 2020',\n               '2021.1': 'TB incidence 2021'}\ntb_df = tb_df.rename(columns=rename_dict)\ntb_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Total</td>\n      <td>8,900</td>\n      <td>7,173</td>\n      <td>7,860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Record Granularity\n\nYou might already be wondering: What's up with that first record?\n\nRow 0 is what we call a **rollup record**, or summary record. It's often useful when displaying tables to humans. The **granularity** of record 0 (Totals) vs the rest of the records (States) is different.\n\nOkay, EDA step two. How was the rollup record aggregated?\n\nLet's check if Total TB cases is the sum of all state TB cases. If we sum over all rows, we should get **2x** the total cases in each of our TB cases by year (why do you think this is?).\n\n::: {.cell execution_count=33}\n``` {.python .cell-code code-fold=\"true\"}\ntb_df.sum(axis=0)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\nU.S. jurisdiction    TotalAlabamaAlaskaArizonaArkansasCaliforniaCol...\nTB cases 2019        8,9008758183642,111666718245583029973261085237...\nTB cases 2020        7,1737258136591,706525417194122219282169239376...\nTB cases 2021        7,8609258129691,750585443194992281064255127494...\nTB incidence 2019                                               109.94\nTB incidence 2020                                                93.09\nTB incidence 2021                                               102.94\ndtype: object\n```\n:::\n:::\n\n\nWhoa, what's going on with the TB cases in 2019, 2020, and 2021? Check out the column types:\n\n::: {.cell execution_count=34}\n``` {.python .cell-code code-fold=\"true\"}\ntb_df.dtypes\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\nU.S. jurisdiction     object\nTB cases 2019         object\nTB cases 2020         object\nTB cases 2021         object\nTB incidence 2019    float64\nTB incidence 2020    float64\nTB incidence 2021    float64\ndtype: object\n```\n:::\n:::\n\n\nSince there are commas in the values for TB cases, the numbers are read as the `object` datatype, or **storage type** (close to the `Python` string datatype), so `pandas` is concatenating strings instead of adding integers (recall that `Python` can \"sum\", or concatenate, strings together: `\"data\" + \"100\"` evaluates to `\"data100\"`). \n\n\nFortunately `read_csv` also has a `thousands` parameter ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)):\n\n::: {.cell execution_count=35}\n``` {.python .cell-code code-fold=\"false\"}\n# improve readability: chaining method calls with outer parentheses/line breaks\ntb_df = (\n    pd.read_csv(\"data/cdc_tuberculosis.csv\", header=1, thousands=',')\n    .rename(columns=rename_dict)\n)\ntb_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Total</td>\n      <td>8900</td>\n      <td>7173</td>\n      <td>7860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code code-fold=\"false\"}\ntb_df.sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\nU.S. jurisdiction    TotalAlabamaAlaskaArizonaArkansasCaliforniaCol...\nTB cases 2019                                                    17800\nTB cases 2020                                                    14346\nTB cases 2021                                                    15720\nTB incidence 2019                                               109.94\nTB incidence 2020                                                93.09\nTB incidence 2021                                               102.94\ndtype: object\n```\n:::\n:::\n\n\nThe Total TB cases look right. Phew!\n\nLet's just look at the records with **state-level granularity**:\n\n::: {.cell execution_count=37}\n``` {.python .cell-code code-fold=\"true\"}\nstate_tb_df = tb_df[1:]\nstate_tb_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>California</td>\n      <td>2111</td>\n      <td>1706</td>\n      <td>1750</td>\n      <td>5.35</td>\n      <td>4.32</td>\n      <td>4.46</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Gather Census Data\n\nU.S. Census population estimates [source](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html) (2019), [source](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html) (2020-2021).\n\nRunning the below cells cleans the data.\nThere are a few new methods here:\n* `df.convert_dtypes()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html)) conveniently converts all float dtypes into ints and is out of scope for the class.\n* `df.drop_na()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)) will be explained in more detail next time.\n\n::: {.cell execution_count=38}\n``` {.python .cell-code code-fold=\"true\"}\n# 2010s census data\ncensus_2010s_df = pd.read_csv(\"data/nst-est2019-01.csv\", header=3, thousands=\",\")\ncensus_2010s_df = (\n    census_2010s_df\n    .reset_index()\n    .drop(columns=[\"index\", \"Census\", \"Estimates Base\"])\n    .rename(columns={\"Unnamed: 0\": \"Geographic Area\"})\n    .convert_dtypes()                 # \"smart\" converting of columns, use at your own risk\n    .dropna()                         # we'll introduce this next time\n)\ncensus_2010s_df['Geographic Area'] = census_2010s_df['Geographic Area'].str.strip('.')\n\n# with pd.option_context('display.min_rows', 30): # shows more rows\n#     display(census_2010s_df)\n    \ncensus_2010s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Geographic Area</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>309321666</td>\n      <td>311556874</td>\n      <td>313830990</td>\n      <td>315993715</td>\n      <td>318301008</td>\n      <td>320635163</td>\n      <td>322941311</td>\n      <td>324985539</td>\n      <td>326687501</td>\n      <td>328239523</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Northeast</td>\n      <td>55380134</td>\n      <td>55604223</td>\n      <td>55775216</td>\n      <td>55901806</td>\n      <td>56006011</td>\n      <td>56034684</td>\n      <td>56042330</td>\n      <td>56059240</td>\n      <td>56046620</td>\n      <td>55982803</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Midwest</td>\n      <td>66974416</td>\n      <td>67157800</td>\n      <td>67336743</td>\n      <td>67560379</td>\n      <td>67745167</td>\n      <td>67860583</td>\n      <td>67987540</td>\n      <td>68126781</td>\n      <td>68236628</td>\n      <td>68329004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>South</td>\n      <td>114866680</td>\n      <td>116006522</td>\n      <td>117241208</td>\n      <td>118364400</td>\n      <td>119624037</td>\n      <td>120997341</td>\n      <td>122351760</td>\n      <td>123542189</td>\n      <td>124569433</td>\n      <td>125580448</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>West</td>\n      <td>72100436</td>\n      <td>72788329</td>\n      <td>73477823</td>\n      <td>74167130</td>\n      <td>74925793</td>\n      <td>75742555</td>\n      <td>76559681</td>\n      <td>77257329</td>\n      <td>77834820</td>\n      <td>78347268</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOccasionally, you will want to modify code that you have imported.  To reimport those modifications you can either use `python`'s `importlib` library:\n\n```python\nfrom importlib import reload\nreload(utils)\n```\n\nor use `iPython` magic which will intelligently import code when files change:\n\n```python\n%load_ext autoreload\n%autoreload 2\n```\n\n::: {.cell execution_count=39}\n``` {.python .cell-code code-fold=\"true\"}\n# census 2020s data\ncensus_2020s_df = pd.read_csv(\"data/NST-EST2022-POP.csv\", header=3, thousands=\",\")\ncensus_2020s_df = (\n    census_2020s_df\n    .reset_index()\n    .drop(columns=[\"index\", \"Unnamed: 1\"])\n    .rename(columns={\"Unnamed: 0\": \"Geographic Area\"})\n    .convert_dtypes()                 # \"smart\" converting of columns, use at your own risk\n    .dropna()                         # we'll introduce this next time\n)\ncensus_2020s_df['Geographic Area'] = census_2020s_df['Geographic Area'].str.strip('.')\n\ncensus_2020s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Geographic Area</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>331511512</td>\n      <td>332031554</td>\n      <td>333287557</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Northeast</td>\n      <td>57448898</td>\n      <td>57259257</td>\n      <td>57040406</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Midwest</td>\n      <td>68961043</td>\n      <td>68836505</td>\n      <td>68787595</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>South</td>\n      <td>126450613</td>\n      <td>127346029</td>\n      <td>128716192</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>West</td>\n      <td>78650958</td>\n      <td>78589763</td>\n      <td>78743364</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Joining Data (Merging `DataFrames`)\n\nTime to `merge`! Here we use the `DataFrame` method `df1.merge(right=df2, ...)` on `DataFrame` `df1` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)). Contrast this with the function `pd.merge(left=df1, right=df2, ...)` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html?highlight=pandas%20merge#pandas.merge)). Feel free to use either.\n\n::: {.cell execution_count=40}\n``` {.python .cell-code code-fold=\"false\"}\n# merge TB DataFrame with two US census DataFrames\ntb_census_df = (\n    tb_df\n    .merge(right=census_2010s_df,\n           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n    .merge(right=census_2020s_df,\n           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n)\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>Geographic Area_x</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>...</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n      <th>Geographic Area_y</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>Alabama</td>\n      <td>4785437</td>\n      <td>4799069</td>\n      <td>...</td>\n      <td>4841799</td>\n      <td>4852347</td>\n      <td>4863525</td>\n      <td>4874486</td>\n      <td>4887681</td>\n      <td>4903185</td>\n      <td>Alabama</td>\n      <td>5031362</td>\n      <td>5049846</td>\n      <td>5074296</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>Alaska</td>\n      <td>713910</td>\n      <td>722128</td>\n      <td>...</td>\n      <td>736283</td>\n      <td>737498</td>\n      <td>741456</td>\n      <td>739700</td>\n      <td>735139</td>\n      <td>731545</td>\n      <td>Alaska</td>\n      <td>732923</td>\n      <td>734182</td>\n      <td>733583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>Arizona</td>\n      <td>6407172</td>\n      <td>6472643</td>\n      <td>...</td>\n      <td>6730413</td>\n      <td>6829676</td>\n      <td>6941072</td>\n      <td>7044008</td>\n      <td>7158024</td>\n      <td>7278717</td>\n      <td>Arizona</td>\n      <td>7179943</td>\n      <td>7264877</td>\n      <td>7359197</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>Arkansas</td>\n      <td>2921964</td>\n      <td>2940667</td>\n      <td>...</td>\n      <td>2967392</td>\n      <td>2978048</td>\n      <td>2989918</td>\n      <td>3001345</td>\n      <td>3009733</td>\n      <td>3017804</td>\n      <td>Arkansas</td>\n      <td>3014195</td>\n      <td>3028122</td>\n      <td>3045637</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>2111</td>\n      <td>1706</td>\n      <td>1750</td>\n      <td>5.35</td>\n      <td>4.32</td>\n      <td>4.46</td>\n      <td>California</td>\n      <td>37319502</td>\n      <td>37638369</td>\n      <td>...</td>\n      <td>38596972</td>\n      <td>38918045</td>\n      <td>39167117</td>\n      <td>39358497</td>\n      <td>39461588</td>\n      <td>39512223</td>\n      <td>California</td>\n      <td>39501653</td>\n      <td>39142991</td>\n      <td>39029342</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>\n```\n:::\n:::\n\n\nHaving all of these columns is a little unwieldy. We could either drop the unneeded columns now, or just merge on smaller census `DataFrame`s. Let's do the latter.\n\n::: {.cell execution_count=41}\n``` {.python .cell-code code-fold=\"false\"}\n# try merging again, but cleaner this time\ntb_census_df = (\n    tb_df\n    .merge(right=census_2010s_df[[\"Geographic Area\", \"2019\"]],\n           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n    .drop(columns=\"Geographic Area\")\n    .merge(right=census_2020s_df[[\"Geographic Area\", \"2020\", \"2021\"]],\n           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n    .drop(columns=\"Geographic Area\")\n)\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>4903185</td>\n      <td>5031362</td>\n      <td>5049846</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>731545</td>\n      <td>732923</td>\n      <td>734182</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>7278717</td>\n      <td>7179943</td>\n      <td>7264877</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>3017804</td>\n      <td>3014195</td>\n      <td>3028122</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>2111</td>\n      <td>1706</td>\n      <td>1750</td>\n      <td>5.35</td>\n      <td>4.32</td>\n      <td>4.46</td>\n      <td>39512223</td>\n      <td>39501653</td>\n      <td>39142991</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Reproducing Data: Compute Incidence\n\nLet's recompute incidence to make sure we know where the original CDC numbers came from.\n\nFrom the [CDC report](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down): TB incidence is computed as “Cases per 100,000 persons using mid-year population estimates from the U.S. Census Bureau.”\n\nIf we define a group as 100,000 people, then we can compute the TB incidence for a given state population as\n\n$$\\text{TB incidence} = \\frac{\\text{TB cases in population}}{\\text{groups in population}} = \\frac{\\text{TB cases in population}}{\\text{population}/100000} $$\n\n$$= \\frac{\\text{TB cases in population}}{\\text{population}} \\times 100000$$\n\nLet's try this for 2019:\n\n::: {.cell execution_count=42}\n``` {.python .cell-code code-fold=\"false\"}\ntb_census_df[\"recompute incidence 2019\"] = tb_census_df[\"TB cases 2019\"]/tb_census_df[\"2019\"]*100000\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>recompute incidence 2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>4903185</td>\n      <td>5031362</td>\n      <td>5049846</td>\n      <td>1.774357</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>731545</td>\n      <td>732923</td>\n      <td>734182</td>\n      <td>7.928425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>7278717</td>\n      <td>7179943</td>\n      <td>7264877</td>\n      <td>2.514179</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>3017804</td>\n      <td>3014195</td>\n      <td>3028122</td>\n      <td>2.120747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>2111</td>\n      <td>1706</td>\n      <td>1750</td>\n      <td>5.35</td>\n      <td>4.32</td>\n      <td>4.46</td>\n      <td>39512223</td>\n      <td>39501653</td>\n      <td>39142991</td>\n      <td>5.342651</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAwesome!!!\n\nLet's use a for-loop and `Python` format strings to compute TB incidence for all years. `Python` f-strings are just used for the purposes of this demo, but they're handy to know when you explore data beyond this course ([documentation](https://docs.python.org/3/tutorial/inputoutput.html)).\n\n::: {.cell execution_count=43}\n``` {.python .cell-code code-fold=\"false\"}\n# recompute incidence for all years\nfor year in [2019, 2020, 2021]:\n    tb_census_df[f\"recompute incidence {year}\"] = tb_census_df[f\"TB cases {year}\"]/tb_census_df[f\"{year}\"]*100000\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U.S. jurisdiction</th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>recompute incidence 2019</th>\n      <th>recompute incidence 2020</th>\n      <th>recompute incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>4903185</td>\n      <td>5031362</td>\n      <td>5049846</td>\n      <td>1.774357</td>\n      <td>1.431024</td>\n      <td>1.821838</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>731545</td>\n      <td>732923</td>\n      <td>734182</td>\n      <td>7.928425</td>\n      <td>7.913519</td>\n      <td>7.899949</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>7278717</td>\n      <td>7179943</td>\n      <td>7264877</td>\n      <td>2.514179</td>\n      <td>1.894165</td>\n      <td>1.775667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>3017804</td>\n      <td>3014195</td>\n      <td>3028122</td>\n      <td>2.120747</td>\n      <td>1.957405</td>\n      <td>2.27864</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>2111</td>\n      <td>1706</td>\n      <td>1750</td>\n      <td>5.35</td>\n      <td>4.32</td>\n      <td>4.46</td>\n      <td>39512223</td>\n      <td>39501653</td>\n      <td>39142991</td>\n      <td>5.342651</td>\n      <td>4.318807</td>\n      <td>4.470788</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThese numbers look pretty close!!! There are a few errors in the hundredths place, particularly in 2021. It may be useful to further explore reasons behind this discrepancy. \n\n::: {.cell execution_count=44}\n``` {.python .cell-code code-fold=\"false\"}\ntb_census_df.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>recompute incidence 2019</th>\n      <th>recompute incidence 2020</th>\n      <th>recompute incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>51.000000</td>\n      <td>51.000000</td>\n      <td>51.000000</td>\n      <td>51.000000</td>\n      <td>51.000000</td>\n      <td>51.000000</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>174.509804</td>\n      <td>140.647059</td>\n      <td>154.117647</td>\n      <td>2.102549</td>\n      <td>1.782941</td>\n      <td>1.971961</td>\n      <td>6436069.078431</td>\n      <td>6500225.72549</td>\n      <td>6510422.627451</td>\n      <td>2.104969</td>\n      <td>1.784655</td>\n      <td>1.969928</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>341.738752</td>\n      <td>271.055775</td>\n      <td>286.781007</td>\n      <td>1.498745</td>\n      <td>1.337414</td>\n      <td>1.478468</td>\n      <td>7360660.467814</td>\n      <td>7408168.462614</td>\n      <td>7394300.076705</td>\n      <td>1.500236</td>\n      <td>1.338263</td>\n      <td>1.474929</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.210000</td>\n      <td>578759.0</td>\n      <td>577605.0</td>\n      <td>579483.0</td>\n      <td>0.172783</td>\n      <td>0.0</td>\n      <td>0.210049</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>25.500000</td>\n      <td>29.000000</td>\n      <td>23.000000</td>\n      <td>1.295000</td>\n      <td>1.210000</td>\n      <td>1.235000</td>\n      <td>1789606.0</td>\n      <td>1820311.0</td>\n      <td>1844920.0</td>\n      <td>1.297485</td>\n      <td>1.211433</td>\n      <td>1.233905</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>70.000000</td>\n      <td>67.000000</td>\n      <td>69.000000</td>\n      <td>1.800000</td>\n      <td>1.520000</td>\n      <td>1.700000</td>\n      <td>4467673.0</td>\n      <td>4507445.0</td>\n      <td>4506589.0</td>\n      <td>1.808606</td>\n      <td>1.521612</td>\n      <td>1.694502</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>180.500000</td>\n      <td>139.000000</td>\n      <td>150.000000</td>\n      <td>2.575000</td>\n      <td>1.990000</td>\n      <td>2.220000</td>\n      <td>7446805.0</td>\n      <td>7451987.0</td>\n      <td>7502811.0</td>\n      <td>2.577577</td>\n      <td>1.993607</td>\n      <td>2.219482</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2111.000000</td>\n      <td>1706.000000</td>\n      <td>1750.000000</td>\n      <td>7.910000</td>\n      <td>7.920000</td>\n      <td>7.920000</td>\n      <td>39512223.0</td>\n      <td>39501653.0</td>\n      <td>39142991.0</td>\n      <td>7.928425</td>\n      <td>7.913519</td>\n      <td>7.899949</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Bonus EDA: Reproducing the Reported Statistic\n\n\n**How do we reproduce that reported statistic in the original [CDC report](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w)?**\n\n> Reported TB incidence (cases per 100,000 persons) increased **9.4%**, from **2.2** during 2020 to **2.4** during 2021 but was lower than incidence during 2019 (2.7). Increases occurred among both U.S.-born and non–U.S.-born persons.\n\nThis is TB incidence computed across the entire U.S. population! How do we reproduce this?\n* We need to reproduce the \"Total\" TB incidences in our rolled record.\n* But our current `tb_census_df` only has 51 entries (50 states plus Washington, D.C.). There is no rolled record.\n* What happened...?\n\nLet's get exploring!\n\nBefore we keep exploring, we'll set all indexes to more meaningful values, instead of just numbers that pertain to some row at some point. This will make our cleaning slightly easier.\n\n::: {.cell execution_count=45}\n``` {.python .cell-code code-fold=\"true\"}\ntb_df = tb_df.set_index(\"U.S. jurisdiction\")\ntb_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n    </tr>\n    <tr>\n      <th>U.S. jurisdiction</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>8900</td>\n      <td>7173</td>\n      <td>7860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=46}\n``` {.python .cell-code code-fold=\"false\"}\ncensus_2010s_df = census_2010s_df.set_index(\"Geographic Area\")\ncensus_2010s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n    <tr>\n      <th>Geographic Area</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>United States</th>\n      <td>309321666</td>\n      <td>311556874</td>\n      <td>313830990</td>\n      <td>315993715</td>\n      <td>318301008</td>\n      <td>320635163</td>\n      <td>322941311</td>\n      <td>324985539</td>\n      <td>326687501</td>\n      <td>328239523</td>\n    </tr>\n    <tr>\n      <th>Northeast</th>\n      <td>55380134</td>\n      <td>55604223</td>\n      <td>55775216</td>\n      <td>55901806</td>\n      <td>56006011</td>\n      <td>56034684</td>\n      <td>56042330</td>\n      <td>56059240</td>\n      <td>56046620</td>\n      <td>55982803</td>\n    </tr>\n    <tr>\n      <th>Midwest</th>\n      <td>66974416</td>\n      <td>67157800</td>\n      <td>67336743</td>\n      <td>67560379</td>\n      <td>67745167</td>\n      <td>67860583</td>\n      <td>67987540</td>\n      <td>68126781</td>\n      <td>68236628</td>\n      <td>68329004</td>\n    </tr>\n    <tr>\n      <th>South</th>\n      <td>114866680</td>\n      <td>116006522</td>\n      <td>117241208</td>\n      <td>118364400</td>\n      <td>119624037</td>\n      <td>120997341</td>\n      <td>122351760</td>\n      <td>123542189</td>\n      <td>124569433</td>\n      <td>125580448</td>\n    </tr>\n    <tr>\n      <th>West</th>\n      <td>72100436</td>\n      <td>72788329</td>\n      <td>73477823</td>\n      <td>74167130</td>\n      <td>74925793</td>\n      <td>75742555</td>\n      <td>76559681</td>\n      <td>77257329</td>\n      <td>77834820</td>\n      <td>78347268</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=47}\n``` {.python .cell-code code-fold=\"false\"}\ncensus_2020s_df = census_2020s_df.set_index(\"Geographic Area\")\ncensus_2020s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n    </tr>\n    <tr>\n      <th>Geographic Area</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>United States</th>\n      <td>331511512</td>\n      <td>332031554</td>\n      <td>333287557</td>\n    </tr>\n    <tr>\n      <th>Northeast</th>\n      <td>57448898</td>\n      <td>57259257</td>\n      <td>57040406</td>\n    </tr>\n    <tr>\n      <th>Midwest</th>\n      <td>68961043</td>\n      <td>68836505</td>\n      <td>68787595</td>\n    </tr>\n    <tr>\n      <th>South</th>\n      <td>126450613</td>\n      <td>127346029</td>\n      <td>128716192</td>\n    </tr>\n    <tr>\n      <th>West</th>\n      <td>78650958</td>\n      <td>78589763</td>\n      <td>78743364</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIt turns out that our merge above only kept state records, even though our original `tb_df` had the \"Total\" rolled record:\n\n::: {.cell execution_count=48}\n``` {.python .cell-code code-fold=\"false\"}\ntb_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n    </tr>\n    <tr>\n      <th>U.S. jurisdiction</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>8900</td>\n      <td>7173</td>\n      <td>7860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nRecall that `merge` by default does an **inner** merge by default, meaning that it only preserves keys that are present in **both** `DataFrame`s.\n\nThe rolled records in our census `DataFrame` have different `Geographic Area` fields, which was the key we merged on:\n\n::: {.cell execution_count=49}\n``` {.python .cell-code code-fold=\"false\"}\ncensus_2010s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n    <tr>\n      <th>Geographic Area</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>United States</th>\n      <td>309321666</td>\n      <td>311556874</td>\n      <td>313830990</td>\n      <td>315993715</td>\n      <td>318301008</td>\n      <td>320635163</td>\n      <td>322941311</td>\n      <td>324985539</td>\n      <td>326687501</td>\n      <td>328239523</td>\n    </tr>\n    <tr>\n      <th>Northeast</th>\n      <td>55380134</td>\n      <td>55604223</td>\n      <td>55775216</td>\n      <td>55901806</td>\n      <td>56006011</td>\n      <td>56034684</td>\n      <td>56042330</td>\n      <td>56059240</td>\n      <td>56046620</td>\n      <td>55982803</td>\n    </tr>\n    <tr>\n      <th>Midwest</th>\n      <td>66974416</td>\n      <td>67157800</td>\n      <td>67336743</td>\n      <td>67560379</td>\n      <td>67745167</td>\n      <td>67860583</td>\n      <td>67987540</td>\n      <td>68126781</td>\n      <td>68236628</td>\n      <td>68329004</td>\n    </tr>\n    <tr>\n      <th>South</th>\n      <td>114866680</td>\n      <td>116006522</td>\n      <td>117241208</td>\n      <td>118364400</td>\n      <td>119624037</td>\n      <td>120997341</td>\n      <td>122351760</td>\n      <td>123542189</td>\n      <td>124569433</td>\n      <td>125580448</td>\n    </tr>\n    <tr>\n      <th>West</th>\n      <td>72100436</td>\n      <td>72788329</td>\n      <td>73477823</td>\n      <td>74167130</td>\n      <td>74925793</td>\n      <td>75742555</td>\n      <td>76559681</td>\n      <td>77257329</td>\n      <td>77834820</td>\n      <td>78347268</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe Census `DataFrame` has several rolled records. The aggregate record we are looking for actually has the Geographic Area named \"United States\".\n\nOne straightforward way to get the right merge is to rename the value itself. Because we now have the Geographic Area index, we'll use `df.rename()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)):\n\n::: {.cell execution_count=50}\n``` {.python .cell-code code-fold=\"false\"}\n# rename rolled record for 2010s\ncensus_2010s_df.rename(index={'United States':'Total'}, inplace=True)\ncensus_2010s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n    <tr>\n      <th>Geographic Area</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>309321666</td>\n      <td>311556874</td>\n      <td>313830990</td>\n      <td>315993715</td>\n      <td>318301008</td>\n      <td>320635163</td>\n      <td>322941311</td>\n      <td>324985539</td>\n      <td>326687501</td>\n      <td>328239523</td>\n    </tr>\n    <tr>\n      <th>Northeast</th>\n      <td>55380134</td>\n      <td>55604223</td>\n      <td>55775216</td>\n      <td>55901806</td>\n      <td>56006011</td>\n      <td>56034684</td>\n      <td>56042330</td>\n      <td>56059240</td>\n      <td>56046620</td>\n      <td>55982803</td>\n    </tr>\n    <tr>\n      <th>Midwest</th>\n      <td>66974416</td>\n      <td>67157800</td>\n      <td>67336743</td>\n      <td>67560379</td>\n      <td>67745167</td>\n      <td>67860583</td>\n      <td>67987540</td>\n      <td>68126781</td>\n      <td>68236628</td>\n      <td>68329004</td>\n    </tr>\n    <tr>\n      <th>South</th>\n      <td>114866680</td>\n      <td>116006522</td>\n      <td>117241208</td>\n      <td>118364400</td>\n      <td>119624037</td>\n      <td>120997341</td>\n      <td>122351760</td>\n      <td>123542189</td>\n      <td>124569433</td>\n      <td>125580448</td>\n    </tr>\n    <tr>\n      <th>West</th>\n      <td>72100436</td>\n      <td>72788329</td>\n      <td>73477823</td>\n      <td>74167130</td>\n      <td>74925793</td>\n      <td>75742555</td>\n      <td>76559681</td>\n      <td>77257329</td>\n      <td>77834820</td>\n      <td>78347268</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=51}\n``` {.python .cell-code code-fold=\"false\"}\n# same, but for 2020s rename rolled record\ncensus_2020s_df.rename(index={'United States':'Total'}, inplace=True)\ncensus_2020s_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n    </tr>\n    <tr>\n      <th>Geographic Area</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>331511512</td>\n      <td>332031554</td>\n      <td>333287557</td>\n    </tr>\n    <tr>\n      <th>Northeast</th>\n      <td>57448898</td>\n      <td>57259257</td>\n      <td>57040406</td>\n    </tr>\n    <tr>\n      <th>Midwest</th>\n      <td>68961043</td>\n      <td>68836505</td>\n      <td>68787595</td>\n    </tr>\n    <tr>\n      <th>South</th>\n      <td>126450613</td>\n      <td>127346029</td>\n      <td>128716192</td>\n    </tr>\n    <tr>\n      <th>West</th>\n      <td>78650958</td>\n      <td>78589763</td>\n      <td>78743364</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<br/>\n\nNext let's rerun our merge. Note the different chaining, because we are now merging on indexes (`df.merge()` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)).\n\n::: {.cell execution_count=52}\n``` {.python .cell-code code-fold=\"false\"}\ntb_census_df = (\n    tb_df\n    .merge(right=census_2010s_df[[\"2019\"]],\n           left_index=True, right_index=True)\n    .merge(right=census_2020s_df[[\"2020\", \"2021\"]],\n           left_index=True, right_index=True)\n)\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>8900</td>\n      <td>7173</td>\n      <td>7860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n      <td>328239523</td>\n      <td>331511512</td>\n      <td>332031554</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>4903185</td>\n      <td>5031362</td>\n      <td>5049846</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>731545</td>\n      <td>732923</td>\n      <td>734182</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>7278717</td>\n      <td>7179943</td>\n      <td>7264877</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>3017804</td>\n      <td>3014195</td>\n      <td>3028122</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<br/>\n\nFinally, let's recompute our incidences:\n\n::: {.cell execution_count=53}\n``` {.python .cell-code code-fold=\"false\"}\n# recompute incidence for all years\nfor year in [2019, 2020, 2021]:\n    tb_census_df[f\"recompute incidence {year}\"] = tb_census_df[f\"TB cases {year}\"]/tb_census_df[f\"{year}\"]*100000\ntb_census_df.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TB cases 2019</th>\n      <th>TB cases 2020</th>\n      <th>TB cases 2021</th>\n      <th>TB incidence 2019</th>\n      <th>TB incidence 2020</th>\n      <th>TB incidence 2021</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>recompute incidence 2019</th>\n      <th>recompute incidence 2020</th>\n      <th>recompute incidence 2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Total</th>\n      <td>8900</td>\n      <td>7173</td>\n      <td>7860</td>\n      <td>2.71</td>\n      <td>2.16</td>\n      <td>2.37</td>\n      <td>328239523</td>\n      <td>331511512</td>\n      <td>332031554</td>\n      <td>2.711435</td>\n      <td>2.163726</td>\n      <td>2.367245</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>87</td>\n      <td>72</td>\n      <td>92</td>\n      <td>1.77</td>\n      <td>1.43</td>\n      <td>1.83</td>\n      <td>4903185</td>\n      <td>5031362</td>\n      <td>5049846</td>\n      <td>1.774357</td>\n      <td>1.431024</td>\n      <td>1.821838</td>\n    </tr>\n    <tr>\n      <th>Alaska</th>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>7.91</td>\n      <td>7.92</td>\n      <td>7.92</td>\n      <td>731545</td>\n      <td>732923</td>\n      <td>734182</td>\n      <td>7.928425</td>\n      <td>7.913519</td>\n      <td>7.899949</td>\n    </tr>\n    <tr>\n      <th>Arizona</th>\n      <td>183</td>\n      <td>136</td>\n      <td>129</td>\n      <td>2.51</td>\n      <td>1.89</td>\n      <td>1.77</td>\n      <td>7278717</td>\n      <td>7179943</td>\n      <td>7264877</td>\n      <td>2.514179</td>\n      <td>1.894165</td>\n      <td>1.775667</td>\n    </tr>\n    <tr>\n      <th>Arkansas</th>\n      <td>64</td>\n      <td>59</td>\n      <td>69</td>\n      <td>2.12</td>\n      <td>1.96</td>\n      <td>2.28</td>\n      <td>3017804</td>\n      <td>3014195</td>\n      <td>3028122</td>\n      <td>2.120747</td>\n      <td>1.957405</td>\n      <td>2.27864</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe reproduced the total U.S. incidences correctly!\n\nWe're almost there. Let's revisit the quote:\n\n> Reported TB incidence (cases per 100,000 persons) increased **9.4%**, from **2.2** during 2020 to **2.4** during 2021 but was lower than incidence during 2019 (2.7). Increases occurred among both U.S.-born and non–U.S.-born persons.\n\nRecall that percent change from $A$ to $B$ is computed as\n$\\text{percent change} = \\frac{B - A}{A} \\times 100$.\n\n::: {.cell tags='[]' execution_count=54}\n``` {.python .cell-code code-fold=\"false\"}\nincidence_2020 = tb_census_df.loc['Total', 'recompute incidence 2020']\nincidence_2020\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n2.1637257652759883\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=55}\n``` {.python .cell-code code-fold=\"false\"}\nincidence_2021 = tb_census_df.loc['Total', 'recompute incidence 2021']\nincidence_2021\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n2.3672448914298068\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=56}\n``` {.python .cell-code code-fold=\"false\"}\ndifference = (incidence_2021 - incidence_2020)/incidence_2020 * 100\ndifference\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\n9.405957511804143\n```\n:::\n:::\n\n\n# Summary\nWe went over a lot of content this lecture; let's summarize the most important points: \n\n## Dealing with Missing Values\nThere are a few options we can take to deal with missing data:\n\n* Drop missing records\n* Keep `NaN` missing values\n* Impute using an interpolated column\n\n## EDA and Data Wrangling\nThere are several ways to approach EDA and Data Wrangling: \n\n* Examine the **data and metadata**: what is the date, size, organization, and structure of the data? \n* Examine each **field/attribute/dimension** individually.\n* Examine pairs of related dimensions (e.g. breaking down grades by major).\n* Along the way, we can \n    * **Visualize** or summarize the data.\n    * **Validate assumptions** about data and its collection process. Pay particular attention to when the data was collected. \n    * Identify and **address anomalies**.\n    * Apply data transformations and corrections (we'll cover this in the upcoming lecture).\n    * **Record everything you do!** Developing in Jupyter Notebook promotes *reproducibility* of your own work!\n\n",
    "supporting": [
      "eda_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}